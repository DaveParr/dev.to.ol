http_interactions:
- request:
    method: get
    uri: https://dev.to/api/articles/me
    body:
      encoding: ''
      string: ''
    headers:
      Accept: application/json, text/xml, application/xml, */*
      api-key: <<<my_api_key>>>
  response:
    status:
      status_code: 200
      category: Success
      reason: OK
      message: 'Success: (200) OK'
    headers:
      accept-ranges:
      - bytes
      - bytes
      - bytes
      - bytes
      access-control-allow-origin: '*'
      age:
      - '0'
      - '0'
      cache-control: max-age=0, private, must-revalidate
      content-encoding: gzip
      content-type: application/json; charset=utf-8
      date: Sat, 06 Jun 2020 12:29:29 GMT
      etag: W/"b8c91bd10c961f1d23556ddf9479c6ed"
      referrer-policy: strict-origin-when-cross-origin
      server: Cowboy
      vary: Accept-Encoding, Origin, X-Loggedin
      via:
      - 1.1 vegur
      - 1.1 varnish
      - 1.1 varnish
      x-cache: MISS, MISS
      x-cache-hits: 0, 0
      x-content-type-options: nosniff
      x-download-options: noopen
      x-frame-options: SAMEORIGIN
      x-permitted-cross-domain-policies: none
      x-request-id: 6db1fe7b-a3be-427b-af1b-388ed6731be1
      x-runtime: '0.071314'
      x-served-by: cache-den19622-DEN, cache-lhr7352-LHR
      x-timer: S1591446570.596773,VS0,VE348
      x-xss-protection: 1; mode=block
    body:
      encoding: UTF-8
      file: no
      string: '[{"type_of":"article","id":347576,"title":"Testing my dev.to API package
        with testthat, webmockr and vcr","description":"I’ve been working on an open
        source R package wrapping the dev.to API. After a bit of prototyping the...","published":true,"published_at":"2020-06-03T11:40:24.185Z","slug":"testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm","path":"/daveparr/testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm","url":"https://dev.to/daveparr/testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm","comments_count":1,"public_reactions_count":5,"page_views_count":0,"published_timestamp":"2020-06-03T11:40:24Z","body_markdown":"I’ve
        been working on an [open source R package wrapping the dev.to\nAPI](https://github.com/DaveParr/dev.to.ol).
        After a bit of prototyping\nthe core feature and then some iterative development
        to make it a bit\nmore useful to a user, it’s starting to settle into something
        that is\nworth testing\\*.\n\n## Testing in R\n\nSometimes people seem a little
        surprised that this is something R users/\nData Scientists even think about,
        but R is a programming language, just\nlike all the others, except different,
        just like all the others. Testing\nin modern tidyverse R is usually accomplished
        by the\n[`testthat`](https://testthat.r-lib.org/) package. If you are more\nfamiliar
        with testing in other languages, this quote from the Overview\nmight help:\n\n\u003e
        testthat draws inspiration from the xUnit family of testing packages,\n\u003e
        as well as from many of the innovative ruby testing libraries, like\n\u003e
        rspec, testy, bacon and cucumber.\n\n### A note on `usethis`\n\nIn R we have
        a rich ecosystem of developer tools to help us make\npackages. `testthat`
        is one. Another one is `usethis`. See what they did\nthere? Anyway, for the
        purpose of this article, you just need to know\nthat a package called `usethis`
        helps us set up things for us to make\ndevelopment easier. In the future I
        might write something more about it\n¯\\\\\\_(ツ)\\_/¯.\n\n## `testthat`\n\n###
        Setting up `testthat`\n\nAssuming that you have a well formatted R Package
        structure, you can\neasily enable a testing framework and all the boiler plate
        you might\nneed with one line:\n\n``` r\nusethis::use_testthat()\n```\n\nWhich
        will do a few things for you and tell you what it’s doing.\n\n``` sh\n✔ Setting
        active project to ''/Users/davidparr/Documents/example.testthat''\n✔ Adding
        ''testthat'' to Suggests field in DESCRIPTION\n✔ Creating ''tests/testthat/''\n✔
        Writing ''tests/testthat.R''\n● Call `use_test()` to initialize a basic test
        file and open it for editing.\n```\n\nFrom there, we can use `usethis::use_test()`.
        If you have a file open in\nRStudio which is an `*.R` file containing function
        definitions it will\nthen make a new test file for you:\n\n``` sh\n✔ Increasing
        ''testthat'' version to ''\u003e= 2.1.0'' in DESCRIPTION\n✔ Writing ''tests/testthat/test-hello.R''\n●
        Modify ''tests/testthat/test-hello.R''\n```\n\nThe contents of that test file
        will be silly boilerplate, so now it’s\ntime to do some real work.\n\n###
        Writing a `testthat` test\n\n``` r\ntest_that(\"multiplication works\", {\n  expect_equal(2
        * 2, 4)\n})\n```\n\nThis is the boilerplate. If you run it, you might be surprised
        that\nnothing happens\\! Well, actually a lot of stuff happens, but it doesn’t\nreally
        tell you about it by design. If you make a test that isn’t going\nto pass
        however…\n\n``` r\ntest_that(\"maths works\", {\n  expect_equal(2 * 2, 5)\n})\n```\n\n    ##
        Error: Test failed: ''maths works''\n    ## * \u003ctext\u003e:2: 2 * 2 not
        equal to 5.\n    ## 1/1 mismatches\n    ## [1] 4 - 5 == -1\n\nAn error\\!
        Just what we wanted\\! so this is the basis of testing with\n`testthat`. Write
        a `test_that()` function, which has a name, and then a\nblock of expectations
        to check against.\n\n## `webmockr`\n\nSo this works fine for traditional unit
        tests, where we can give\ndiscrete calculations, or check that a given function
        gives a specific\noutput end to end, where we control both the test, but also
        the function\nas a whole. But what if we’re reliant on some ‘external’ process
        that we\nmight not control. The dev.to API for instance? I’m not employed
        by\ndev.to (through I am [looking for a new\nopportunity](https://dev.to/daveparr/i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5)),\nso
        I don’t get to play around inside the API system, but I do need to\nprove
        that any code I write will behave the way I want it to based on\ntheir API
        requests and responses. A simple way to prove this is to\n*mock* their service
        (i.e. impersonate it, not tell it it’s silly). This\nis where [`webmockr`](https://docs.ropensci.org/webmockr/)
        comes in.\n`webmockr` is an:\n\n\u003e “R library for stubbing and setting
        expectations on HTTP requests”\n\nPerfect. Let’s write something using both
        `testthat` and `webmockr`.\n\n### Writing a `webmockr` test\n\nIn `webmockr`
        we make *stubs*. These are fake, minimal objects that are\nsimilar to test
        fixtures. We know their properties, because we made\nthem, and we want to
        make sure that any functions we write interact with\nthese objects in a predictable
        way. Another way of looking at them is as\na fake API. They look like an API,
        with responses and status codes, but\nthey only exist in our test suite. This
        means I don’t need to bombard\ndev.to with requests any more to make sure
        I haven’t broken anything.\n\n``` r\nwebmockr::enable(adapter = \"httr\")\n\nwebmockr::stub_registry_clear()\n\nwebmockr::stub_request(\"get\",
        \"https://dev.to/api/users/me\") %\u003e%\n  webmockr::to_return(body = \"success!\",
        status = 200)\n\nmy_user \u003c- dev.to.ol::get_my_user()\n\ntest_that(\"stubbed
        response is 200\", {\n  expect_is(my_user, \"response\")\n  expect_equal(my_user$status_code,
        200)\n})\n```\n\nThis code first of all sets up our test file to understand
        that requests\nwill be sent as if from the `httr` package. It then clears
        the registry,\njust to make sure nothing is left in a cache. It then populates
        the now\nempty cache with a new stub. This stub will respond to a `GET` request\nto
        the URL, and will return a simple text body, and a 200 status code.\nThe function
        I want to test is then run, which in this environment hits\nthe *stub*, not
        the real api. The object that is returned is then\nchecked by `test_that`
        to make sure it is a `response` type object, and\nthat is has a status code
        that has the value 200.\n\n### Good enough, but is it actually enough?\n\nThis
        proves a few, specific things. That the function returns a\n`response` that
        has a 200 status code if it trys to `GET` from that\nspecific URL. However,
        APIs actually return quite a lot of information\nby default and maybe I care
        about more things than a 200 status code.\nThey can also have quite complex
        structures, so using this method to\nmake a fake response could get *very*
        awkward if I am trying to make a\nrealistic response. Also, what if the structure
        of the api changes\nunderneath us? It is in beta after all. A big change would
        mean all\nthose carefully written pipes would have to be rewritten by me every\ntime.
        Blergh. Luckily we have a solution for that too\\!\n\n## `vcr`\n\n[`vcr`](https://docs.ropensci.org/vcr/)
        does not stand for `Very Cool\nResponses`, but I think it should. From it’s
        own description:\n\n\u003e Record HTTP calls and replay them\n\nIt’s an R
        port of a ruby gem of the same name, this package allows you\nto ‘record’
        the response of an API to a YAML file ‘cassette’. You can\nthen ‘play’ the
        ‘cassette’ back during the test as if the API was being\nactually called.
        If you’re still not sure where the name comes from,\nthen you might be a little
        to young to [get the\nreference](https://twitter.com/TheEllenShow/status/1116056186606850048).\n\n###
        Setting up `vcr`\n\n`vcr` has a few things it needs in a project to run, and
        though it\ndoesn’t have its *own* entry in `usethis`, it does have it’s own\nset-up
        function in a similar style:\n\n``` r\nvcr::use_vcr()\n```\n\n``` sh\n◉ Using
        package: vcr.example  \n◉ assuming fixtures at: tests/fixtures  \n✓ Adding
        vcr to Suggests field in DESCRIPTION  \n✓ Creating directory: ./tests/testthat  \n◉
        Looking for testthat.R file or similar  \n✓ tests/testthat.R: added  \n✓ Adding
        vcr config to tests/testthat/helper-vcr.example.R  \n✓ Adding example test
        file tests/testthat/test-vcr_example.R  \n✓ .gitattributes: added  \n◉ Learn
        more about `vcr`: https://books.ropensci.org/http-testing\n```\n\nFrom there,
        we can use the normal `testthat` flow. Here’s an example\nusing the `POST`
        to write a new article.\n\n``` r\ntest_that(\"post new article\", {\n  vcr::use_cassette(\"post_new_article\",
        {\n    new_article \u003c- dev.to.ol::post_new_article(file = \"./test.Rmd\")\n  })\n\n  expect_is(new_article,
        \"response\")\n  expect_equal(new_article$status_code, 201)\n})\n```\n\nWell,
        that’s an easy change\\! The only difference from the first test is\nthat
        we have wrapped the function we are testing in a `use_cassette`\nblock, inside
        the `test_that` block. Now, the first time this function\nis run, you [get\nthis](https://github.com/DaveParr/dev.to.ol/blob/master/tests/fixtures/post_new_article.yml).\nA
        huge YAML file that describes the response of the actual API. Now,\nevery
        time the test is run, that cassette will get loaded as the ‘mock’,\nand it’s
        so much more developed than our stub\\! We can test against\nanything we want
        in the response, and even better, the response is\ntotally human readable.\n\nWhat
        about changes? What happens if you make a change to the data you\nuse to test
        the function that invalidates the `cassette`? What if the\ndev.to spec changes?
        Easy, all you do is delete the test and re-run. The\nfunction will then go
        and get a new response, and populate the file\nagain. Your tests then run
        against the new file. You can even commit\nthese to version control. Then
        you can tell exactly when an API change\noccurred, and what was different
        afterwards.\n\n## Thanks Scott\n\nBoth the `webmockr` and `vcr` packages are
        being maintained by @sckott,\nwho is an active writer here on dev.to. and
        I think he’s really worth a\nfollow. He also works on [ROpenSci](https://ropensci.org/),
        which I\nthink is also a really cool project. If you are working with R on
        a\nscientific/research project you should be extra interested.\n\n\\* Yes,
        I know that TDD exists. IMHO: No, I don’t think it’s a bad\nthing, but also
        no, I don’t think it’s always something to use\neverywhere all the time.\n","positive_reactions_count":5,"cover_image":null,"tag_list":["Rstats","projectbenatar","showdev","testing"],"canonical_url":"https://dev.to/daveparr/testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"},"flare_tag":{"name":"showdev","bg_color_hex":"#091b47","text_color_hex":"#b2ffe1"}},{"type_of":"article","id":347581,"title":"Does
        anyone have any meetup alternatives?","description":"I found this article
        on meetup alternatives interesting. I''m an organiser for Cardiff R Usergroup,
        an...","published":true,"published_at":"2020-06-01T17:52:32.193Z","slug":"does-anyone-have-any-meetup-alternatives-30j2","path":"/daveparr/does-anyone-have-any-meetup-alternatives-30j2","url":"https://dev.to/daveparr/does-anyone-have-any-meetup-alternatives-30j2","comments_count":3,"public_reactions_count":2,"page_views_count":36,"published_timestamp":"2020-06-01T17:52:32Z","body_markdown":"[I
        found this article on meetup alternatives interesting](https://marcusnoble.co.uk/2019-10-21-meetup-alternatives/).
        I''m an organiser for [Cardiff R Usergroup](https://www.meetup.com/Cardiff-R-User-Group/),
        and regularly attend quite a few other events in the city. \n\nIs meetup common
        for tech groups where you are? Do you or events you go to use anything different?","positive_reactions_count":2,"cover_image":null,"tag_list":["watercooler","discuss","eventsinyourcity"],"canonical_url":"https://dev.to/daveparr/does-anyone-have-any-meetup-alternatives-30j2","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}},{"type_of":"article","id":344150,"title":"Building
        my first Django project","description":"I''m working through Django for Beginners
        by William S. Vincent. The second chapter gets us into devel...","published":true,"published_at":"2020-06-01T12:00:26.409Z","slug":"building-my-first-django-project-4fi3","path":"/daveparr/building-my-first-django-project-4fi3","url":"https://dev.to/daveparr/building-my-first-django-project-4fi3","comments_count":0,"public_reactions_count":2,"page_views_count":76,"published_timestamp":"2020-06-01T12:00:26Z","body_markdown":"I''m
        working through [Django for Beginners by William S. Vincent](https://djangoforbeginners.com/).
        The second chapter gets us into developing our first app. It simply displays
        a single page with an unformatted Hello World on it, but I really appreciated
        how the project is so fully fleshed out end to end. You start a project with
        a clean `pipenv`, and make the files and folders through the CLI. The django
        framework provides some really nice methods to ''boilerplate'' the multiple
        files needed in each project, and having this introduced at the start and
        then fill in the details later when you are hands on is definitely the best
        way to go.\n\nIntroducing migrations and the url-view-model[-template] core
        concepts was pretty simple in practice, though a little confusing initially.
        \"I''ve just made a bunch of files with this single `startapp` command, what
        do they all do?\" was admittedly my first reaction. \n\nThe best part of the
        way this book is set up is the definition of done used in the core workflow.
        A project isn''t done unless it has a commit history, is hosted on GitHub
        and deployed on Heroku. I''m really a fan of approaching deployment in Chapter
        2, just like version control and dev environments in Chapter 1. These concepts
        are your friends, not your monsters :)\n\nIncidentally, having only been aware
        of Heroku in passing, I really like the PAAS set up. Very usable, the cli
        tools make the whole thing a doddle and the end satisfaction of being able
        to point at something that''s actually on the web and say ''I did that!''
        is always a little more satisfying than ''It works on my machine?''.","positive_reactions_count":2,"cover_image":null,"tag_list":["python","django"],"canonical_url":"https://dev.to/daveparr/building-my-first-django-project-4fi3","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}},{"type_of":"article","id":344145,"title":"Setting
        up a Django dev environment","description":"I''m working through Django for
        Beginners by William S. Vincent. The first part is about setting up yo...","published":true,"published_at":"2020-05-27T18:33:40.372Z","slug":"setting-up-a-django-dev-environment-17b7","path":"/daveparr/setting-up-a-django-dev-environment-17b7","url":"https://dev.to/daveparr/setting-up-a-django-dev-environment-17b7","comments_count":0,"public_reactions_count":4,"page_views_count":48,"published_timestamp":"2020-05-27T18:33:40Z","body_markdown":"I''m
        working through [Django for Beginners by William S. Vincent](https://djangoforbeginners.com/).
        The first part is about setting up your dev environment. The book is setup
        to start for a _complete_ beginner level, which is really nice. It starts
        from introducing the basics of the CLI for both Mac and Windows systems, and
        then some simple terminal commands with `cd`, `ls` etc.\n\nIt then goes on
        to help with installation of Python3, `git`, `pipenv` and `django`, all great
        stuff for getting started, plus it set''s a great baseline for the rest of
        the book.\n\nFor anyone who has worked at all with terminals, version control,
        isolating environments and code editors, 90% of this will be already done
        on the machine, but I still think it''s worth putting in. Having it laid out
        for you at the start of your programming experience that version control and
        the terminal are part of the process I think helps with the hump I''ve seen
        in more experienced beginners where `git` and `pipenv` are Yet Another Thing
        To Learn and so get pushed back in the learning pathway more out of fear than
        anything else.\n\nPersonally, I zipped through the setup in a few minutes.
        Hello World django app next!\n\nHas anyone else seen the ''git is yet another
        thing to learn'' hump? Maybe even had it? How did you overcome it?","positive_reactions_count":4,"cover_image":null,"tag_list":["python","django","git","pipenv"],"canonical_url":"https://dev.to/daveparr/setting-up-a-django-dev-environment-17b7","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}},{"type_of":"article","id":343573,"title":"I
        made my dev.to content into a website to find a new job","description":"After
        discovering this post and this post, I decided to use this tooling to get
        a very simple job don...","published":true,"published_at":"2020-05-25T18:29:10.311Z","slug":"i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5","path":"/daveparr/i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5","url":"https://dev.to/daveparr/i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5","comments_count":2,"public_reactions_count":21,"page_views_count":359,"published_timestamp":"2020-05-25T18:29:10Z","body_markdown":"After
        discovering [this post](https://dev.to/stackbit/project-benatar-publishing-dev-powered-websites-with-stackbit-lfo)
        and [this post](https://dev.to/devteam/you-can-now-generate-self-hostable-static-blogs-right-from-your-dev-content-via-stackbit-7a5),
        I decided to use this tooling to get a very simple job done to help me look
        for work.\n\n## Context\n\nI''ve been using dev.to a little over the last
        year, and a lot more over the last month. It makes sense for me to use this
        content in my job hunt. I also had a languishing personal page. Originally
        made as a little experiment with hugo, it hadn''t seen love in a while, and
        due to some jankey usage of high quality photos performance wise it was pretty
        bad. I''d been meaning to overhaul it for a while, and when the dev.to x stackbit
        collab came to my attention, it was a perfect fit.\n\n## Goals\n\n1. Use the
        content I''ve written, and will be continuing to write, to prove I know at
        least a few things about programming.\n1. Get that content wrapped up neatly
        with a contact page, a statement that I''m looking for work, and a brief about
        me\n1. Use my daveparr.info domain\n1. Make the website more performant than
        it''s current iteration\n1. Use a clean, simple, slightly professional theme\n\n##
        Method\n\n1. Read the instructions in @ben ''s [post](https://dev.to/devteam/you-can-now-generate-self-hostable-static-blogs-right-from-your-dev-content-via-stackbit-7a5)\n1.
        Go through the creation flow\n1. Assign the domain in netlify (I had a netlify
        hosted JAMstack previously, and my domain was already loaded in there. YMMV)\n1.
        Clone the project @stackbit created from GitHub, and follow the [readme](https://github.com/DaveParr/daveparrinfo/blob/master/README.md)
        they left there to help you authenticate correctly\n1. Update the [boilerplate
        stuff](https://github.com/DaveParr/daveparrinfo/commit/d8836e723d49ccd13f5655e7f58346dfa4ade17f)\n1.
        Push the changes back to GitHub\n1. Profit\n\n## Hiccup\n\nI was a little
        surprised when my local copy suddenly got all my blog files [that I then just
        commited]\n(https://github.com/DaveParr/daveparrinfo/commit/1987c701187b45a85d8b0448a8c577c47ab8b2ac),
        but that seemed to be ok. Pretty sure I''ve not broken anything :)\n\n## The
        End\n\nGoals achieved, faster website, with better styling, that will be kept
        more up to date.\n\n## P.S. \n\nIf you are reading this _on_ my [website](daveparr.info),
        this is all actually managed through a headless CMS called [dev.to](dev.to).
        You can use the link to my profile on the left of this article. If you are
        reading this on dev.to you can see my running website at [daveparr.info](daveparr.info).","positive_reactions_count":21,"cover_image":null,"tag_list":["projectbenatar","showdev","hugo","stackbit"],"canonical_url":"https://dev.to/daveparr/i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"},"flare_tag":{"name":"showdev","bg_color_hex":"#091b47","text_color_hex":"#b2ffe1"}},{"type_of":"article","id":342971,"title":"Posting
        straight from .Rmd to dev.to (for real this time)","description":"I’ve spent
        a little time fleshing out my open source R package to post from .Rmd straight
        to dev.to....","published":true,"published_at":"2020-05-24T17:08:05.561Z","slug":"posting-straight-from-rmd-to-dev-to-1j4p","path":"/daveparr/posting-straight-from-rmd-to-dev-to-1j4p","url":"https://dev.to/daveparr/posting-straight-from-rmd-to-dev-to-1j4p","comments_count":0,"public_reactions_count":18,"page_views_count":170,"published_timestamp":"2020-05-24T17:08:05Z","body_markdown":"I’ve
        spent a little time fleshing out my [open source R\npackage](https://github.com/DaveParr/dev.to.ol)
        to post from `.Rmd`\nstraight to dev.to.\n\n## Update from V1\n\nThe biggest
        difference from the [first\nversion](https://dev.to/daveparr/posting-from-rmd-to-dev-to-5gld)
        is\nthat there is now a single function to move straight from an `.Rmd` on\ndisk
        to a post on dev.to. In V1 the user still had to:\n\n1.  Write an `.Rmd`\n2.  `knit`
        to `github_document`\n3.  `post_new_article` using my `dev.to.ol` package\n4.  De-duplicate
        the title\n5.  (Optionally) Add meta-data\n\nWith this new function the workflow
        is:\n\n1.  Write an `.Rmd`\n2.  `post_new_article` using my `dev.to.ol` package\n\n:tada:\n\n```
        r\n#'' @title Post a markdown file to dev.to\n#'' @description Create a new
        post from an .Rmd.\n#'' @param file The path to the file\n#'' @param key Your
        API key, Default: NA\n#'' @return The response\n#'' @details Will look for
        an api key in the `.REnviron` file. Seems to check if the body is identical
        to a previous article and error if so with `\"Body markdown has already been
        taken\"`.\n#'' The following YAML arguments are read from the file YAML frontmatter
        if present:\n#'' \\describe{\n#''   \\item{title}{A character string}\n#''   \\item{series}{A
        character string}\n#''   \\item{published}{A boolean}\n#''   \\item{tags}{list
        of character strings: \\code{[\"tag1\", \"tag2\"]}}\n#'' }\n#''\n#'' The default
        table output method renders a very large print code block.\n#'' The workaround
        is to use  \\code{\\link[knitr]{kable}}.\n#''\n#'' @examples\n#'' \\dontrun{\n#''
        if(interactive()){\n#''  post_new_article(\"./articles/my_article.Rmd\")\n#''  }\n#''
        }\n#'' @seealso\n#''  \\code{\\link[rmarkdown]{yaml_front_matter}},\\code{\\link[rmarkdown]{render}}\n#''  \\code{\\link[readr]{read_file}}\n#''  \\code{\\link[stringr]{str_remove}}\n#''  \\code{\\link[glue]{glue}}\n#''  \\code{\\link[httr]{POST}},\\code{\\link[httr]{add_headers}},\\code{\\link[httr]{content}}\n#''
        @rdname post_new_article\n#'' @export\n#'' @importFrom rmarkdown yaml_front_matter
        render\n#'' @importFrom readr read_file\n#'' @importFrom stringr str_remove\n#''
        @importFrom glue glue\n#'' @importFrom httr POST add_headers content\n\npost_new_article
        \u003c-\n  function(file,\n           key = NA) {\n    check_file \u003c-
        is_postable_Rmd(file)\n\n    if (check_file) {\n      file_frontmatter \u003c-
        rmarkdown::yaml_front_matter(file)\n\n      output_path \u003c- rmarkdown::render(''./data/test.Rmd'',\n                                       output_format
        = ''github_document'',\n                                       output_dir
        = getwd())\n\n      file_string \u003c- readr::read_file(output_path) %\u003e%\n        stringr::str_remove(glue::glue(\"{title}\\n================\\n\\n\\n\",\n                                       title
        = file_frontmatter$title))\n\n      response \u003c- httr::POST(\n        url
        = \"https://dev.to/api/articles\",\n        httr::add_headers(\"api-key\"
        = api_key(key = key)),\n        body = list(\n          article = list(\n            title
        = file_frontmatter$title,\n            series = file_frontmatter$series,\n            published
        = file_frontmatter$published,\n            tags = file_frontmatter$tags,\n            body_markdown
        = file_string\n          )\n        ),\n        encode = ''json''\n      )\n      httr::content(response)\n    }
        else {\n      message(attr(check_file, \"msg\"))\n    }\n  }\n```\n\n## Notable
        changes\n\n### Extract `YAML` frontmatter and render from `.Rmd` with [`rmarkdown`](https://rmarkdown.rstudio.com/)\n\nThe
        function will now accept an `.Rmd` file directly which it renders to\nthe
        correct markdown output internally. This was the biggest part\nmissing from
        V1, and was easy to do with `rmarkdown::render`. A great\nside-effect is that
        I can also access the `YAML` frontmatter of the\n`.Rmd`, which I can use to
        populate the meta-data such as the series the\npost is in, the tags the post
        is relevant to, and the published status.\n\n### Check file is suitable with\n[`assertthat`](https://github.com/hadley/assertthat)\n\nAnother
        benefit is that there is now a concrete object I can check for\ncorrectness.
        I’ve adopted the `assertthat` package to help me, and most\nof the work was
        [done in this\ncommit](https://github.com/DaveParr/dev.to.ol/commit/ddccf8ce60adf2bc35ed61d0c0ae581a9189d32d).\nThe
        workhorse function is\n[`is_postable_Rmd`](https://github.com/DaveParr/dev.to.ol/blob/master/R/is_postable_Rmd.R):\n\n    is_postable_Rmd
        \u003c- function(file) {\n      assertthat::see_if(\n        assertthat::is.readable(file),\n        assertthat::has_extension(file,
        \"Rmd\")\n      )\n    }\n\nUsing `assertthat::see_if` was really useful.
        It allowed me to check for\nmultiple conditions, and if they were both passed,
        it returns `TRUE`.\nHowever, if they did not pass, it returns `FALSE` *as
        well as a message\nattribute*. This meant that I could very trivially plumb
        that back into\nthe main function for user feedback as to what is the problem
        with the\nline `message(attr(check_file, \"msg\"))`. Additionally, as I add
        criteria\nto the function I know they will all return human, well formatted
        error\nmessages. Great work `assertthat`\\!\n\n### Deduplicate the title with
        [`glue`](https://glue.tidyverse.org/) and [`stringr`](https://stringr.tidyverse.org/)\n\nOne
        of the issues with the original approach was the call to render will\ngenerate
        an `.md` with a title *in the file*, but the dev.to api wants\nthe title *as
        a separate part of the call*. `stringr` and `glue` to the\nrescue\\! Using
        `glue` is basically a super powered paste. It does nice\nthings to insert
        named string variables into a templated string. I use\nthis to make the string
        that is what I want to *remove* from the\n`body_markdown` object, and then
        do the actual removal with\n`str_remove`.\n\n## Next steps\n\nImages. The
        real power of Rmarkdown comes from turning code into\nnotebooks populated
        with graphics representing your data science work. I\nhave [not yet found
        an api endpoint for\nimages](https://dev.to/daveparr/is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd).\nThe
        POST looks like it will allow a cover image to be included, but on\nthe face
        of it I don’t think it will allow images to be inserted at\narbitrary points
        in the article text. Still, I’ll start there and see\nwhere it goes\\!\n","positive_reactions_count":18,"cover_image":null,"tag_list":["rstats","projectbenatar","showdev","meta"],"canonical_url":"https://dev.to/daveparr/posting-straight-from-rmd-to-dev-to-1j4p","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"},"flare_tag":{"name":"showdev","bg_color_hex":"#091b47","text_color_hex":"#b2ffe1"}},{"type_of":"article","id":342420,"title":"Is
        there an API endpoint to upload images to DEV.TO?","description":"I''m continuing
        to work on dev.to.ol. Some of the future work is sort of clear to me, but
        I''m still mi...","published":true,"published_at":"2020-05-23T17:24:47.260Z","slug":"is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd","path":"/daveparr/is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd","url":"https://dev.to/daveparr/is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd","comments_count":0,"public_reactions_count":2,"page_views_count":73,"published_timestamp":"2020-05-23T17:24:47Z","body_markdown":"
        I''m continuing to work on [`dev.to.ol`](https://github.com/DaveParr/dev.to.ol).
        Some of the [future work](https://github.com/DaveParr/dev.to.ol/projects)
        is sort of clear to me, but I''m still missing a big piece of the puzzle.
        \n\n\u003e How can I take the charts (images) generated by the rendering of
        the .Rmd, and submit them to dev.to?\n\nI''m not spotting a `POST` or `PUT`
        method in the [api docs](https://docs.dev.to/api/). Have I overlooked something,
        or is it something that might be a future feature?","positive_reactions_count":2,"cover_image":null,"tag_list":["help","meta","projectbenatar","Rstats"],"canonical_url":"https://dev.to/daveparr/is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"},"flare_tag":{"name":"help","bg_color_hex":"#ff3232","text_color_hex":"#ffffff"}},{"type_of":"article","id":339873,"title":"Posting
        from .Rmd to dev.to","description":"I’ve started making an R package called
        dev.to.ol. Dev.to has an api which is in beta, which I’m usin...","published":true,"published_at":"2020-05-20T11:37:27.120Z","slug":"posting-from-rmd-to-dev-to-5gld","path":"/daveparr/posting-from-rmd-to-dev-to-5gld","url":"https://dev.to/daveparr/posting-from-rmd-to-dev-to-5gld","comments_count":2,"public_reactions_count":6,"page_views_count":150,"published_timestamp":"2020-05-20T11:37:27Z","body_markdown":"I’ve
        started making an R package called\n[`dev.to.ol`](https://github.com/DaveParr/dev.to.ol).
        Dev.to has an [api\nwhich is in beta](https://docs.dev.to/api/), which I’m
        using to power\nthe package.\n\n## Prototype\n\nThe first function was really
        just to make sure I could use the api at\nall. It gets all the articles for
        the authenticated user. What’s my most\nrecent articles title?\n\n``` r\nlibrary(dev.to.ol)\ndev.to.ol::get_users_articles()[[1]]$title\n```\n\n    ##
        Using DEVTO in .Reinviron\n\n    ## [1] \"Tidy Tuesday and space to learn\"\n\nSo
        how does this function work?\n\n``` r\n#'' @title get the authenticated users
        articles\n#'' @description Provides lots of info on your users articles\n#''
        @param key the api you have set up on DEV.TO\n#'' @return article stuff\n#''
        @details if no key is supplied, will check for key named DEVTO in `.Renviron`\n#''
        @examples\n#'' \\dontrun{\n#'' if(interactive()){\n#''  get_users_articles(\"my_api_key\")\n#''  }\n#''
        }\n#'' @seealso\n#''  \\code{\\link[httr]{content}},\\code{\\link[httr]{GET}},\\code{\\link[httr]{add_headers}}\n#''
        @rdname get_users_articles\n#'' @export\n#'' @importFrom httr content GET
        add_headers\n\nget_users_articles \u003c- function(key = NA) {\n  httr::content(httr::GET(url
        = \"https://dev.to/api/articles/me\",\n                          httr::add_headers(\"api-key\"
        =\n                                              if (!is.na(key)) {\n                                                key\n                                              }
        else {\n                                                message(\"Using DEVTO
        in .Renviron\")\n                                                Sys.getenv(x
        = \"DEVTO\")\n                                              })))\n}\n```\n\nVery
        simply\\!\n\n  - It uses `httr` to do most of the work through a `GET` request.\n  -
        It allows a user to supply their own api key as an argument.\n  - If the user
        has left that argument as the default `NA`, it will use\n    the environmental
        variable named `DEVTO`. This can be set with an\n    `.Renviron` file at the
        project or user level that looks like this:\n\n\u003c!-- end list --\u003e\n\n    DEVTO=\"obviouslynotmyrealkey\"\n\n##
        Motivation\n\nSo as R users, we have a great tool baked into our language:
        rmarkdown.\nI use it for nearly everything. We also have some great tools
        to magnify\nit’s power, such as R Notebooks, blogdown, package down and distill.\nSome
        great R people are making the effort to put content here such as\nJulia Silge
        (@juliasilge) and Colin Fay (@colinfay), though they are\nalready well established
        bloggers, and are publishing from their main\nwebsite through RSS. It’s a
        great solution for them but personally I was\nlooking at dev.to as a great
        way to *not* have to have a whole website.\nSo what do you do if you want
        to publish a blog, but don’t want to\nactually maintain a full website? What
        if you also want to be able to be\npart of the great dev.to community? What
        if you’re both of those things\nand also find you have a large volume of time
        on your hands? You write a\npackage to put `.Rmd`s onto dev.to as simply as
        possible.\n\n## Workflow\n\nMy current process is this:\n\n1.  Write an Rmarkdown\n2.  Render
        to `github_document` style markdown\n3.  Open the markdown file I just made\n4.  Copy
        and paste the output to the dev.to UI\n5.  Fill in the meta-date\n6.  Hit
        publish\n\nAn ideal process would be:\n\n1.  Write an Rmarkdown\n2.  Hit publish\n\nLets
        see, that’s…\n\n``` r\nremoved_work \u003c- 4/6\n\nscales::label_percent()(removed_work)\n```\n\n    ##
        [1] \"67%\"\n\nWow, gains\\!\n\n## Minimum Viable Function\n\nSo, the key
        piece of the package is to get a function that will jump my\nmarkdown output
        from my computer onto dev.to. There are lots more bits\nthat I should have,
        but that part is the most important.\n\n``` r\n#'' @title Post a markdown
        file to dev.to\n#'' @description Create a new post well rendered markdown
        file\n#'' @param key Your API key, Default: NA\n#'' @param file The path to
        the file, Default: file\n#'' @return The response\n#'' @details Will look
        for an api key in the `.REnviron` file. Seems to check if the body is identical
        to a previous article and error if so with `\"Body markdown has already been
        taken\"`.\n#'' @examples\n#'' \\dontrun{\n#'' if(interactive()){\n#''  post_new_article(\"./articles/my_article.md\")\n#''  }\n#''
        }\n#'' @seealso\n#''  \\code{\\link[httr]{POST}},\\code{\\link[httr]{add_headers}},\\code{\\link[httr]{verbose}},\\code{\\link[httr]{content}}\n#''  \\code{\\link[readr]{read_file}}\n#''
        @rdname post_new_article\n#'' @export\n#'' @importFrom httr POST add_headers
        verbose content\n#'' @importFrom readr read_file\n\npost_new_article \u003c-
        function(key = NA, file = file) {\n\n  response \u003c- httr::POST(\n    url
        = \"https://dev.to/api/articles\",\n    httr::add_headers(\"api-key\" =\n                        if
        (!is.na(key)) {\n                          key\n                        }
        else {\n                          message(\"Using DEVTO in .Renviron\")\n                          Sys.getenv(x
        = \"DEVTO\")\n                        }),\n    body = list(article = list(\n      title
        = ''title'',\n      body_markdown = readr::read_file(file = file)\n    )),\n    encode
        = ''json'',\n    httr::verbose()\n  )\n  httr::content(response)\n}\n```\n\nLots
        of similar things as the earlier function. Api key is all the same\ncode (don’t
        worry, when I have to write it a third time, I’ll abstract\nit ;P). There
        are three key changes.\n\n1.  use `httr::POST` instead of `httr::GET` because
        here I’m giving the\n    api info, not requesting it.\n2.  use the `body`
        argument to enclose the info I am sending the api,\n    with a list of 1 item
        `article` which itself is a list of 2 items\n    `title` and `body_markdown`\n3.  use
        `readr::read_file` to read the markdown file I want to post into\n    memory
        so it can be sent to the api\n\n## So does it work?\n\nIf you can read this,
        yes :mechanical\\_arm:\n","positive_reactions_count":6,"cover_image":null,"tag_list":["Rstats","projectbenatar","showdev","markdown"],"canonical_url":"https://dev.to/daveparr/posting-from-rmd-to-dev-to-5gld","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"},"flare_tag":{"name":"showdev","bg_color_hex":"#091b47","text_color_hex":"#b2ffe1"}},{"type_of":"article","id":338914,"title":"Tidy
        Tuesday and space to learn","description":"TidyTusdays are a weekly R Community
        event where people learn about RStats by practising with a diffe...","published":true,"published_at":"2020-05-19T11:55:13.566Z","slug":"tidy-tuesday-and-space-to-learn-162o","path":"/daveparr/tidy-tuesday-and-space-to-learn-162o","url":"https://dev.to/daveparr/tidy-tuesday-and-space-to-learn-162o","comments_count":0,"public_reactions_count":5,"page_views_count":87,"published_timestamp":"2020-05-19T11:55:13Z","body_markdown":"[TidyTusdays](https://github.com/rfordatascience/tidytuesday)
        are a\nweekly R Community event where people learn about RStats by practising\nwith
        a different data set each week. Last week the [Cardiff R User\ngroup](https://www.meetup.com/Cardiff-R-User-Group/)
        worked on the\nvolcanoes data-set :volcano:, and something in it really tripped
        me up.\nWe’ve done this a few times now, and are building up our work in [this\nGitHub
        repo](https://github.com/CaRdiffR/tidy_thursdays).\n\n``` r\nlibrary(tidyverse)\nvolcano
        \u003c- readr::read_csv(''https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/volcano.csv'')\n```\n\n##
        Data structure\n\nLet’s have a look at what the data is\n\n``` r\nvolcano
        %\u003e% \n  str()\n```\n\n    ## tibble [958 × 26] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n    ##  $
        volcano_number          : num [1:958] 283001 355096 342080 213004 321040 ...\n    ##  $
        volcano_name            : chr [1:958] \"Abu\" \"Acamarachi\" \"Acatenango\"
        \"Acigol-Nevsehir\" ...\n    ##  $ primary_volcano_type    : chr [1:958] \"Shield(s)\"
        \"Stratovolcano\" \"Stratovolcano(es)\" \"Caldera\" ...\n    ##  $ last_eruption_year      :
        chr [1:958] \"-6850\" \"Unknown\" \"1972\" \"-2080\" ...\n    ##  $ country                 :
        chr [1:958] \"Japan\" \"Chile\" \"Guatemala\" \"Turkey\" ...\n    ##  $ region                  :
        chr [1:958] \"Japan, Taiwan, Marianas\" \"South America\" \"México and Central
        America\" \"Mediterranean and Western Asia\" ...\n    ##  $ subregion               :
        chr [1:958] \"Honshu\" \"Northern Chile, Bolivia and Argentina\" \"Guatemala\"
        \"Turkey\" ...\n    ##  $ latitude                : num [1:958] 34.5 -23.3
        14.5 38.5 46.2 ...\n    ##  $ longitude               : num [1:958] 131.6
        -67.6 -90.9 34.6 -121.5 ...\n    ##  $ elevation               : num [1:958]
        641 6023 3976 1683 3742 ...\n    ##  $ tectonic_settings       : chr [1:958]
        \"Subduction zone / Continental crust (\u003e25 km)\" \"Subduction zone /
        Continental crust (\u003e25 km)\" \"Subduction zone / Continental crust (\u003e25
        km)\" \"Intraplate / Continental crust (\u003e25 km)\" ...\n    ##  $ evidence_category       :
        chr [1:958] \"Eruption Dated\" \"Evidence Credible\" \"Eruption Observed\"
        \"Eruption Dated\" ...\n    ##  $ major_rock_1            : chr [1:958] \"Andesite
        / Basaltic Andesite\" \"Dacite\" \"Andesite / Basaltic Andesite\" \"Rhyolite\"
        ...\n    ##  $ major_rock_2            : chr [1:958] \"Basalt / Picro-Basalt\"
        \"Andesite / Basaltic Andesite\" \"Dacite\" \"Dacite\" ...\n    ##  $ major_rock_3            :
        chr [1:958] \"Dacite\" \" \" \" \" \"Basalt / Picro-Basalt\" ...\n    ##  $
        major_rock_4            : chr [1:958] \" \" \" \" \" \" \"Andesite / Basaltic
        Andesite\" ...\n    ##  $ major_rock_5            : chr [1:958] \" \" \" \"
        \" \" \" \" ...\n    ##  $ minor_rock_1            : chr [1:958] \" \" \" \"
        \"Basalt / Picro-Basalt\" \" \" ...\n    ##  $ minor_rock_2            : chr
        [1:958] \" \" \" \" \" \" \" \" ...\n    ##  $ minor_rock_3            : chr
        [1:958] \" \" \" \" \" \" \" \" ...\n    ##  $ minor_rock_4            : chr
        [1:958] \" \" \" \" \" \" \" \" ...\n    ##  $ minor_rock_5            : chr
        [1:958] \" \" \" \" \" \" \" \" ...\n    ##  $ population_within_5_km  : num
        [1:958] 3597 0 4329 127863 0 ...\n    ##  $ population_within_10_km : num
        [1:958] 9594 7 60730 127863 70 ...\n    ##  $ population_within_30_km : num
        [1:958] 117805 294 1042836 218469 4019 ...\n    ##  $ population_within_100_km:
        num [1:958] 4071152 9092 7634778 2253483 393303 ...\n    ##  - attr(*, \"spec\")=\n    ##   ..
        cols(\n    ##   ..   volcano_number = col_double(),\n    ##   ..   volcano_name
        = col_character(),\n    ##   ..   primary_volcano_type = col_character(),\n    ##   ..   last_eruption_year
        = col_character(),\n    ##   ..   country = col_character(),\n    ##   ..   region
        = col_character(),\n    ##   ..   subregion = col_character(),\n    ##   ..   latitude
        = col_double(),\n    ##   ..   longitude = col_double(),\n    ##   ..   elevation
        = col_double(),\n    ##   ..   tectonic_settings = col_character(),\n    ##   ..   evidence_category
        = col_character(),\n    ##   ..   major_rock_1 = col_character(),\n    ##   ..   major_rock_2
        = col_character(),\n    ##   ..   major_rock_3 = col_character(),\n    ##   ..   major_rock_4
        = col_character(),\n    ##   ..   major_rock_5 = col_character(),\n    ##   ..   minor_rock_1
        = col_character(),\n    ##   ..   minor_rock_2 = col_character(),\n    ##   ..   minor_rock_3
        = col_character(),\n    ##   ..   minor_rock_4 = col_character(),\n    ##   ..   minor_rock_5
        = col_character(),\n    ##   ..   population_within_5_km = col_double(),\n    ##   ..   population_within_10_km
        = col_double(),\n    ##   ..   population_within_30_km = col_double(),\n    ##   ..   population_within_100_km
        = col_double()\n    ##   .. )\n\n## Objective\n\nLots of character columns,
        and some with some slightly funky formatting,\nsuch as `/` and variations
        on a theme with `(s)` and `(es)`. We’ve also\ngot a bunch of ‘sparse’ data
        in the columns that start with `major_rock`\nor `minor_rock` that look like
        spaces. R has a rich set of tools for\ndealing with missing data a little
        more effectively, so lets\nclean this up by setting the missing data to be
        explicit `NA`. In this\ncase, as the column is a character type, we need to
        `NA_character` to\nfill it up.\n\n## Failing solution\n\n``` r\nvolcano %\u003e%\n    mutate_at(\n    .vars
        = vars(starts_with(c(\"major_rock\", \"minor_rock\"))),\n    .funs = ~ case_when(\n      .
        == \" \" ~ NA_character_,\n      TRUE ~ .\n    )\n  ) %\u003e% \n  select(starts_with(c(\"major_rock\",
        \"minor_rock\"))) %\u003e% \n  head() %\u003e% \n  knitr::kable()\n```\n\n|
        major\\_rock\\_1               | major\\_rock\\_2               | major\\_rock\\_3        |
        major\\_rock\\_4               | major\\_rock\\_5 | minor\\_rock\\_1        |
        minor\\_rock\\_2        | minor\\_rock\\_3 | minor\\_rock\\_4 | minor\\_rock\\_5
        |\n| :--------------------------- | :--------------------------- | :--------------------
        | :--------------------------- | :------------- | :-------------------- |
        :-------------------- | :------------- | :------------- | :------------- |\n|
        Andesite / Basaltic Andesite | Basalt / Picro-Basalt        | Dacite                |                              |                |                       |                       |                |                |                |\n|
        Dacite                       | Andesite / Basaltic Andesite |                       |                              |                |                       |                       |                |                |                |\n|
        Andesite / Basaltic Andesite | Dacite                       |                       |                              |                |
        Basalt / Picro-Basalt |                       |                |                |                |\n|
        Rhyolite                     | Dacite                       | Basalt / Picro-Basalt
        | Andesite / Basaltic Andesite |                |                       |                       |                |                |                |\n|
        Andesite / Basaltic Andesite | Basalt / Picro-Basalt        |                       |                              |                |
        Dacite                |                       |                |                |                |\n|
        Andesite / Basaltic Andesite |                              |                       |                              |                |
        Dacite                | Basalt / Picro-Basalt |                |                |                |\n\nWell,
        that doesn’t quite work. What I want is to have the blank spots\nfilled up
        with `NA`. Is it my code? It’s not the most basic solution,\nusing some of
        the tidyeval concepts such as `vars` and `funs`. Lets make\nit as simple as
        possible.\n\n``` r\nvolcano %\u003e% \n  filter(major_rock_5 == \" \") %\u003e%
        \n  knitr::kable()\n```\n\n| volcano\\_number | volcano\\_name | primary\\_volcano\\_type
        | last\\_eruption\\_year | country | region | subregion | latitude | longitude
        | elevation | tectonic\\_settings | evidence\\_category | major\\_rock\\_1
        | major\\_rock\\_2 | major\\_rock\\_3 | major\\_rock\\_4 | major\\_rock\\_5
        | minor\\_rock\\_1 | minor\\_rock\\_2 | minor\\_rock\\_3 | minor\\_rock\\_4
        | minor\\_rock\\_5 | population\\_within\\_5\\_km | population\\_within\\_10\\_km
        | population\\_within\\_30\\_km | population\\_within\\_100\\_km |\n| --------------:
        | :------------ | :--------------------- | :------------------- | :------
        | :----- | :-------- | -------: | --------: | --------: | :-----------------
        | :----------------- | :------------- | :------------- | :------------- |
        :------------- | :------------- | :------------- | :------------- | :-------------
        | :------------- | :------------- | ------------------------: | -------------------------:
        | -------------------------: | --------------------------: |\n\nOdd. I can’t
        find any values that are just spaces, even though they are\nprinted out that
        way\\! I know they are there, I can see them\\! Luckily,\nthe point of these
        projects is to learn, and to learn from each other in\nthe group :school:.\n\n##
        Problem\n\nMy buddy [Heather](https://twitter.com/HeathrTurnr) was I think
        a little\nsurprised when I demonstrated this, but within a few minutes she’d\nworked
        it out. It’s encoded as a *non\\_breaking space*. She linked this\nblog in
        our chat about [non-braking\nspaces](https://blog.tonytsai.name/blog/2017-12-04-detecting-non-breaking-space-in-r/)\nand
        offered us the cryptic solution:\n\n    \"\\u00A0\"\n\nThe blog goes into
        detail about what this is but the tl;dr is: “It looks\nlike a space but it’s
        not and it’s [designed that\nway](https://en.wikipedia.org/wiki/Non-breaking_space)”.\n\nSo
        a quick tweak to the code and…\n\n## Functional solution\n\n``` r\nvolcano
        %\u003e%\n    mutate_at(\n    .vars = vars(starts_with(c(\"major_rock\", \"minor_rock\"))),\n    .funs
        = ~ case_when(\n      . == \"\\u00A0\" ~ NA_character_,\n      TRUE ~ .\n    )\n  )
        %\u003e% \n  select(starts_with(c(\"major_rock\", \"minor_rock\"))) %\u003e%
        \n  head() %\u003e% \n  knitr::kable()\n```\n\n| major\\_rock\\_1               |
        major\\_rock\\_2               | major\\_rock\\_3        | major\\_rock\\_4               |
        major\\_rock\\_5 | minor\\_rock\\_1        | minor\\_rock\\_2        | minor\\_rock\\_3
        | minor\\_rock\\_4 | minor\\_rock\\_5 |\n| :--------------------------- |
        :--------------------------- | :-------------------- | :---------------------------
        | :------------- | :-------------------- | :-------------------- | :-------------
        | :------------- | :------------- |\n| Andesite / Basaltic Andesite | Basalt
        / Picro-Basalt        | Dacite                | NA                           |
        NA             | NA                    | NA                    | NA             |
        NA             | NA             |\n| Dacite                       | Andesite
        / Basaltic Andesite | NA                    | NA                           |
        NA             | NA                    | NA                    | NA             |
        NA             | NA             |\n| Andesite / Basaltic Andesite | Dacite                       |
        NA                    | NA                           | NA             | Basalt
        / Picro-Basalt | NA                    | NA             | NA             |
        NA             |\n| Rhyolite                     | Dacite                       |
        Basalt / Picro-Basalt | Andesite / Basaltic Andesite | NA             | NA                    |
        NA                    | NA             | NA             | NA             |\n|
        Andesite / Basaltic Andesite | Basalt / Picro-Basalt        | NA                    |
        NA                           | NA             | Dacite                | NA                    |
        NA             | NA             | NA             |\n| Andesite / Basaltic
        Andesite | NA                           | NA                    | NA                           |
        NA             | Dacite                | Basalt / Picro-Basalt | NA             |
        NA             | NA             |\n\n## Full solution\n\nSuccess\\! After
        digging around a little, I discovered `str_trim` and\n`str_squish` can be
        used for this as well to make a perfectly tidy\nsolution\\!\n\n``` r\nvolcano
        %\u003e%\n    mutate_at(\n    .vars = vars(starts_with(c(\"major_rock\", \"minor_rock\"))),\n    .funs
        = ~ case_when(\n      str_trim(.) == \"\" ~ NA_character_,\n      TRUE ~ .\n    )\n  )
        %\u003e% \n  select(starts_with(c(\"major_rock\", \"minor_rock\"))) %\u003e%
        \n  head() %\u003e% \n  knitr::kable()\n```\n\n| major\\_rock\\_1               |
        major\\_rock\\_2               | major\\_rock\\_3        | major\\_rock\\_4               |
        major\\_rock\\_5 | minor\\_rock\\_1        | minor\\_rock\\_2        | minor\\_rock\\_3
        | minor\\_rock\\_4 | minor\\_rock\\_5 |\n| :--------------------------- |
        :--------------------------- | :-------------------- | :---------------------------
        | :------------- | :-------------------- | :-------------------- | :-------------
        | :------------- | :------------- |\n| Andesite / Basaltic Andesite | Basalt
        / Picro-Basalt        | Dacite                | NA                           |
        NA             | NA                    | NA                    | NA             |
        NA             | NA             |\n| Dacite                       | Andesite
        / Basaltic Andesite | NA                    | NA                           |
        NA             | NA                    | NA                    | NA             |
        NA             | NA             |\n| Andesite / Basaltic Andesite | Dacite                       |
        NA                    | NA                           | NA             | Basalt
        / Picro-Basalt | NA                    | NA             | NA             |
        NA             |\n| Rhyolite                     | Dacite                       |
        Basalt / Picro-Basalt | Andesite / Basaltic Andesite | NA             | NA                    |
        NA                    | NA             | NA             | NA             |\n|
        Andesite / Basaltic Andesite | Basalt / Picro-Basalt        | NA                    |
        NA                           | NA             | Dacite                | NA                    |
        NA             | NA             | NA             |\n| Andesite / Basaltic
        Andesite | NA                           | NA                    | NA                           |
        NA             | Dacite                | Basalt / Picro-Basalt | NA             |
        NA             | NA             |\n\nLet’s try and breakdown what is happening
        in this solution by concept,\nand then outline the routine in human language
        to finish.\n\n## Concepts\n\n### Non-breaking spaces\n\n  - the ‘missing’
        values are not real spaces, they are *non-breaking\n    spaces*.\n  - [`stringr::str_trim`](https://stringr.tidyverse.org/reference/str_trim.html)\n    and
        `stringr::str_squish` removes space from either the ends or all\n    the way
        through a character string depending on what else is\n    happening in the
        string and what you need from the solution.\n  - [`mutate_at`](https://dplyr.tidyverse.org/reference/mutate_all.html)\n    is
        a buddy of `mutate`, where you use *functional programming* style\n    to
        apply a function over a collection of columns.\n  - this means that for the
        context of evaluation, we will be getting\n    `\"\"`, where as previously
        we were seeing `\" \"` which was actually\n    encoded as `\"\\u00A0\"`\n\n###
        Variable selection\n\n  - [`starts_with`](https://dplyr.tidyverse.org/reference/select.html#useful-functions)\n    is
        a select helper that is designed for cases when a related value\n    is stretch
        wide across multiple columns with similar names, and\n    returns a vector
        of column names filtered to your criteria.\n  - [`vars`](https://dplyr.tidyverse.org/reference/vars.html)\n    automatically
        *quotes* the names of the columns to *evaluate* later\n    in context and
        is almost always used as a wrapper to the `.var =`\n    argument when it’s
        supported by a function.\n  - this means that we will be doing on operation
        on each of the columns\n    selected.\n\n### Formula function\n\n  - `.funs
        =` argument, like `.var =`, has a counterpart\n    [`funs()`](https://dplyr.tidyverse.org/reference/funs.html),
        but\n    this is being deprecated in favour of the *expression notation*.\n  -
        [`case_when`](https://dplyr.tidyverse.org/reference/case_when.html)\n    is
        an alternative version of the more common `if else` operation.\n  - `~` is
        a special operator that is key to the expression notation. It\n    effectively
        separates the Left Hand Side (LHS) of an expression from\n    the Right Hand
        Side (RHS). It’s used in two ways in this code.\n    `case_when` uses full
        expressions to represent what should happen on\n    the RHS when the criteria
        of the LHS is met. `.funs =` uses it to\n    make a lambda style formula.
        This is sometimes referred to as a\n    [*quosure*](https://dplyr.tidyverse.org/articles/programming.html#quoting).\n  -
        `.` is also a special operator, and I recommend reading the\n    [documentation
        of\n    pipe](https://magrittr.tidyverse.org/reference/pipe.html) `%\u003e%`.
        The\n    idea of it here is to reference the data being operated on itself.\n    In
        this specific case, it’s each value from each of the selected\n    columns
        for equivalence to an empty space.\n\n## Step-by-step\n\nDid you follow all
        that? It’s a minefield I know, but it allows us to do\nsomething very powerful
        in only a few lines. As an alternative way of\nunderstanding what this does,
        here’s the step by step:\n\n1)  Get all the columns that start with either
        `\"major_rock''` or\n    `\"minor_rock\"`\n2)  For each of the those columns
        trim any value at the start or end\n    that is whitespace, including non-breaking
        white space temporarily,\n    without modifying the underlying data\n3)  If
        the value after that is an empty string, replace it in the same\n    column
        with the `NA` value for characters\n4)  If the value after does not pass that
        test, use the original value\n\nSo do you *have to* program this way? No,
        not really. You could manually\ncreate the list of columns you want to modify,
        but that would be prone\nto human error and what if you end up with `\"minor_rock_6\"`
        or\n`\"major_rock_100\"`? You could always make a traditional `if else`\nstructure,
        but that can get long fast if there are multiple conditions\nto check for.
        How about using the character string `\"\\u00A0\"` to test\nfor equivalence?
        Well, that would work now, but how do you pick up if\nthey change suddenly
        to actual spaces? Or another whitespace encoding?\nProgramming like this keeps
        code readable, maintainable, and robust.\n\nIs this overkill for tidy Tuesdays?
        Yes, absolutely. Are the problems\nthat you solve with this approach purely
        academic? No, not at all. Plus,\ndoing all that work in 129 characters is
        pretty neat. Excluding spaces.","positive_reactions_count":5,"cover_image":null,"tag_list":["RStats","tidyverse","tidytuesday"],"canonical_url":"https://dev.to/daveparr/tidy-tuesday-and-space-to-learn-162o","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}},{"type_of":"article","id":334065,"title":"Is
        there a good way to post from .Rmd to dev.to yet?","description":"I know we
        have blogdown and distill, which are great for hosting whole sites. We also
        have the github...","published":true,"published_at":"2020-05-13T12:05:26.081Z","slug":"is-there-a-good-way-to-post-from-rmd-to-dev-to-yet-4c9","path":"/daveparr/is-there-a-good-way-to-post-from-rmd-to-dev-to-yet-4c9","url":"https://dev.to/daveparr/is-there-a-good-way-to-post-from-rmd-to-dev-to-yet-4c9","comments_count":1,"public_reactions_count":1,"page_views_count":41,"published_timestamp":"2020-05-13T12:05:26Z","body_markdown":"I
        know we have `blogdown` and `distill`, which are great for hosting whole sites.
        We also have the `github_document` output from `knitr`, which is ok, but a
        little manual to get something up on the site.\n\nDoes anyone know if there
        is any work being done to publish more effectively to dev.to, or something
        that I might have missed that is well known?","positive_reactions_count":1,"cover_image":null,"tag_list":["Rstats","question","devto","blogging"],"canonical_url":"https://dev.to/daveparr/is-there-a-good-way-to-post-from-rmd-to-dev-to-yet-4c9","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}},{"type_of":"article","id":334055,"title":"Pocket
        Monster BMI","description":"library(pokedex) library(tidyverse) library(knitr)              How
        big is a Pocket Monster?   Pokemo...","published":true,"published_at":"2020-05-13T11:55:29.276Z","slug":"pocket-monster-bmi-1ao0","path":"/daveparr/pocket-monster-bmi-1ao0","url":"https://dev.to/daveparr/pocket-monster-bmi-1ao0","comments_count":0,"public_reactions_count":4,"page_views_count":63,"published_timestamp":"2020-05-13T11:55:29Z","body_markdown":"```
        r\nlibrary(pokedex)\nlibrary(tidyverse)\nlibrary(knitr)\n```\n\n# How big
        is a Pocket Monster?\n\nPokemon is a combination of ‘Pocket’ and ‘Monster’.
        So they’re all\npretty small right? Not quite.\n\n``` r\nscale_format \u003c-
        scales::number_format(accuracy = 1, big.mark = \",\")\n\npokemon %\u003e%\n  ggplot(aes(x
        = height, y = weight)) +\n  geom_point() +\n  scale_y_continuous(labels =
        scale_format) + \n  labs(title = \"Height and Weight of Pocket Monsters\",\n       x
        = \"Height (m)\",\n       y = \"Weight (kg)\")\n```\n\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/ma2yfumh5qno7716asn6.png)\n\nMaybe
        we need to work on this graph a little. Let''s make it log scaled on\nboth
        axis. I’ll put myself in for reference too.\n\n``` r\npokemon %\u003e%\n  ggplot(aes(x
        = height, y = weight)) +\n  geom_point() +\n  geom_vline(xintercept = 1.7)
        +\n  geom_hline(yintercept = 72) +\n  labs(title = \"Height and Weight of
        Pocket Monsters\",\n       subtitle = \"Trainer Daves''s height and weight
        for reference\",\n       x = \"Height (m)\",\n       y = \"Weight (kg)\",\n       caption
        = \"Log X and Y Scale\") +\n  scale_x_log10() +\n  scale_y_log10(labels =
        scale_format)\n```\n\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/0rvxuys3lh1jwiggs95v.png)\n\nSo
        after a log transform of the scales we have a (roughly) linear\nrelationship.
        This is what we would expect in real world data. Nothing\nwith a physical
        existence can have a 0 or negative measure for these\nfeatures. Therefore,
        thinking of this in terms of average can be\nmisleading. It will always be
        ‘long tailed’. It might be a stretch to\nrefer to them all as Pocket Monsters
        though.\n\nThere’s also clearly a relationship between both height and weight.\nLet’s
        try and capture this in a single feature.\n\n# BMI\n\nThe body mass index
        is a simple metric to link height and weight. Let’s\ncreate it for our Pokemon.\n\n```
        r\nBMI \u003c- function(weight, height) {\n  weight/(height^2)\n}\n\npokemon
        %\u003e% \n  mutate(BMI = BMI(weight = weight, height = height)) -\u003e pokemon\n\npokemon
        %\u003e% \n  ggplot(aes(x = BMI)) +\n  geom_histogram() +\n  labs(title =
        \"BMI of Pocket Monsters\")\n```\n\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/wc0wmg7bis190lc4gqcy.png)\n\nWell,
        that’s something of a surprise. Looking at the scatter plots from\nearlier,
        there is something in the data set that is very small, but also\n*extremely*
        heavy. Let’s try and work out what that is.\n\n``` r\npokemon %\u003e% \n  arrange(desc(BMI))
        %\u003e% \n  select(name, height, weight, BMI, genus) %\u003e% \n  top_n(10,
        BMI) %\u003e% \n  kable()\n```\n\n| name      | height | weight |        BMI
        | genus              |\n| :-------- | -----: | -----: | ---------: | :-----------------
        |\n| Cosmoem   |    0.1 |  999.9 | 99990.0000 | Protostar Pokémon  |\n| Minior    |    0.3
        |   40.0 |   444.4444 | Meteor Pokémon     |\n| Aron      |    0.4 |   60.0
        |   375.0000 | Iron Armor Pokémon |\n| Durant    |    0.3 |   33.0 |   366.6667
        | Iron Ant Pokémon   |\n| Clamperl  |    0.4 |   52.5 |   328.1250 | Bivalve
        Pokémon    |\n| Torkoal   |    0.5 |   80.4 |   321.6000 | Coal Pokémon       |\n|
        Cacnea    |    0.4 |   51.3 |   320.6250 | Cactus Pokémon     |\n| Munchlax  |    0.6
        |  105.0 |   291.6667 | Big Eater Pokémon  |\n| Sandygast |    0.5 |   70.0
        |   280.0000 | Sand Heap Pokémon  |\n| Beldum    |    0.6 |   95.2 |   264.4444
        | Iron Ball Pokémon  |\n\nThere’s no accounting for cosmological battle entities.
        I’m going to\nclaim that the Protostar Pokemon is a little out of scope for
        this and\nfilter it out. Let’s have a look at what we’re left with.\n\n```
        r\nDave_BMI \u003c- BMI(weight = 72,  height = 1.70)\n\npokemon %\u003e% \n  filter(name
        != \"Cosmoem\")%\u003e% \n  ggplot(aes(x = BMI)) +\n  geom_histogram() +\n  geom_vline(xintercept
        = Dave_BMI) + \n  labs(title = \"BMI of Pocket Monsters\",\n       subtitle
        = \"Trainer Dave''s BMI for reference\",\n       caption = \"Cosmoem removed\")\n```\n\n![Alt
        Text](https://dev-to-uploads.s3.amazonaws.com/i/kj2y0tn7o91vny08qggf.png)\n\nSo
        most Pokemon are actually a little bigger than me, and a few of them\nare
        a lot bigger\\!\nWe’ve also realised that some of them might just be very
        different to\nme, like stars, made entirely of metal or rock, or maybe even
        giant\ndragons? Just like in the earlier article, I’m going to pivot the data\nso
        we get a comparison for dual type Pokemon on both their types.\n\n``` r\npokemon
        %\u003e%\n  filter(name != \"Cosmoem\") %\u003e% \n  select(name, type_1,
        type_2, BMI, height, weight) %\u003e%\n  pivot_longer(\n    cols = starts_with(\"type\"),\n    names_to
        = \"slot\",\n    values_to = \"type\",\n    values_drop_na = TRUE\n  ) %\u003e%
        \n  ggplot(aes(x = BMI)) +\n  geom_density() + \n  geom_vline(xintercept =
        Dave_BMI) + \n  facet_wrap(. ~ type, scales = \"free\") +\n  labs(title =
        \"Pocket Monster BMI by type\",\n       subtitle = \"Trainer Dave''s BMI for
        reference\",\n       caption = \"Cosmoem removed\")\n```\n\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/yus2sxt4ss54olz64zii.png)\n\nSo
        it looks like I’m not quite as hefty as Pokemon that are rock, steel,\nice,
        ground, fighting, dark or dragon. That makes sense. I’m also a bit\nmore corporeal
        than fairy or ghost type. Pokemon has some really big\nbugs though\\!\n\n#
        Game Over\n\nWe’ve learned quite a few R programming things today. The most
        obvious\nwere some `ggplot` chart tools:\n\n  - `geom_vline()` and `geom_hline()`
        make 1 dimensional lines at\n    specific points\n  - `geom_histogram()` and
        `geom_density()` show the distribution of a\n    single value across mutiple
        observations\n  - `facet_wrap()` can make grouped charts, which are often
        known as\n    *small multiples*\n  - `scale_x_log10()` and `scale_y_log10`
        is an easy way to plot a log\n    axis\n  - the `scales` package is also useful
        for formatting the axis labels\n\nDid you also notice the first thing we did
        with the `scales` package? In\nR you can assign a *function* to a reference.
        This means that we don’t\nneed to repeat ourselves if we want to set it up
        with the same arguments\nmultiple times, like with formatting axis with large
        numbers.\n\nIn the `tidyverse` world we also used the optional arguments in\n`pivot_longer()`
        to select 2 columns to pivot on, and to drop rows we\ncreate that have `NA`
        when the Pokemon only has 1 type.\n\nMost importantly though, we created our
        own function, and it was easy\\!\nThe `BMI` function we created we used to
        make a single value,\n`Dave_BMI`, but also to make the whole `BMI` column
        for each Pokemon in\nthe data set\\! That’s pretty cool.\n\nFrom 2 known features,
        `weight` and `height` we made one single new\nmeasurement `BMI`. This an example
        of something that will come up more\nin later posts about machine learning
        which is called ‘feature\nengineering’.\n\nThe next article will be going
        into how the Pokedex package is actually\nmade, both in trying to design a
        ‘tidy’ data set, but also how to make a\npackage in R\\!\n\nP.S. I know that
        `Pocket Monster` is related to the pokeballs they fit in, but that''s a less
        fun title.","positive_reactions_count":4,"cover_image":null,"tag_list":["Rstats","tidyverse","pokemon","functional"],"canonical_url":"https://dev.to/daveparr/pocket-monster-bmi-1ao0","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}},{"type_of":"article","id":331136,"title":"Introducing
        the Pokedex package!","description":"I made an R data package to make Pokemon
        data more usable in R!   library(pokedex) library(tidyverse)...","published":true,"published_at":"2020-05-09T17:03:18.022Z","slug":"introducing-the-pokedex-package-5416","path":"/daveparr/introducing-the-pokedex-package-5416","url":"https://dev.to/daveparr/introducing-the-pokedex-package-5416","comments_count":0,"public_reactions_count":6,"page_views_count":139,"published_timestamp":"2020-05-09T17:03:18Z","body_markdown":"I
        made an R data package to make Pokemon data more usable in R\\!\n\n``` r\nlibrary(pokedex)\nlibrary(tidyverse)\nlibrary(knitr)\n```\n\n#
        How many Pokemon in the package?\n\nI’ve tried to make the data set ‘tidy’
        from the start, so we can use\n`summarise` to count them, and `kable` to make
        some dev.to friendly\nmarkdown tables.\n\n``` r\npokemon %\u003e% \n  summarise(count
        = n()) %\u003e% \n  kable()\n```\n\n| count |\n| ----: |\n|   807 |\n\n# Types\n\nTypes
        are pretty key to Pokemon. Lets have a quick look at the Kanto\nstarters and
        types.\n\n``` r\npokemon %\u003e% \n  top_n(n = -9, wt = species_id) %\u003e%
        \n  select(identifier, type_1, type_2) %\u003e%\n  kable()\n```\n\n| identifier
        | type\\_1 | type\\_2 |\n| :--------- | :------ | :------ |\n| bulbasaur  |
        grass   | poison  |\n| ivysaur    | grass   | poison  |\n| venusaur   | grass   |
        poison  |\n| charmander | fire    | NA      |\n| charmeleon | fire    | NA      |\n|
        charizard  | fire    | flying  |\n| squirtle   | water   | NA      |\n| wartortle  |
        water   | NA      |\n| blastoise  | water   | NA      |\n\n# Single and dual
        types\n\nSo Pokemon can have either 1 or 2 types. What’s the split between
        single\ntype and dual type Pokemon?\n\n``` r\npokemon %\u003e%\n  mutate(dual_type
        = case_when(is.na(type_2) ~ TRUE,\n                               TRUE ~ FALSE))
        %\u003e%\n  group_by(dual_type) %\u003e%\n  summarise(count = n()) %\u003e%
        \n  kable()\n```\n\n| dual\\_type | count |\n| :--------- | ----: |\n| FALSE      |   405
        |\n| TRUE       |   402 |\n\nSo, it’s nearly a 50:50 split of Pokemon that
        are single type to Pokemon\nthat have 2 types.\n\n# How many by type?\n\nBut
        there are also quite a few types of Pokemon. Starting with the\nprimary type,
        lets make a quick chart to understand the distribution of\nprimary types.
        Using `group_by` will mean the `summarise` gets\ncalculated *per group*. We
        can then pipe directly into `ggplot` for a\ncol chart with `geom_col`.\n\n```
        r\npokemon %\u003e%\n  group_by(type_1) %\u003e%\n  summarise(count = n())
        %\u003e%\n  ggplot(aes(x = type_1, y = count)) +\n  geom_col() +\n  labs(title
        = \"Pokemon by primary type\")\n```\n\n![Pokemon by primary type](https://dev-to-uploads.s3.amazonaws.com/i/v9nfgl5rwqt0zp18i44s.png)\n\nLots
        of water type Pokemon, and lots of normal type Pokemon, but very\nfew flying
        types. Interesting. How about the secondary types?\n\n``` r\npokemon %\u003e%
        \n  filter(!is.na(type_2)) %\u003e% \n  group_by(type_2) %\u003e% \n  summarise(count
        = n()) %\u003e% \n  ggplot(aes(x = type_2, y = count)) +\n  geom_col() +\n  labs(title
        = \"Pokemon by secondary type\",\n       caption = \"For Pokemon with dual
        type\")\n```\n\n![Pokemon by secondary type](https://dev-to-uploads.s3.amazonaws.com/i/7r4iuz9whihop7b5cjrh.png)\n\nLook
        at all those ’mons with flying as a secondary type\\! The thing is\nthat,
        game-wise, the *order* of the typing doesn’t matter. We can easily\ncount
        the occurrence of a specific type in either primary or secondary\nposition
        with `pivot_longer`.\n\n`pivot_longer` is actually a newer tidyverse function.
        It is\ncomplemented with `pivot_wider` and this pair are intended to eventually\nreplace
        `spread` and `gather`. By filtering out the `NA` I remove any\nobservations
        of secondary types for Pokemon that don’t actually have\nthem.\n\n``` r\npokemon
        %\u003e% \n  select(identifier, type_1, type_2) %\u003e% \n  pivot_longer(-identifier,
        names_to = \"slot\", values_to = \"type\") %\u003e% \n  group_by(type) %\u003e%
        \n  summarise(count = n()) %\u003e% \n  filter(!is.na(type)) %\u003e% \n  ggplot(aes(x
        = type, y = count)) +\n  geom_col() +\n  labs(title = \"Pokemon by either
        type\",\n       caption = \"This will count a dual type Pokemon twice,\\nonce
        for each type\")\n```\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/v5uh6xygkrq7rjikajce.png)\n\nSo
        is there any consistency in order at all?\n\n``` r\npokemon %\u003e%\n  filter((type_1
        == \"ghost\" \u0026 type_2 == \"fire\") |\n           (type_1 == \"fire\"
        \u0026 type_2 == \"ghost\")) %\u003e% \n  select(identifier, type_1, type_2)\n```\n\n    ##
        # A tibble: 4 x 3\n    ##   identifier  type_1 type_2\n    ##   \u003cchr\u003e       \u003cchr\u003e  \u003cchr\u003e
        \n    ## 1 litwick     ghost  fire  \n    ## 2 lampent     ghost  fire  \n    ##
        3 chandelure  ghost  fire  \n    ## 4 blacephalon fire   ghost\n\nIt doesn’t
        look like it. a `ghost fire` Pokemon and a `fire ghost`\nPokemon both turn
        up. I’d like to see what the coincidence rate is of\neach type in dual type
        Pokemon, so I need to get some ordering in. I can\nuse `case_when` in `mutate`
        to create a two new columns in the data. I\ncan make 2 in one call because
        `mutate` supports multiple *expressions*,\neach of which names a column, and
        then operates conditionally on the\nother 2 type columns. These new columns
        will:\n\n  - always have a value in the column `type_1_ordered`\n  - if the
        Pokemon is dual type, have a value in `type_2_ordered`\n  - always have the
        types alphabetically ordered between the two\n    columns. i.e. it will always
        be `fire, ghost`, never `ghost, fire`.\n\n\u003c!-- end list --\u003e\n\n```
        r\npokemon %\u003e%\n  mutate(\n    type_1_ordered = case_when(is.na(type_2)
        ~ type_1,\n                               type_1 \u003c type_2 ~ type_1,\n                               TRUE
        ~ type_2),\n    type_2_ordered = case_when(type_1 \u003e type_2 ~ type_1,\n                               TRUE
        ~ type_2)\n  ) -\u003e pokemon\n```\n\nWhat might the distribution be of the
        flying secondary type, per primary\ntype?\n\n``` r\npokemon %\u003e%\n  mutate(type_combined
        = case_when(\n    !is.na(type_2_ordered) ~ paste(type_1_ordered, type_2_ordered),\n    is.na(type_2_ordered)
        ~ type_1_ordered\n  )) %\u003e%\n  group_by(type_combined) %\u003e%\n  summarise(count
        = n()) %\u003e%\n  arrange(desc(count)) %\u003e%\n  mutate(type_combined =
        as_factor(type_combined)) %\u003e%\n  ggplot(aes(x = type_combined, y = count))
        +\n  geom_col() +\n  labs(title = \"Count of Pokemon by dual type\",\n       caption
        = \"Ordered by count\") + \n  theme(axis.text.x = element_text(angle = 90))\n```\n\n![Alt
        Text](https://dev-to-uploads.s3.amazonaws.com/i/fz5flcvh8dbtfh3zvh9s.png)\n\nSo
        the most often occurring dual type is flying normal. That explains\nthe first
        2 charts. It’s a bit tricky to see the rest though. Lets make\na more useful
        plot.\n\n``` r\npokemon %\u003e% \n  group_by(type_1_ordered, type_2_ordered)
        %\u003e% \n  filter(!is.na(type_2_ordered)) %\u003e% \n  summarise(count =
        n()) %\u003e% \n  ggplot(aes(x = type_1_ordered, y = type_2_ordered, size
        = count)) +\n  geom_point() +\n  labs(title = \"Coincidence of a particular
        dual type\")\n```\n\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/v6qbe0h2nh6n4vz4bnmz.png)\n\nSo
        `flying normal` has the biggest count, with there being quite a few\n`bug
        flying`. That makes sense, as so many bug Pokemon have wings\\!\nThere are
        also lot’s of `bug poison` and `grass poison`. That makes\nsense too, as so
        many bugs and plants are poisonous\\! How many Pokemon\nhave unique types
        though?\n\n``` r\npokemon %\u003e% \n  group_by(type_1_ordered, type_2_ordered)
        %\u003e% \n  filter(!is.na(type_2_ordered)) %\u003e% \n  summarise(count =
        n()) %\u003e% \n  filter(count == 1) %\u003e% \n  ungroup() %\u003e% \n  summarise(count
        = n()) %\u003e% \n  kable()\n```\n\n| count |\n| ----: |\n|    24 |\n\n24
        Pokemon have unique dual types. Out of 807 that isn’t very many\\!\nMaybe
        these Pokemon might be particularly useful? I’ll try and work it\nout…\n\n#
        Game Over\n\nThis post has been a simple example of both the data in the package,
        but\nalso the `tidyverse` methods of doing Exploratory Data Analysis. You
        can\nfind out more about tidyverse [here](https://www.tidyverse.org/)\n\nI
        got the raw data from [this repo by\nveekun](https://github.com/veekun/pokedex).
        My package is available\n[here](https://github.com/DaveParr/pokedex), and
        the particular version\nI used for this post is\n[here](https://github.com/DaveParr/pokedex/commit/67638e8bc52d58bb0c38534b7c2acc9a78b42053).\nThough
        it’s in a pretty raw state, I hope to improve over time.\n\nI made this package
        to have a bigish, diverse set of data to play with,\nthat lots of people recognise,
        and that has some inherent real world\napplication. Pokemon is a huge franchise
        with multiple instalments. Lots\nof people have played it, and even if you
        haven’t you probably have an\nintuition about what a Pokemon is, and what
        data about a Pokemon might\nmake sense, and mean in context with other Pokemon.
        Feel free to fork\nand mess around with as you like. I hope its fun, and maybe
        even\nuseful\\!\n","positive_reactions_count":6,"cover_image":null,"tag_list":["R","Pokemon","tidyverse","RStats"],"canonical_url":"https://dev.to/daveparr/introducing-the-pokedex-package-5416","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}},{"type_of":"article","id":235676,"title":"Local
        gitlab runners, ''no such image'', docker and disk space","description":"Davids-MacBook-Pro:data-science
        davidparr$ gitlab-runner exec docker ''anomaly detection'' Runtime plat...","published":true,"published_at":"2020-01-10T13:08:31.863Z","slug":"gotcha-local-gitlab-runners-no-such-image-docker-and-disk-space-7ei","path":"/daveparr/gotcha-local-gitlab-runners-no-such-image-docker-and-disk-space-7ei","url":"https://dev.to/daveparr/gotcha-local-gitlab-runners-no-such-image-docker-and-disk-space-7ei","comments_count":0,"public_reactions_count":9,"page_views_count":376,"published_timestamp":"2020-01-10T13:08:31Z","body_markdown":"```\nDavids-MacBook-Pro:data-science
        davidparr$ gitlab-runner exec docker ''anomaly detection''\nRuntime platform                                    arch=amd64
        os=darwin pid=72331 revision=a8a019e0 version=12.3.0\nWARNING: You most probably
        have uncommitted changes. \nWARNING: These changes will not be tested.         \nRunning
        with gitlab-runner 12.3.0 (a8a019e0)\nUsing Docker executor with image rocker/tidyverse:latest
        ...\nAuthenticating with credentials from /Users/davidparr/.docker/config.json\nPulling
        docker image rocker/tidyverse:latest ...\nERROR: Preparation failed: Error:
        No such image: rocker/tidyverse:latest (executor_docker.go:195:0s)\nWill be
        retried in 3s ...\nUsing Docker executor with image rocker/tidyverse:latest
        ...\nAuthenticating with credentials from /Users/davidparr/.docker/config.json\nPulling
        docker image rocker/tidyverse:latest ...\nERROR: Preparation failed: Error:
        No such image: rocker/tidyverse:latest (executor_docker.go:195:0s)\nWill be
        retried in 3s ...\nUsing Docker executor with image rocker/tidyverse:latest
        ...\nAuthenticating with credentials from /Users/davidparr/.docker/config.json\nPulling
        docker image rocker/tidyverse:latest ...\nERROR: Preparation failed: Error:
        No such image: rocker/tidyverse:latest (executor_docker.go:195:0s)\nWill be
        retried in 3s ...\nERROR: Job failed (system failure): Error: No such image:
        rocker/tidyverse:latest (executor_docker.go:195:0s)\n```\n\nBut you _know_
        the image exists. It''s _definately_ a thing. Look, [it''s right here](https://hub.docker.com/r/rocker/tidyverse/).
        I can even __RUN IT IN PRODUCTION__ so why is it not running on my machine?\n\n![Alt
        Text](https://thepracticaldev.s3.amazonaws.com/i/4t9ogf06iqphsaewwxvt.jpg)\n\nTurns
        out gitlab, as brilliant as I''m normally finding their CICD solution, is
        lying to you. The image _does_ exist, you _aren''t_ mad, just not seeing the
        whole picture. \n\n```\nDavids-MacBook-Pro:data-science davidparr$ docker
        pull rocker/tidyverse\nUsing default tag: latest\nlatest: Pulling from rocker/tidyverse\n16ea0e8c8879:
        Pull complete \n7ce39da2c1e2: Extracting [==================================================\u003e]  222.8MB/222.8MB\nff1bceed0bef:
        Download complete \ne36d273bec5a: Download complete \nd3acc34c6c77: Download
        complete \n14d07989ce8b: Download complete \n73b6bcbfcb26: Download complete
        \n70b803ec0e47: Download complete \nfailed to register layer: Error processing
        tar file(exit status 1): write /usr/lib/gcc/x86_64-linux-gnu/8/libsupc++.a:
        no space left on device\nDavids-MacBook-Pro:data-science davidparr$ docker
        pull rocker/tidyverse\nUsing default tag: latest\nlatest: Pulling from rocker/tidyverse\n16ea0e8c8879:
        Pull complete \n7ce39da2c1e2: Extracting [===================\u003e                               ]  85.23MB/222.8MB\nff1bceed0bef:
        Download complete \ne36d273bec5a: Download complete \nd3acc34c6c77: Download
        complete \n14d07989ce8b: Download complete \n73b6bcbfcb26: Download complete
        \n70b803ec0e47: Downloading [==================================================\u003e]  324.8MB/324.8MB\nwrite
        /var/lib/docker/tmp/GetImageBlob686008714: no space left on device\n```\n\n_That''s_
        the error message we needed. It turns out that after a while, your local machines
        ''Sparse Image'', that has all your docker images, containers, networks and
        registries, and also resizes it''s on disk footprint as you use docker, will
        get filled up with old images, containers and other cruft. \n\nThere is a
        bit more info [in this thread](https://forums.docker.com/t/no-space-left-on-device-error/10894)
        but the short version is that you probably just want to run `docker system
        prune -a`.\n\nThis command is documented to \"Remove unused data\", and when
        run will tell you all about what it''s going to do:\n\n```\nWARNING! This
        will remove:\n  - all stopped containers\n  - all networks not used by at
        least one container\n  - all images without at least one container associated
        to them\n  - all build cache\n```\n\nFor my use cases this is perfect. All
        the images I need in practice are backed up on the cloud and can be rebuilt
        from code when needed (as they should be), leaving my disk memory to be able
        to be treated a little more like active memory, hot swapping in and out containers
        as needed, keeping the disk space tidy and minimal. \n\nIn the end I received
        this lovely message:\n```\nTotal reclaimed space: 10.24GB\n```\n\nAnd we''re
        back to happy local emulation of my CI/CD pipeline. Now if only I could optimise
        my R testing image...\n","positive_reactions_count":9,"cover_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--iaizgnXx--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/wgy943gt1fv7y9sn39aa.jpg","tag_list":["cicd","docker","gitlab"],"canonical_url":"https://dev.to/daveparr/gotcha-local-gitlab-runners-no-such-image-docker-and-disk-space-7ei","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}},{"type_of":"article","id":139436,"title":"The
        Real Difference (TM) between Python and R for Data Science","description":"smarter
        than your average comparison","published":true,"published_at":"2019-08-27T13:42:58.731Z","slug":"the-real-difference-tm-between-python-and-r-for-data-science-280i","path":"/daveparr/the-real-difference-tm-between-python-and-r-for-data-science-280i","url":"https://dev.to/daveparr/the-real-difference-tm-between-python-and-r-for-data-science-280i","comments_count":0,"public_reactions_count":7,"page_views_count":342,"published_timestamp":"2019-08-27T13:42:58Z","body_markdown":"---\ntitle:
        The Real Difference (TM) between Python and R for Data Science\npublished:
        true\ndescription: smarter than your average comparison\ntags: data science,
        rstats, python, comparison\n---\n\n## Batman vs Superman\n\nData science has
        a two language problem. R and python are **both** _the_ language for data
        science. This has lead to some pretty abstract, generic and sometimes absurd
        definitions between the two languages. The worst is probably this image:\n\n![RBat
        vs pyman](https://pbs.twimg.com/media/Ce8VP0FWIAI0ad2?format=jpg\u0026name=small)\n\nData
        science is such a wide term, with sometimes a very diverse or even poor understanding
        in business, that clickbaity titles giving superficial answers abound. I''ve
        tracked down the [source of this image](http://ucanalytics.com/blogs/r-vs-python-comparison-and-awsome-books-free-pdfs-to-learn-them/),
        which has also floated around on twitter [once (2016)](https://twitter.com/lisachwinter/status/715814232676298753)
        or [twice (2018)](https://twitter.com/cmastication/status/1037486624500854784).
        To give the author of the post his dues, the article it''s derived from is
        interesting, and I hope the SEO bonus from publishing as the film hype cycle
        grew got him some extra book sales (the books he links to are actually _really_
        worth reading).\n\nI first came across it on (a now removed) instagram post
        where it was literally captioned \"How to pass any data-science interview\"
        on an account specifically advertising it''s data science recruitment services.
        I''m not against pop-culture/programming bleed over in any form (I''ve done
        enough Pokemon programming talks that any horse I get on has to be less Rapidash
        and more Ponyta), but at the point that people who are trying to break into
        the industry are being told this is _valuable information to tell an interviewer_,
        then there is evidently a gap between needs and knowledge.\n\nThe difference,
        and decision for the ''right'' tool for the job is actually defined by a mixture
        of internal and external factors. Both languages, in themselves, do the job
        of data ingest, processing, analysis, modelling and prediction equally well.
        Both can be deployed on-premises or on the cloud. Both  Minor differences
        in syntax, and major differences in deployment tooling become the defining
        factors.\n\n## INTERNALS: Syntax and ecosystem\n\nAny programming language
        is little more than syntax. Functional, Object-oriented, Imperative and more,
        in various combinations, with specific conventions and patterns. Curiously
        both [R](https://en.wikipedia.org/wiki/R_(programming_language)) and [Python](https://en.wikipedia.org/wiki/Python_(programming_language))
        are ''Multi-paradigm'' according to Wikipedia. This means that multiple, different
        styles can be used depending on the problem at hand. You can write python
        in an OO way, or a functional way. R is often thought of as functional, though
        it allows the construction of classes, and objects with methods, and side-effects,
        so it''s not a ''pure functional'' language.\n\n### However, how do _people_
        actually write code for data science? \n\nIn R, data science is a _first class
        application_ (and maybe even _sole aplication_?). [Tidyverse](https://www.tidyverse.org/)
        is arguably the de facto way to write most R projects now. With RStudio giving
        it full corporate support and funding an eco-system of tooling, most R I write,
        have seen others write, and I''ve taught people to write is in this style.
        Pipes `%\u003e%` chain function calls with non-standard evaluation of arguments,
        Rmarkdown documents, ggplot visualisation and shiny apps are an R data scientists
        solution of choice. Tidyverse is itself _functionally inspired_, [purrr explicitly
        states this](https://purrr.tidyverse.org/articles/other-langs.html) and [Hadley
        Wickham directly argues that \"R, at its heart, is a functional programming
        (FP) language.\"](http://adv-r.had.co.nz/Functional-programming.html)\n\n\nPython
        is _everywhere_. Data science in Python isn''t pythons only reason for existence.
        [scipy](https://www.scipy.org/) is the python tool chain for data science.
        numpy and pandas are best of buddies, and matplotlib is a front runner for
        graphics. This collection of tools is far less cohesive though, with scikit
        learn, seaborn and jupyter notebooks also being hugely popular, but totally
        removed from the scipy ecosystem. These tools therefore need a bit more work
        to mould into a full product. Object Oriented programming is also more popular,
        [even for](https://towardsdatascience.com/a-data-scientist-should-know-at-least-this-much-python-oop-d63f37eaac4d)
        [data science](https://towardsdatascience.com/object-oriented-programming-for-data-scientists-build-your-ml-estimator-7da416751f64).
        This means you''ll be calling objects more directly, and explicitly pulling
        out methods on objects with `myObject.method` more often.\n\n\n### What does
        that mean for me?\n\nDo you understand functional programming or object oriented
        programming already, or is one immediately making sense over the other? Great,
        use that one. \nDo you already have an ecosystem of certain tools? Great,
        use whatever you already have.\nDo you already have colleagues that you need
        to work with? Great, use whatever they are.\nDo you already have a support
        network around you for one language but not the other? Great, don''t make
        life harder than it needs to be.\n\n## EXTERNALS: Application and deployment\n\nWhat
        if you don''t have an easy answer though? You''re starting a new project,
        or you are the only programmer in the business? Then the choice becomes harder
        to get right, but more clear the more experience you have. When you know both
        tools _can achieve_ the same job, you have to choose which one does it _more
        easily_. I''ve found that I will reach for python and R equally now I''ve
        been working professionally in both for a while, however, _which_ I use is
        defined pretty clearly.\n\n### When to use R\n\nR encapsulates statistic and
        mathematical ideas clearly and robustly. Depending on where you get your dependencies
        from you can have a very clear idea of the likely ''correctness'' of the library.
        Roughly [ROpenSci](https://ropensci.org/) is more rigorous and stable than
        [CRAN](https://cran.r-project.org/) which is better than github. Tidyverse
        pipes, NSE, purrr give a tightly coupled working environment where syntax
        is consistent, terse, and trivially refactored. ggplot and RMarkdown give
        business consumable outputs from the start, where code can be kept tightly
        coupled to narrative and reporting, but also infinitely customisable to produce
        something that would get past marketing without a glance. Many academic publications
        rely on R and RMarkdown for both research and publication. If you need to
        make interactive output, shiny is a straightforward application framework,
        with a tight to everything else in this ecosystem.\n\nR is for **analysts**
        who need to be _certain_ of the underlying data processing _immediately_,
        produce and iterate on _reporting_ outputs _as fast as possible_ and write
        the _least code_ for the most return. [Hadley effectively said as much last
        week](https://qz.com/1661487/hadley-wickham-on-the-future-of-r-python-and-the-tidyverse/).\n\n\u003e
        I think R Markdown is an amazing contribution to R. ... When you are doing
        data analysis typing speed is actually a bottleneck.\n\n### When to use Python\n\nPython
        is [already used tonnes more than R](https://insights.stackoverflow.com/survey/2019#technology-_-programming-scripting-and-markup-languages)
        because data science isn''t it''s _only_ job. Data engineers use it very heavily,
        back-end and even front-end developers use it for all kinds of projects, wether
        it is data intensive or not. In many linux distributions (including Mac) it''s
        actually installed as part of your machine when you put the operating system
        on. It''s also arguably a _cloud native_ language. AWS lambda functions [support
        it out of the box](https://aws.amazon.com/lambda/features/), and Microsoft
        [recently copied them](https://www.theregister.co.uk/2019/08/20/microsoft_azure_functions/).
        This is doubly interesting as Microsoft bought one of the [biggest R consultancies
        in 2015](https://blogs.technet.microsoft.com/machinelearning/2015/04/06/microsoft-closes-acquisition-of-revolution-analytics/),
        but as of yet R is not a natively supported language in much of Microsofts
        ecosystem. It''s definitely got more baked in R support than AWS ([PowerBI](https://docs.microsoft.com/en-us/power-bi/desktop-r-visuals)
        and [many others](https://techcommunity.microsoft.com/t5/AI-Customer-Engineering-Team/Understanding-your-R-strategy-options-on-the-Azure-AI-Platform/ba-p/735626?WT.mc_id=Revolutions-blog-davidsmi\u0026WT.mc_id=Revolutions-blog-davidsmi)),
        but has made moves to [potentially trim back MRAN](https://blog.revolutionanalytics.com/2019/05/cran-snapshots-and-you.html).
        All this means that Python is spoken by most developers, that python is supported
        by most big cloud providers, and that python is probably already built into
        whatever you are working on.\n\nPython is for **developers** who need to _deploy
        software_ within a _traditional software environment_ in a _more traditional
        development_ workflow, where _first-class cloud support_ matters, and integration
        with _existing code_ is of top priority.\n\n## Conclusion\n\nR doesn''t [necessarily
        deploy easily into software development](https://resources.rstudio.com/rstudio-conf-2019/it-depends-a-dialog-about-dependencies)
        (\u003c- not strictly related, but great talk that''s relevant to the problem),
        though it is definitely possible (I''ve done it), you have to put in more
        work to get a roughly similar result. In many situations, that trade off might
        not be worth it.\n\nPython doesn''t necessarily fit into BI and academic workflows,
        thought it''s definitely possible (I''ve also done it), you have to put in
        more work to get a roughly similar result. In many situations, that trade
        off might not be worth it.\n\nSuperman, Batman, Detective Work, Intelligence,
        Cunning, Usage of Tools, More Brain than Muscles, Muscle Power, Super Strength,
        Elegance, Wide Range, More Muscles than Brain are not meaningful differentiators.","positive_reactions_count":7,"cover_image":null,"tag_list":["datascience","rstats","python","comparison"],"canonical_url":"https://dev.to/daveparr/the-real-difference-tm-between-python-and-r-for-data-science-280i","user":{"name":"Dave
        Parr","username":"daveparr","twitter_username":"DaveParr","github_username":"DaveParr","website_url":"https://www.daveparr.info","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg"}}]'
  recorded_at: 2020-06-06 12:29:30 GMT
  recorded_with: vcr/0.5.4, webmockr/0.6.2
