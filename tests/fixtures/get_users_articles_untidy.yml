http_interactions:
- request:
    method: get
    uri: https://dev.to/api/articles/me
    body:
      encoding: ''
      string: ''
    headers:
      Accept: application/json, text/xml, application/xml, */*
      api-key: <<<my_api_key>>>
  response:
    status:
      status_code: 200
      category: Success
      reason: OK
      message: 'Success: (200) OK'
    headers:
      accept-ranges:
      - bytes
      - bytes
      access-control-allow-origin: '*'
      cache-control: max-age=0, private, must-revalidate
      content-encoding: gzip
      content-type: application/json; charset=utf-8
      date: Mon, 29 Jun 2020 13:55:30 GMT
      etag: W/"332ba0d5ef3962f05f544a00860c925f"
      referrer-policy: strict-origin-when-cross-origin
      server: Cowboy
      vary: Accept-Encoding, Origin, X-Loggedin
      via:
      - 1.1 vegur
      - 1.1 varnish
      - 1.1 varnish
      x-cache: MISS, MISS
      x-cache-hits: 0, 0
      x-content-type-options: nosniff
      x-download-options: noopen
      x-frame-options: SAMEORIGIN
      x-permitted-cross-domain-policies: none
      x-request-id: 54f5760f-36ef-47ff-809c-3050c456f27f
      x-runtime: '0.174763'
      x-served-by: cache-den19642-DEN, cache-lhr7352-LHR
      x-timer: S1593438930.725404,VS0,VE339
      x-xss-protection: 1; mode=block
    body:
      encoding: UTF-8
      file: no
      string: "[{\"type_of\":\"article\",\"id\":370013,\"title\":\"Nativefier is bonkers\",\"description\":\"I
        made an electron app in 4 lines...   nativefier \\\"http://musicforprogramming.net/\\\"
        -n \\\"musicforprogr...\",\"published\":true,\"published_at\":\"2020-06-26T21:26:59.104Z\",\"slug\":\"nativefire-is-bonkers-4m43\",\"path\":\"/daveparr/nativefire-is-bonkers-4m43\",\"url\":\"https://dev.to/daveparr/nativefire-is-bonkers-4m43\",\"comments_count\":0,\"public_reactions_count\":2,\"page_views_count\":29,\"published_timestamp\":\"2020-06-26T21:26:59Z\",\"body_markdown\":\"I
        made an electron app in 4 lines...\\n\\n```sh\\nnativefier \\\"http://musicforprogramming.net/\\\"
        -n \\\"musicforprogramming\\\"\\ncd musicforprogramming-linux-x64/\\nsudo
        chmod +x musicforprogramming\\n./musicforprogramming\\n```\\n\\n# Motivation\\n\\nI
        like music, but don't like music in browser tabs. Basically because i have
        it open all the time, I want to find and control it easily, and I don't want
        it cluttering up an area that might be soley focused on work. \\n\\nI discovered
        some neat apps for google play, and wanted to see if there was one for my
        other go to, [musicforprogramming](http://musicforprogramming.net/). There
        wasn't, so I just casually googled how to convert a page into an electron
        app and OMFG!\\n\\n# Solution\\n\\n{% github jiahaog/nativefier %}\\n\\n[This
        post](https://www.todesktop.com/guides/nativefier) and [this one](https://www.addictivetips.com/ubuntu-linux-tips/nativefier-turn-websites-into-linux-apps/)
        helped iron out some kinks and now I can launch programming music right from
        my VS code terminal!\\n\\n![vs code and an electron app of musicforprogramming
        made with nativefier](https://dev-to-uploads.s3.amazonaws.com/i/7dh4uokd2pt0zxgeye0n.png)\\n\\n#
        Extra credit\\n\\n```sh\\nalias musicforprogramming=\\\"~/Dev/musicforprogramming-linux-x64/musicforprogramming\\n```\\n\\n\",\"positive_reactions_count\":2,\"cover_image\":null,\"tag_list\":[\"npm\",\"electron\",\"music\",\"app\"],\"canonical_url\":\"https://dev.to/daveparr/nativefire-is-bonkers-4m43\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":367598,\"title\":\"Investigating
        interactions between dev.to and stackbit\",\"description\":\"Is the description
        also the excerpt?   I was poking around in the dev.to api, and had my sta...\",\"published\":true,\"published_at\":\"2020-06-26T10:18:47.372Z\",\"slug\":\"investigating-interactions-between-dev-to-and-stackbit-38ge\",\"path\":\"/daveparr/investigating-interactions-between-dev-to-and-stackbit-38ge\",\"url\":\"https://dev.to/daveparr/investigating-interactions-between-dev-to-and-stackbit-38ge\",\"comments_count\":0,\"public_reactions_count\":2,\"page_views_count\":43,\"published_timestamp\":\"2020-06-26T10:18:47Z\",\"body_markdown\":\"##
        Is the `description` also the `excerpt`?\\n\\nI was poking around in the [dev.to
        api](https://docs.dev.to/api/), and\\nhad my [stackbit cms\\nintegration](https://dev.to/devteam/you-can-now-generate-self-hostable-static-blogs-right-from-your-dev-content-via-stackbit-7a5)\\nopen
        in another window and I noticed something I hadn’t before. My first\\never
        post had a neat ‘excerpt’ that wasn’t actually part of the main\\nbody of
        the post. My other posts didn’t. In the `yaml` there is actually\\na key called
        `excerpt` with the string in question. The API also has a\\nvalue that can
        be part of the response which is a string labelled\\n[“Description”](https://docs.dev.to/api/#operation/createArticle)\\nwhich
        I hadn’t integrated into my\\n[`dev.to.ol`](https://github.com/DaveParr/dev.to.ol)
        package yet. I have\\nnow. I must have written that first post through the
        editor built into\\nthe website. Is this field no longer supported? I seem
        to be able to set\\nit through the API, but I can’t see the info anywhere
        on the current\\nsite.\\n\\nSo, if I’m correct, this post should show up with
        a neat little\\ndescription on stackbit, but not on dev.to. \\n\\nUPDATE:
        Apparently not. So what does the description field do then?\\n\\n## Should
        liquid tags work in stackbit?\\n\\nI like the liquid tags, in some cases.
        I was even debating writing an R\\nfunction to convert a url into the relevant
        liquid tag through string\\nparsing, but I’ve spotted that liquid tags aren’t
        actually supported by\\nstackbit? See the end of this post on dev, and this
        copy of it on my\\nstackbit site, where the link seems large and broken. Are
        there plans to\\nsupport this on stack bit? Or do you already, and I’ve just
        not spotted\\nhow to ‘turn it on’?\\n\\n\\u003e n.b. if you are on my personal
        site daveparr.info, this might be\\n\\u003e confusing, but it’s actually generated
        from my content on dev.to via\\n\\u003e an integration with stack bit. You
        can see more about this from the\\n\\u003e links in the footer VVV\\n\",\"positive_reactions_count\":2,\"cover_image\":null,\"tag_list\":[\"projectbenatar\",\"showdev\",\"rstats\",\"meta\"],\"canonical_url\":\"https://dev.to/daveparr/investigating-interactions-between-dev-to-and-stackbit-38ge\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"showdev\",\"bg_color_hex\":\"#091b47\",\"text_color_hex\":\"#b2ffe1\"}},{\"type_of\":\"article\",\"id\":367500,\"title\":\"Why
        use AWS Lambda for Data Science?\",\"description\":\"Motivation   Serverless
        is a way to deploy code, without having to manage the infrastructure...\",\"published\":true,\"published_at\":\"2020-06-25T14:23:43.105Z\",\"slug\":\"why-use-aws-lambda-for-data-science-421\",\"path\":\"/daveparr/why-use-aws-lambda-for-data-science-421\",\"url\":\"https://dev.to/daveparr/why-use-aws-lambda-for-data-science-421\",\"comments_count\":3,\"public_reactions_count\":25,\"page_views_count\":123,\"published_timestamp\":\"2020-06-25T14:23:43Z\",\"body_markdown\":\"##
        Motivation\\n\\nServerless is a way to deploy code, without having to manage
        the\\ninfrastructure underneath it. In AWS terms this means there is an\\ncompute
        instance that runs your code, except you don’t control it, and\\nthat might
        be a good thing. It only exists when it’s asked for by\\nsomething else, and
        therefore you only pay for the work it does. If you\\nneed to do work concurrently
        you get a new instance, which also goes\\naway as soon as you don’t need it,
        so it’s scaleable.\\n\\nFor a data scientist this is an interesting prospect
        for a number of\\nreasons. The first is keeping you hands clean. Not all people
        in this\\nrole come from a ‘operations’ background. Many of us are analysts
        first,\\nand graduate into the role. However, that shouldn’t mean we don’t
        ‘own\\nour deployments’. However, it also means that we might not have the\\nbackground,
        time or inclination to really get into the nitty-gritty.\\nManaged infrastructure,
        that can scale seamlessly out of the box is a\\nnice middle ground. We can
        still manage our own deployments, but theres\\nless to worry about than owning
        your own EC2 instances, let alone a\\nfleet of them. The way that the instances
        themselves die off is also\\nvaluable. We may be doing work that requires
        24/7 processing, but often,\\nwe aren’t. Why pay for a box which might have
        50% required utilisation\\ntime, or even less?\\n\\n### Limits\\n\\nJust like
        in everything there is a balance. There are *physical* limits\\nto this process.
        I’ve had success deploying data science assets in this\\narchitecture, but
        if you can’t fit your job in these limits, this\\nalready isn’t for you. Sure,
        data science *can be* giant machine\\nlearning models on huge hardware with
        massive data volumes, but we have\\nto be honest and acknowledge that it isn’t
        always. K.I.S.S. should apply\\nto everything.\\n\\nIf you can get good enough
        business results with a linear regression,\\ndon’t put in 99% more effort
        to train the new neural network hotness to\\nget a 2% increase in performance.
        Simplicity in calculation, deployment,\\nand explainability *matter*.\\n\\n\\u003e
        “No ML is easier to manage than no ML” ©\\n\\u003e \\\\[@julsimon\\\\](\\u003chttps://twitter.com/julsimon/status/1124383078313537536\\u003e)\\n\\n##
        Getting started\\n\\n``` python\\nfrom scipy import stats\\nimport numpy as
        np\\n\\nnp.random.seed(12345678)\\n\\nx = np.random.random(10)\\ny = 1.6*x
        + np.random.random(10)\\n\\nslope, intercept, r_value, p_value, std_err =
        \\n  stats.linregress(x, y)\\n```\\n\\nThis is a nonsense linear regression.
        IMHO it’s a data science ‘Hello\\nWorld’. Let’s make it an AWS Lambda serverless
        function.\\n\\n``` diff\\n+ import json\\nfrom scipy import stats\\nimport
        numpy as np\\n+ def lambda_handler(event, context):\\n  np.random.seed(12345678)\\n\\nx
        = np.random.random(10)\\ny = 1.6*x + np.random.random(10)\\n\\nslope, intercept,
        r_value, p_value, std_err = stats.linregress(x, y) \\n+   return_body = {\\n
        \ +       \\\"m\\\": slope, \\\"c\\\": intercept,\\\"r2\\\": r_value ** 2,
        \\n  +       \\\"p\\\": p_value, \\\"se\\\": std_err\\n  +   }\\n+   return
        {\\\"body\\\": json.dumps(return_body)}\\n```\\n\\nThese changes achieve 3
        things:\\n\\n1.  Turning a *script* into a *function*\\n2.  Supplying the
        function arguments `event` and `context`\\n3.  Formatting the return as json\\n\\nThese
        are required as AWS Lambda needs a *function*. This is so that its\\n*event
        driven architecture* can feed in data through `event`, and so\\nthat it’s
        `json` formatted data can both be received by your function,\\nand then also
        the response be returned by that function into the rest of\\nthe system.\\n\\nYou
        can then open up the AWS console in a browser, navigate to the\\nLambda service,
        and then copy and paste this into this screen:\\n\\n![aws console lambda editor](https://raw.githubusercontent.com/DaveParr/dev.to-posts/master/snakes-lambdas_files/basic.png)\\n\\nYou
        can then hit run and…\\n\\n![aws console lambda editor with an error\\nmessage](https://raw.githubusercontent.com/DaveParr/dev.to-posts/master/snakes-lambdas_files/basic-fail.png)\\n\\nWhat
        happened? Well, because it’s a *managed* instance, the function\\ndoesn’t
        know what `scipy` is. It’s not installed on the cloud, it was\\ninstalled
        on your machine…\\n\\n## Layers\\n\\nAWS lambda doesn’t `pip install ....`.
        Seeing as these run on compute\\ninstances that turn up when needed, and are
        destroyed when not needed,\\nwith no attached storage, you need to find a
        way to tell AWS what your\\ndependencies are, or you’ll just have to write
        super-pure base Python\\\\!\\nWell, that may not be *strictly* true. `json`
        is *built in by default to\\nevery instance*, so is `boto3`, but what about
        our data science buddies?\\n`numpy`, `scipy` are *[published by\\naws](https://aws.amazon.com/blogs/aws/new-for-aws-lambda-use-any-programming-language-and-share-common-components/)
        as layers*. Layers are bundles of code, that contain the dependencies you
        need to run the functions you write.\\nSo in this case we can open the ‘layers’
        view in AWS and attach these to our function.\\n\\n![layers](https://raw.githubusercontent.com/DaveParr/dev.to-posts/master/snakes-lambdas_files/layers.png)\\n\\nNow
        that you’ve attached all your dependencies with layers, go ahead and\\nrun
        your function again.\\n\\n![editor](https://raw.githubusercontent.com/DaveParr/dev.to-posts/master/snakes-lambdas_files/basic-success.png)\\n\\nSuccess\\\\!
        So now you know the basics of how to put some Python data\\nscience into practice
        on AWS Lambda.\\n\\nThis is a companion post to my talk on using data science
        in AWS lambda.\\nIf you’re keen to know more, and can’t wait for me to write
        it all up\\nhere. You can get the gist of the whole talks from this repo :smile:
        {% github\\nDaveParr/snakes\\\\_and\\\\_lambdas %}\\n\",\"positive_reactions_count\":25,\"cover_image\":null,\"tag_list\":[\"python\",\"datascience\",\"serverless\",\"aws\"],\"canonical_url\":\"https://dev.to/daveparr/why-use-aws-lambda-for-data-science-421\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":345011,\"title\":\"Building
        my first Django project with CSS and Static Files\",\"description\":\"I'm
        working through Django for Beginners by William S. Vincent. Until now we've
        had some pretty bareb...\",\"published\":true,\"published_at\":\"2020-06-25T13:14:11.865Z\",\"slug\":\"building-my-first-django-project-with-css-and-static-files-12g1\",\"path\":\"/daveparr/building-my-first-django-project-with-css-and-static-files-12g1\",\"url\":\"https://dev.to/daveparr/building-my-first-django-project-with-css-and-static-files-12g1\",\"comments_count\":1,\"public_reactions_count\":2,\"page_views_count\":66,\"published_timestamp\":\"2020-06-25T13:14:11Z\",\"body_markdown\":\"I'm
        working through [Django for Beginners by William S. Vincent](https://djangoforbeginners.com/).
        Until now we've had some pretty barebones Times New Roman style UI, however
        that's all about to change! I think.\\n\\nI'm really appreciating this incremental
        iteration of concepts in each new Chapter. Each time I start a new app for
        the chapter it's engraining the muscle memory and concept recall into me.
        I'm able to run through the first 5 lines of code at the CLI nearly from memory.
        It's also a great mechanism to help you if you get stuck on a wierd error
        and don't know what to do. You know the next chapter will have a clean slate.
        Great idea William.\\n\\nThe repetition isn't just the set-up though.\\n\\n\\u003e
        “Now we can add the functionality for individual blog pages. How do we do
        that? We need to create a new view, url, and template. I hope you’re noticing
        a pattern in development with Django now!”\\n\\nI sure am. \\n\\nI'm glad
        that the book also doesn't go into non-django areas, but still points readers
        to places to look for more info. The last chapter pointed me towards some
        resources to understand more about databases, and this one does similar with
        CSS.\\n\\nIt was interesting to see that the approach used to identify a blog
        post for navigation in the URL patterns looked _kinda_ regex-ish:\\n\\n```py\\nurlpatterns
        = [\\n    path('post/\\u003cint:pk\\u003e/', BlogDetailView.as_view(), name='post_detail'),\\n
        \   path('', BlogListView.as_view(), name='home'),\\n]\\n```\\n\\n`\\u003cint:pk\\u003e`
        is the part that identifies the blog post required for the url to link from
        the ListView to the DetailView. It was interesting to find out there was something
        like a unique identifier for each post baked into it in the background. I
        was wondering about how this primary key is treated in bigger projects. Is
        it common to keep this approach of integer ordered primary keys, or do they
        get replaced in larger, more complex projects with hashes or other unique
        ids?\",\"positive_reactions_count\":2,\"cover_image\":null,\"tag_list\":[\"python\",\"django\",\"css\"],\"canonical_url\":\"https://dev.to/daveparr/building-my-first-django-project-with-css-and-static-files-12g1\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":357514,\"title\":\"3
        minimal features for my dev.to api wrapper\",\"description\":\"I’ve made 3
        very small features for my open source R package wrapping the dev.to API.
        \         create...\",\"published\":true,\"published_at\":\"2020-06-17T13:02:10.887Z\",\"slug\":\"3-minimal-features-for-my-dev-to-api-wrapper-371l\",\"path\":\"/daveparr/3-minimal-features-for-my-dev-to-api-wrapper-371l\",\"url\":\"https://dev.to/daveparr/3-minimal-features-for-my-dev-to-api-wrapper-371l\",\"comments_count\":0,\"public_reactions_count\":3,\"page_views_count\":33,\"published_timestamp\":\"2020-06-17T13:02:10Z\",\"body_markdown\":\"I’ve
        made 3 very small features for my [open source R package wrapping\\nthe dev.to
        API](https://github.com/DaveParr/dev.to.ol).\\n\\n## `create_new_article`\\n\\nNow
        that the main requirements for the file to post are stabilising,\\nI’ve written
        a quick and dirty function to make a boilerplate article:\\n\\n``` r\\ncreate_new_article
        \\u003c-\\n  function(title,\\n           series = 'series',\\n           tags
        = '[\\\"tag1\\\", \\\"tag2\\\"]',\\n           file = \\\"\\\") {\\n    boilerplate_frontmatter
        \\u003c-\\n      glue::glue(\\n        '---\\\\ntitle: \\\"{title}\\\"\\\\noutput:
        github_document\\\\nseries: \\\"{series}\\\"\\\\ntags: {tags}\\\\n---'\\n
        \     )\\n\\n    cat(boilerplate_frontmatter, file = file)\\n  }\\n```\\n\\nThis
        will use the [`glue`](https://glue.tidyverse.org/) package to put\\nthe strings
        in the function argument into the right place in the\\nboilerplate YAML front
        matter. If then uses `cat` to either print that\\nto screen, or to create
        a new file with it, if a file path is supplied.\\n\\n## `main_image`\\n\\nIf
        there is a `main_image` parameter in the `YAML` front matter that is\\na url
        of an image, that image will be set as the cover image of the\\npost. I got
        this one from a photo by [Julian\\nDufort](https://unsplash.com/@juliandufort?utm_source=unsplash\\u0026utm_medium=referral\\u0026utm_content=creditCopyText)\\non\\n[Unsplash](https://unsplash.com/s/photos/3?utm_source=unsplash\\u0026utm_medium=referral\\u0026utm_content=creditCopyText).\\nI
        *believe* that if you put an unsplash URL into this field that goes\\n**directly
        to the image** it is within their\\n[license](https://unsplash.com/license),
        though if anyone knows\\nsomething to the contrary please let me know. It’s
        the first time I have\\nused this service, despite hearing about it for years.\\n\\n##
        Collapse spaces tags\\n\\nI recently fooled myself for a good ten minutes
        into thinking that there\\nwas a problem with my API code yesterday when I
        kept getting a 422\\nresponse to putting a new article up, when in fact it
        was that I had a\\nspace character in one of my tags. Now the `post_new_article`
        function\\ncollapses any spaces it encounters in tags. Achieving this was
        a breeze\\nwith [`purrr`](https://purrr.tidyverse.org/) and\\n[`stringr`](https://stringr.tidyverse.org//):\\n\\n```
        r\\npurrr::map(file_frontmatter$tags, stringr::str_remove_all, \\\" \\\")\\n```\\n\\nThis
        little nugget takes the list of tags, and then maps the function\\n`str_remove_all`
        across all the spaces. This isn’t at all exposed to the\\nuser, as it’s non-negotiable
        from the API side anyway :)\\n\",\"positive_reactions_count\":3,\"cover_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--wDQKE_1G--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://images.unsplash.com/photo-1529784730934-afecdfb85594%3Fixlib%3Drb-1.2.1%26ixid%3DeyJhcHBfaWQiOjEyMDd9%26auto%3Dformat%26fit%3Dcrop%26w%3D1660%26q%3D80\",\"tag_list\":[\"projectbenatar\",\"showdev\",\"rstats\",\"functional\"],\"canonical_url\":\"https://dev.to/daveparr/3-minimal-features-for-my-dev-to-api-wrapper-371l\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"showdev\",\"bg_color_hex\":\"#091b47\",\"text_color_hex\":\"#b2ffe1\"}},{\"type_of\":\"article\",\"id\":357411,\"title\":\"Is
        'R' or 'Rstats' the preferred tag for the R programming language on dev?\",\"description\":\"The
        language is called R.  There a strong convention of the tag #rstats being
        used in social media su...\",\"published\":true,\"published_at\":\"2020-06-17T10:03:20.828Z\",\"slug\":\"is-r-or-rstats-the-preferred-tag-for-the-r-programming-language-10ea\",\"path\":\"/daveparr/is-r-or-rstats-the-preferred-tag-for-the-r-programming-language-10ea\",\"url\":\"https://dev.to/daveparr/is-r-or-rstats-the-preferred-tag-for-the-r-programming-language-10ea\",\"comments_count\":12,\"public_reactions_count\":2,\"page_views_count\":64,\"published_timestamp\":\"2020-06-17T10:03:20Z\",\"body_markdown\":\"The
        language is called R.\\n\\nThere a strong convention of the tag #rstats being
        used in social media [such as Twitter](https://twitter.com/hashtag/RStats?s=09)\\n\\nIs
        there a preference/canonical tag on dev.to? Is there reason to merge the tags
        (if that is even possible)? Does it even really matter?\",\"positive_reactions_count\":2,\"cover_image\":null,\"tag_list\":[\"meta\",\"discuss\",\"r\",\"rstats\"],\"canonical_url\":\"https://dev.to/daveparr/is-r-or-rstats-the-preferred-tag-for-the-r-programming-language-10ea\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"discuss\",\"bg_color_hex\":\"#000000\",\"text_color_hex\":\"#FFFFFF\"}},{\"type_of\":\"article\",\"id\":357002,\"title\":\"Webscraping
        with rvest and themeing ggplot\",\"description\":\"library(tidyverse) library(pokedex)
        \    ggplot is the ‘default’ plotting library in R. It’s a very ol...\",\"published\":true,\"published_at\":\"2020-06-16T16:57:30.261Z\",\"slug\":\"webscraping-with-rvest-and-themeing-ggplot-4573\",\"path\":\"/daveparr/webscraping-with-rvest-and-themeing-ggplot-4573\",\"url\":\"https://dev.to/daveparr/webscraping-with-rvest-and-themeing-ggplot-4573\",\"comments_count\":1,\"public_reactions_count\":3,\"page_views_count\":32,\"published_timestamp\":\"2020-06-16T16:57:30Z\",\"body_markdown\":\"```
        r\\nlibrary(tidyverse)\\nlibrary(pokedex)\\n```\\n\\n[`ggplot`](https://ggplot2.tidyverse.org/)
        is the ‘default’ plotting\\nlibrary in R. It’s a very old package now, but
        has been kept up-to-date\\nand is one of the core ‘tidyverse’ packages.\\n[`rvest`](https://rvest.tidyverse.org/)
        is also a tidyverse package that\\ndeals with web scrapping, inspired by equivalents
        like [“beautiful\\nsoup”](https://www.crummy.com/software/BeautifulSoup/).\\n\\nThere
        is a table of hex colour codes used by\\n[Bulbapedia](https://bulbapedia.bulbagarden.net/wiki/Category:Type_color_templates)\\nfor
        each pokemon type. I’d like top be able to use this for plots made\\nwith
        my [`pokedex` package](https://github.com/DaveParr/pokedex).\\n\\n## Webscraping
        with `rvest`\\n\\n### Get the data\\n\\n``` r\\nread_html(\\\"https://bulbapedia.bulbagarden.net/wiki/Category:Type_color_templates\\\")
        %\\u003e% \\n  html_nodes(\\\".wikitable\\\") %\\u003e%\\n  .[[1]] %\\u003e%
        \\n  html_table() -\\u003e pokemon_colour_table\\n```\\n\\nThis very simple
        pipe goes to the url and detects all html nodes with a\\nclass of `\\\"wikitable\\\"`
        and puts them in a list. It then takes the first\\nelement (of one in this
        case), converts it into a table, and assigns it\\nto a variable `pokemon_colour_table`\\n\\n###
        Clean the data\\n\\n``` r\\npokemon_colour_table %\\u003e%\\n  janitor::clean_names()
        %\\u003e%\\n  slice(1:75) %\\u003e%\\n  select(-video_game_types_3) %\\u003e%\\n
        \ rename(type_full = video_game_types, colour = video_game_types_2) %\\u003e%\\n
        \ filter(type_full != \\\"\\\") %\\u003e%\\n  mutate(\\n    type = tolower(str_trim(str_remove_all(type_full,
        \\\"color|light|dark|\\\\\\\\:\\\"))),\\n    colour_var = case_when(\\n      str_detect(type_full,
        \\\"light\\\") ~ \\\"light\\\",\\n      str_detect(type_full, \\\"dark\\\")
        ~ \\\"dark\\\"\\n    )\\n  ) %\\u003e%\\n  mutate(colour = paste0(\\\"#\\\",
        colour)) %\\u003e%\\n  select(-type_full, type, colour_var, colour) -\\u003e
        type_colours\\n```\\n\\nCleaning the data is the more irritating part, as
        always. First,\\n`janitor::clean_names()` does a bunch of sane default things
        to make\\nsure our table names are snakecase, with no mad characters and\\nduplication
        etc.. Then, as we only want the first part we slice it, and\\nas we only want
        the first 2 columns, we drop the third. We then give the\\nremaining columns
        sane names, and remove rows that have empty strings.\\n\\nThe meat of the
        data cleaning comes next, parsing the label column to\\nget just the type
        out and convert it to lower case and putting it into a\\nnew column, then
        conditionally checking if the row is a variant\\nlight/dark hue, or the default,
        and making a column to represent that.\\nFinally we convert the colour code
        to an actual hex string.\\n\\n### Format for `ggplot2` colour scale\\n\\n`ggplot2`
        wants the scale as a named list. Making this in a tidy way is\\nvery straightforward.\\n\\n```
        r\\ntype_colours %\\u003e%\\n  filter(is.na(colour_var)) %\\u003e%\\n  select(-colour_var)
        %\\u003e%\\n  mutate(colour = set_names(colour, type)) %\\u003e%\\n  pull(colour)
        -\\u003e pokemon_type_scale_colours\\n```\\n\\nIn this particular case we
        select all the values that *do not* have a\\n`colour_var` value, i.e. the
        defaults, drop the `colour_var` column, and\\nset the names of the `colour`
        column to the *value* of the type column.\\nWe have to do this because `scale_*_manual()`
        in ggplot will expect a\\nnamed list, where the names are the `type` categorical
        variable, and the\\ncontents of the list are the hex colour codes for that
        type. Then when\\nwe `pull` that column into a list we will have a named list.\\n\\n##
        Theming\\n\\n### Add a font with `showtext`\\n\\nKeeping the video game flavour,
        lets also make a quick theme using the a\\nvideo game font. We can use\\n[`showtext`](https://github.com/yixuan/showtext)
        to easily add the\\n“Press Start 2P” font from google fonts.\\n\\n``` r\\nlibrary(\\\"showtext\\\")\\nfont_add_google(\\\"Press
        Start 2P\\\")\\nshowtext_auto()\\n```\\n\\nThen, starting from the `theme_minimal`
        we can replace the default font,\\nand rotate the text labels on the bottom
        axis.\\n\\n``` r\\ntheme_pokedex \\u003c- function () {\\n  theme_minimal()
        %+replace%\\n    theme(\\n      text = element_text(family = \\\"Press Start
        2P\\\"),\\n      axis.text.x = element_text(angle = -90)\\n    )\\n}\\n\\ntheme_set(theme_pokedex())\\n```\\n\\n##
        Eeveelutions\\n\\nTo demonstrate, lets make a simple plot showing the key
        stats of the\\neeveelutions.\\n\\n``` r\\npokemon %\\u003e% \\n  filter(evolution_chain_id
        == 67) %\\u003e% \\n  select(identifier, hp:speed, type_1) %\\u003e% \\n  pivot_longer(cols
        = c(hp:speed),\\n               names_to = \\\"stat\\\") %\\u003e% \\n  ggplot(aes(x
        = stat, y = value, fill = type_1)) +\\n  geom_col() +\\n  facet_wrap(. ~ identifier)
        +\\n  scale_fill_manual(values = pokemon_type_scale_colours) +\\n  labs(title
        = \\\"eeveelutions stats\\\")\\n```\\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/eugomzb1g1v9z6ytyry4.png)\\n\",\"positive_reactions_count\":3,\"cover_image\":null,\"tag_list\":[\"rstats\",\"pokemon\",\"datascience\",\"websscraping\"],\"canonical_url\":\"https://dev.to/daveparr/webscraping-with-rvest-and-themeing-ggplot-4573\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":356940,\"title\":\"Is
        it my imagination or was there a tag following intensity feature on dev.to?\",\"description\":\"I
        seem to remember that there was a mechanism for my user to say per tag how
        interested they were on...\",\"published\":true,\"published_at\":\"2020-06-16T15:33:08.376Z\",\"slug\":\"is-it-my-imagination-or-was-there-a-tag-following-intensity-feature-on-dev-to-3khc\",\"path\":\"/daveparr/is-it-my-imagination-or-was-there-a-tag-following-intensity-feature-on-dev-to-3khc\",\"url\":\"https://dev.to/daveparr/is-it-my-imagination-or-was-there-a-tag-following-intensity-feature-on-dev-to-3khc\",\"comments_count\":7,\"public_reactions_count\":4,\"page_views_count\":178,\"published_timestamp\":\"2020-06-16T15:33:08Z\",\"body_markdown\":\"I
        seem to remember that there was a mechanism for my user to say per tag how
        interested they were on dev.to?\\n\\ne.g. I could go to my settings and from
        there view my tags, with a decimal value next to each of them where 1 is 'normal
        interest', 2 was 'very high interest', and 0.5 was 'not interested'. \\n\\nIs
        it still here? Where does it live? Has it moved? Did I imagine in in some
        dev.to centric fever dream?\",\"positive_reactions_count\":4,\"cover_image\":null,\"tag_list\":[\"meta\",\"help\",\"discuss\"],\"canonical_url\":\"https://dev.to/daveparr/is-it-my-imagination-or-was-there-a-tag-following-intensity-feature-on-dev-to-3khc\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":354878,\"title\":\"Recommend
        an image hosting service for my dev.to api wrapper\",\"description\":\"I am
        writing a wrapper in R for the dev.to API. One of the goals is to allow images
        that are generate...\",\"published\":true,\"published_at\":\"2020-06-13T15:07:15.159Z\",\"slug\":\"recommend-an-image-hosting-service-for-my-dev-to-api-wrapper-55ko\",\"path\":\"/daveparr/recommend-an-image-hosting-service-for-my-dev-to-api-wrapper-55ko\",\"url\":\"https://dev.to/daveparr/recommend-an-image-hosting-service-for-my-dev-to-api-wrapper-55ko\",\"comments_count\":2,\"public_reactions_count\":3,\"page_views_count\":53,\"published_timestamp\":\"2020-06-13T15:07:15Z\",\"body_markdown\":\"I
        am writing a wrapper in R for the dev.to API. One of the goals is to allow
        images that are generated from an .Rmd to be visible in the post. \\n\\n#
        Idea 1 - googledrive\\n\\nI thought I might be able to use the `googledrive`
        package to put images into my gdrive, but I haven't been able to find a way
        to get a link that shows up in dev.to\\n\\n# Idea 2 - imgur\\n\\nImgur _used_
        to support anonymous uploads and have an API wrapper to R, but the package
        in question has been [looking for a new maintainer](https://github.com/cloudyr/imguR/issues/11).
        Also, in a really quick test the current codebase appears broken. \\n\\n#
        Idea 3 - S3 bucket\\n\\nI could setup my own s3 bucket, and link the images
        from there, however that requires a lot of setup for other users, I wanted
        to keep this as 'low barrier' as possible.\\n\\n# Idea 4 - Rpubs\\n\\nRPubs
        allows uploads of documents from Rstudio IDE really easily, though AFAIK you
        can't then pull an actual link out of the image that will display in the article,
        for instance [this old plot I made for an SO question](https://rpubs.com/DaveRGP/SOLabelLogHeatMap)\\n\\n#
        Goals\\n\\n* Needs to be easy to setup\\n* Needs to be effectively free\\n*
        Needs to be accessible programmatically (API etc)\\n* Would be great if there
        was _no_ authorisation required\\n* Would be great if there was _already_
        an interface with R\\n\\nIdeas?\",\"positive_reactions_count\":3,\"cover_image\":null,\"tag_list\":[\"help\",\"projectbenatar\",\"discuss\",\"rstats\"],\"canonical_url\":\"https://dev.to/daveparr/recommend-an-image-hosting-service-for-my-dev-to-api-wrapper-55ko\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":354676,\"title\":\"A
        really hacky way to prevent dev.to posts turning up on your stackbit website
        by tag\",\"description\":\"So I have found a method to prevent posts with
        discuss, watercooler, help, etc. turning up in my Stac...\",\"published\":true,\"published_at\":\"2020-06-13T10:56:46.981Z\",\"slug\":\"a-really-hacky-way-to-prevent-dev-to-posts-turning-up-on-your-stackbit-website-by-tag-3jj3\",\"path\":\"/daveparr/a-really-hacky-way-to-prevent-dev-to-posts-turning-up-on-your-stackbit-website-by-tag-3jj3\",\"url\":\"https://dev.to/daveparr/a-really-hacky-way-to-prevent-dev-to-posts-turning-up-on-your-stackbit-website-by-tag-3jj3\",\"comments_count\":0,\"public_reactions_count\":1,\"page_views_count\":24,\"published_timestamp\":\"2020-06-13T10:56:46Z\",\"body_markdown\":\"So
        I have found a method to prevent posts with `discuss`, `watercooler`, `help`,
        etc. turning up in my Stackbit dev.to site by tag. However, I'm actually pretty
        disappointed with the solution. It's very verbose, very unconfigurable. However,
        it also does work.\\n\\n# The Dream\\n\\nThe user can put a single line of
        code into the hugo template that will accept some array type data object that
        represents multiple tags. That object can then get fed from the `config.yaml`
        with some array type data object.\\n\\n# The Opposite of the dream\\n\\nThe
        opposite of the dream was easy, it was this one line:\\n\\n```hugo\\n{{ range
        $post := (where $display_posts \\\"Params.tags\\\" \\\"intersect\\\" (slice
        \\\"Rstats\\\" \\\"rstats\\\" \\\"python\\\")) }}\\n```\\n\\nThis [commit](https://github.com/DaveParr/daveparrinfo/commit/d4f29da6c0ebc18878af06ddf4c6b7f340c76612)
        puts it in more context. This line will \\nonly range the `$post` variable
        over the `$display_posts` that have a tag that is in the `slice`. So now I
        just need to invert that.\\n\\n# Warning signs\\n\\n[This post onf the Hugo
        Discourse Forum](https://discourse.gohugo.io/t/negative-intersect-not-intersect-is-needed/13323)
        was an early find, and a bit disheartening. Still, I cracked on with some
        more research, and in the end I had to [ask for some help]\\n(https://discourse.gohugo.io/t/how-do-i-exclude-posts-based-on-any-one-of-multiple-tags/26187/14).\\n\\n#
        The 'Ugly' truth\\n\\nWe ended up settling on the most basic of consecutive
        `if else` statements, with one line for each of the tags we didn't want. As
        my very helpful new friend put it:\\n\\n```\\n{{ if in .Params.tags \\\"tag1\\\"
        }}\\u003c!-- nah //--\\u003e\\n{{ else if in .Params.tags \\\"tag2\\\" }}\\u003c!--
        nah either //--\\u003e\\n{{ else }}\\n \\u003cYour content here\\u003e\\n{{end}}\\n```\\n\\n[This
        is the commit I ended up with](https://github.com/DaveParr/daveparrinfo/commit/6c39c76867a4eb0b3958a1f089b39e1a92d9a500)\\n\\n#
        Why I don't like it\\n\\nMy new buddy was very helpful, and had some interesting
        info about [Schrodingers cat](https://www.theguardian.com/science/2019/jun/03/feline-fine-fate-of-schrodingers-cat-can-be-reversed-study),
        but I think he also could see this was an imperfect solution. It creates one
        specific problem for maintenance, and means it's more difficult to implement
        another related feature:\\n\\n## Maintenance problem\\n\\nEach time I want
        to add a new tag to exclude, I need to modify the actual page with new lines
        of code. Each new tag requires a new line `{{ else if in .Params.tags \\\"tag-to-remove\\\"
        }}`\\n\\n## Desired feature\\n\\nIt would be safer and also easier if a data
        structure in the `config.yaml` could be used, as then the page template remains
        removed from the business logic, however as a _whole line_ needs to be added
        for each tag, I don't see a way that the logic can be abstracted away from
        the template here, which is a shame\\n\\n# Can you help?\\n\\nI've written
        an amount of hugo in side projects, but I'm far from an expert. If you can
        find a better solution please let me know :)\",\"positive_reactions_count\":1,\"cover_image\":null,\"tag_list\":[\"projectbenatar\",\"stackbit\",\"hugo\",\"help\"],\"canonical_url\":\"https://dev.to/daveparr/a-really-hacky-way-to-prevent-dev-to-posts-turning-up-on-your-stackbit-website-by-tag-3jj3\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":344987,\"title\":\"Building
        my first Django project with pages\",\"description\":\"I'm working through
        Django for Beginners by William S. Vincent. Chapter 3 starts using templates
        and...\",\"published\":true,\"published_at\":\"2020-06-11T08:30:27.897Z\",\"slug\":\"building-my-first-django-project-with-pages-kjn\",\"path\":\"/daveparr/building-my-first-django-project-with-pages-kjn\",\"url\":\"https://dev.to/daveparr/building-my-first-django-project-with-pages-kjn\",\"comments_count\":0,\"public_reactions_count\":5,\"page_views_count\":150,\"published_timestamp\":\"2020-06-11T08:30:27Z\",\"body_markdown\":\"I'm
        working through [Django for Beginners by William S. Vincent](https://djangoforbeginners.com/).
        Chapter 3 starts using templates and introduces Class-Based Views.\\n\\nThere
        is a section introducing Class-Based views, and then mentioning older Function-Based
        views. It was interesting to see this evidence of the framework progressing,
        though it's not so surprising for something that's a decade or so old!\\n\\nThe
        templating syntax was really neat. I'd seen very similar in Hugo and Jekyll,
        and so the idea of having a kind of 'placeholder' with `“{% block content
        %}{% endblock content %}` was nice to use. I've admittedly done very little
        webdev though. I was curious what other approaches might be common alternatives?
        If you have an example please let me know in the comments!\\n\\nSomething
        that was curious to me was the inversion of structure in django vs hugo.\\n\\nIn
        hugo, I've very regularly used partials such as in [the SatRdays theme here](https://github.com/satRdays/hugo-satrdays-theme/blob/cfc0873e03a7f278f8e09227875affbfcc50169f/layouts/index.html).
        Here, I have a single home page with my headers and footers, and 'inject'
        a partial into it with `{{ partial \\\"nav.html\\\" . }}`. In django I feel
        like it kind of works the other way. We create a project, and then the equivalent
        to a hugo partial would actually be a django app within the project? Then,
        each app shares top level content through lines like `{% extends 'base.html'
        %}` within each apps template?\\n\\nIt seems like it might be more brittle
        to me, but maybe also more powerful? There's more duplicate lines to get wrong,
        but also more opportunities to vary what it does?\\n\\nWhat do veteran djangians(is
        that right?) think? Does anyone use both Hugo and Django, but for different
        projects and for specific reasons?\",\"positive_reactions_count\":5,\"cover_image\":null,\"tag_list\":[\"python\",\"django\",\"hugo\",\"jekyll\"],\"canonical_url\":\"https://dev.to/daveparr/building-my-first-django-project-with-pages-kjn\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":352473,\"title\":\"Writing
        R packages, fast\",\"description\":\"R packages are great. R users have a
        rich ecosystem of extensions to help us doing various things. We...\",\"published\":true,\"published_at\":\"2020-06-10T09:38:19.521Z\",\"slug\":\"writing-r-packages-fast-474c\",\"path\":\"/daveparr/writing-r-packages-fast-474c\",\"url\":\"https://dev.to/daveparr/writing-r-packages-fast-474c\",\"comments_count\":0,\"public_reactions_count\":5,\"page_views_count\":14,\"published_timestamp\":\"2020-06-10T09:38:19Z\",\"body_markdown\":\"R
        packages are great. R users have a rich ecosystem of extensions to\\nhelp
        us doing various things. We have our own *integrated* package\\nmanagement
        system,\\n[CRAN](https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-CRAN_003f),\\nand
        we also have [Metacran](https://www.r-pkg.org/) which gives us an\\neasy way
        to work out how popular specific packages are used. R also\\nmakes it ‘easy’
        for you to write your own packages\\\\! Sort of.\\n\\n# How can I create and
        R package?\\n\\nCRAN suggests making an R package [is really\\nsimple](https://cran.r-project.org/doc/FAQ/R-FAQ.html#How-can-I-create-an-R-package_003f).\\n\\n\\u003e
        5.5 How can I create an R package? A package consists of a\\n\\u003e subdirectory
        containing a file DESCRIPTION and the subdirectories R,\\n\\u003e data, demo,
        exec, inst, man, po, src, and tests (some of which can be\\n\\u003e missing).
        The package subdirectory may also contain files INDEX,\\n\\u003e NAMESPACE,
        configure, cleanup, LICENSE, LICENCE, COPYING and NEWS.\\n\\u003e \\n\\u003e
        See section “Creating R packages” in Writing R Extensions, for\\n\\u003e details.
        This manual is included in the R distribution, see What\\n\\u003e documentation
        exists for R?, and gives information on package\\n\\u003e structure, the configure
        and cleanup mechanisms, and on automated\\n\\u003e package checking and building.\\n\\u003e
        \\n\\u003e R version 1.3.0 has added the function package.skeleton() which
        will\\n\\u003e set up directories, save data and code, and create skeleton
        help files\\n\\u003e for a set of R functions and datasets.\\n\\nSo I just
        run the function `package.skeleton()`, and then I just fill in\\nsome R code
        right? Well, you could. But also, please don’t. Having done\\nit that way
        myself the first few times, you *can* do that, but that\\ndoesn’t mean you
        *should*. Luckily R is a programming language, and\\npeople use programming
        languages to automate things. So obviously people\\nhave built packages the
        slow way that will help you build your package\\n[easier, better, faster](https://www.youtube.com/watch?v=gAjR4_CbPpQ).\\nWe
        should use those instead\\\\!\\n\\n# Starting a project\\n\\nYou should be
        using RStudio. It’s an [Open\\nSource](https://github.com/rstudio/rstudio)
        IDE for R specifically,\\nwhich is [free to download](https://rstudio.com/).
        The fastest way to\\nstart your project is to open RStudio, and go to `File
        \\u003e New Project \\u003e\\nNew Directory \\u003e R Package`. Then give
        it a name, and make sure to create\\na git repository with it.\\n\\nYou now
        have a Hello World package. It contains a function called\\n`hello` in the
        `R` directory, with a few comments and notes about short\\ncuts. You will
        be able to **Build** the package, and you can run a\\n**Check**, which will
        give you a warning, and run the **Test** which\\nwill give you an error.\\n\\nYou’ll
        also have a few other files and folders. `man` will hold the\\nmanual, or
        documentation. The `DESCRIPTION` gives you a bunch of\\nmetadata, and the
        `NAMESPACE` will only have the line\\n`exportPattern(\\\"^[[:alpha:]]+\\\")`.
        Don’t worry about that for now, we’ll\\nfix it in a moment. `.Rbuildignore`
        is a bit like the `.gitignore`. It\\nwill just contain references for R to
        *not* use when running **Build**.\\n\\n# Setting up a package and managing
        package structure with`usethis`\\n\\nI talked about [`usethis`](https://usethis.r-lib.org/)
        in my [last\\npost](https://dev.to/daveparr/testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm),\\nbut
        didn’t do it nearly the justice it deserves. The best place to start\\nis
        [Usage](https://usethis.r-lib.org/#usage) and then have a look at the\\n[Reference](https://usethis.r-lib.org/reference/index.html).\\n\\nIn
        my projects I tend to use these functions to set up each one:\\n\\n  - `use_pipe()`
        to allow the package to use pipes from `magrittr`\\n  - `use_testthat()` to
        set up tests that for the package\\n  - `use_package()` to include a dependency,
        such as `ggplot2` or\\n    `readr`\\n  - `use_vignette()` to include long
        form documentation\\n  - `use_readme_rmd()`/`use_readme_md()` to create Readmes\\n
        \ - `use_badge()` to fill in those Readmes with badges\\n\\nAnd then to write
        my package I tend to use these functions to write it:\\n\\n  - `use_r()` to
        create a new R file to source\\n  - `use_test()` to create a new test for
        a specific open R file\\n  - `use_data()` to include data sets in my packages\\n\\nSo
        you can do all these things manually, and maybe the first time you\\nshould.
        Maybe you should learn that to use a package you need to modify\\nthe `Imports`
        field in the `DESCRIPTION`, and maybe you need to learn\\nthat to make `testthat`
        work in your package you need to make a specific\\n`test` folder, and then
        include a `testthat.R` file to make it work.\\nHowever, I also don’t need
        to implement my own class every time I want\\nto make an object that holds
        a data matrix either, and I also don’t need\\nto know how the interpreter
        *actually* works when I run my `hello`\\nfunction. There’s a reason why we
        don’t write in 1 and 0, and it’s the\\nsame reason I don’t see the value in
        writing my own `NAMESPACE` files\\nany more. I can do it, but it’s a simple
        boring task that I’ve done a\\nbunch of times before, and that at this stage
        I’m actually likely to get\\nmore wrong than the computer. Talking of which…\\n\\n#
        `NAMESPACE`, self-documenting code and self-coding documentation\\n\\nThe
        `NAMESPACE` helps your package understand what functions it sources\\nfrom
        what other packages, and what functions it allows to be used. [The\\nR packages
        book](http://r-pkgs.had.co.nz/namespace.html) has a chapter\\non it that goes
        into detail, but the key thing to really understand is\\n*how* to use it.\\n\\nAs
        an example, lets run `usethis::use_pipe()`. This will set-up our\\npackage
        to allow us to use the `%\\u003e%` operator to chain functions. Our\\nconsole
        tells us:\\n\\n``` r\\n● Run `devtools::document()`\\n```\\n\\nWe also have
        a new file `./R/utils-pipe.R`:\\n\\n``` r\\n#' Pipe operator\\n#'\\n#' See
        \\\\code{magrittr::\\\\link[magrittr]{\\\\%\\u003e\\\\%}} for details.\\n#'\\n#'
        @name %\\u003e%\\n#' @rdname pipe\\n#' @keywords internal\\n#' @export\\n#'
        @importFrom magrittr %\\u003e%\\n#' @usage lhs \\\\%\\u003e\\\\% rhs\\nNULL\\n```\\n\\nSo
        this is a file that’s all comments? Not quite. This is a Roxygen\\ncomment
        block with `#'`, and it has special powers. It won’t actually be\\nexecuted
        if this file is sourced, but if we *document* our package, the\\nprocess will
        read these comment blocks, and the `@` tags, and populate\\nout the documentation
        in `./man`. As we got prompted though, we need to\\nrun the documentation
        process manually, so lets do that with\\n`devtools::document()`.\\n\\n```
        sh\\nUpdating making.packages documentation\\nFirst time using roxygen2. Upgrading
        automatically...\\nWriting NAMESPACE\\nLoading making.packages\\nWriting NAMESPACE\\nWriting
        pipe.Rd\\n```\\n\\nNow we have some changes. Our `NAMESPACE` LOOKS LIKE THIS:\\n\\n```
        r\\n# Generated by roxygen2: do not edit by hand\\n\\nexport(\\\"%\\u003e%\\\")\\nimportFrom(magrittr,\\\"%\\u003e%\\\")\\n```\\n\\nand
        we have a new `./man/pipe.Rd` file:\\n\\n``` r\\n% Generated by roxygen2:
        do not edit by hand\\n% Please edit documentation in R/utils-pipe.R\\n\\\\name{\\\\%\\u003e\\\\%}\\n\\\\alias{\\\\%\\u003e\\\\%}\\n\\\\title{Pipe
        operator}\\n\\\\usage{\\nlhs \\\\%\\u003e\\\\% rhs\\n}\\n\\\\description{\\nSee
        \\\\code{magrittr::\\\\link[magrittr]{\\\\%\\u003e\\\\%}} for details.\\n}\\n\\\\keyword{internal}\\n```\\n\\nWhat’s
        happened? A few things:\\n\\n1.  Roxygen was associated with our package build
        to parse and process\\n    the comments\\n2.  Roxygen re-wrote the `NAMESPACE`\\n3.
        \ Roxygen read the Roxygen comments in the `./R/utils-pipe.R`\\n4.  Roxygen
        used those special comments to put an import and an export\\n    line into
        the `NAMESPACE`\\n      - The `export` will allow users to use the `%\\u003e%`
        when they load\\n        our package\\n      - The `importFrom` will allow
        us to use the `%\\u003e%` in our own code\\n        in the package itself\\n5.
        \ Roxygen populated the manual page for the function so we can see it\\n    in
        the RStudio help.\\n\\nCompare the two comment blocks now. What are the differences?\\n\\n##
        Roxygen comments\\n\\n``` r\\n#' Pipe operator\\n#'\\n#' See \\\\code{magrittr::\\\\link[magrittr]{\\\\%\\u003e\\\\%}}
        for details.\\n#'\\n#' @name %\\u003e%\\n#' @rdname pipe\\n#' @keywords internal\\n#'
        @export\\n#' @importFrom magrittr %\\u003e%\\n#' @usage lhs \\\\%\\u003e\\\\%
        rhs\\nNULL\\n```\\n\\n## Roxygenised `.Rd`\\n\\n``` r\\n% Generated by roxygen2:
        do not edit by hand\\n% Please edit documentation in R/utils-pipe.R\\n\\\\name{\\\\%\\u003e\\\\%}\\n\\\\alias{\\\\%\\u003e\\\\%}\\n\\\\title{Pipe
        operator}\\n\\\\usage{\\nlhs \\\\%\\u003e\\\\% rhs\\n}\\n\\\\description{\\nSee
        \\\\code{magrittr::\\\\link[magrittr]{\\\\%\\u003e\\\\%}} for details.\\n}\\n\\\\keyword{internal}\\n```\\n\\nSo
        the first big one is formatting. The first one looks (mostly) human\\nreadable,
        while the second one has a lot more cruft. This cruft is\\nbasically LaTeX.
        The order has been changed around and few of the labels\\nare a little different,
        but there is another big change. `@export` and\\n`@importFrom` aren’t in the
        documentation\\\\! Those were *only* included\\nto help Roxygen populate the
        `NAMESPACE` file. So you can see that those\\ntwo tags are actually amongst
        the most important things to include in\\ndocumenting other functions. If
        you check in the `DESCRIPTION` file we\\nnow *also* have a new `Imports` field
        in the YAML with `magrittr` being\\nthe only entry. Did you notice that there
        was no *actual* R code in this\\nfunction? It actually explicitly contained
        `NULL`. All of this was\\npurely generated from the documentation, but now
        we actually have a new\\npiece of fundamental functionality in our package.
        Weird huh?\\n\\n# The package skeleton’s connected to the comment bone. The
        comment bone’s connected to the sinew imports.\\n\\nSo now you’re all prepared
        to write your own package. You know how to\\nstart a new package project,
        how to set it up with `usethis` and how to\\ndocument functions with Roxygen.
        Hold up though. That thing about not\\nhaving to do the basically the same
        fiddly boring job multiple times in\\neach package? I really meant it. The
        cool R kids don’t even write their\\nown Roxygen any more.\\n\\nGo back to
        your `./R/hello.R` file, and ditch those boring vanilla `#`\\ncomments. Now
        source the function into your global environment so you\\ncan run it interactively.
        Now `install.packages(\\\"sinew\\\")`, and run\\n`sinew::makeOxygen(hello)`.\\n\\n```
        r\\n#' @description FUNCTION_DESCRIPTION\\n\\n#' @return OUTPUT_DESCRIPTION\\n#'
        @details DETAILS\\n#' @examples \\n#' \\\\dontrun{\\n#' if(interactive()){\\n#'
        \ #EXAMPLE1\\n#'  }\\n#' }\\n#' @rdname hello\\n#' @export \\n```\\n\\nSo
        [sinew](https://yonicd.github.io/sinew/) has built us a template for\\nRoxygen,
        and put the function name in? Cute, but I don’t need that to\\nwrite one word
        for me. OK, how about something a bit more real world.\\nI’ve been [making
        a wrapper for the dev.to\\nAPI](https://dev.to/daveparr/posting-straight-from-rmd-to-dev-to-1j4p)\\n(using
        all these methods). If I go get my `post_new_article` function\\nand run `sinew::makeOxygen(post_new_article)`:\\n\\n```
        r\\n#' @title FUNCTION_TITLE\\n#' @description FUNCTION_DESCRIPTION\\n#' @param
        file PARAM_DESCRIPTION\\n#' @param key PARAM_DESCRIPTION, Default: NA\\n#'
        @return OUTPUT_DESCRIPTION\\n#' @details DETAILS\\n#' @examples \\n#' \\\\dontrun{\\n#'
        if(interactive()){\\n#'  #EXAMPLE1\\n#'  }\\n#' }\\n#' @seealso \\n#'  \\\\code{\\\\link[rmarkdown]{yaml_front_matter}},\\\\code{\\\\link[rmarkdown]{render}}\\n#'
        \ \\\\code{\\\\link[readr]{read_file}}\\n#'  \\\\code{\\\\link[stringr]{str_remove}}\\n#'
        \ \\\\code{\\\\link[glue]{glue}}\\n#'  \\\\code{\\\\link[httr]{POST}},\\\\code{\\\\link[httr]{add_headers}}\\n#'
        @rdname post_new_article\\n#' @export \\n#' @importFrom rmarkdown yaml_front_matter
        render\\n#' @importFrom readr read_file\\n#' @importFrom stringr str_remove\\n#'
        @importFrom glue glue\\n#' @importFrom httr POST add_headers\\n```\\n\\nThis
        is my output. Sinew inspects my function, and then *derives* the\\nfunctions
        I need to import and adds them to the Roxygen comment block.\\nIt also links
        the functions in the `@seealso` which will show up in the\\ndocs. Remember
        that these now get *automatically* added to the\\n`NAMESPACE` and `DESCRIPTIONS`
        where they need to be, each time I\\ndocument my package. It’s also understood
        what arguments my function\\ntakes, and populated them with the defaults,
        if present. Now, why would\\nyou bother writing this by hand any more?\\n\\n#
        TL;DR\\n\\n1.  Start your package in the RStudio IDE as a new project\\n2.
        \ Set up your package with `usethis`\\n3.  Populate your Roxygen comments
        with `sinew`\\n4.  Profit\\\\!\\n\",\"positive_reactions_count\":5,\"cover_image\":null,\"tag_list\":[\"rstats\",\"packages\",\"tools\"],\"canonical_url\":\"https://dev.to/daveparr/writing-r-packages-fast-474c\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":347576,\"title\":\"Testing
        my dev.to API package with testthat, webmockr and vcr\",\"description\":\"I’ve
        been working on an open source R package wrapping the dev.to API. After a
        bit of prototyping the...\",\"published\":true,\"published_at\":\"2020-06-03T11:40:24.185Z\",\"slug\":\"testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm\",\"path\":\"/daveparr/testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm\",\"url\":\"https://dev.to/daveparr/testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm\",\"comments_count\":2,\"public_reactions_count\":5,\"page_views_count\":109,\"published_timestamp\":\"2020-06-03T11:40:24Z\",\"body_markdown\":\"I’ve
        been working on an [open source R package wrapping the dev.to\\nAPI](https://github.com/DaveParr/dev.to.ol).
        After a bit of prototyping\\nthe core feature and then some iterative development
        to make it a bit\\nmore useful to a user, it’s starting to settle into something
        that is\\nworth testing\\\\*.\\n\\n## Testing in R\\n\\nSometimes people seem
        a little surprised that this is something R users/\\nData Scientists even
        think about, but R is a programming language, just\\nlike all the others,
        except different, just like all the others. Testing\\nin modern tidyverse
        R is usually accomplished by the\\n[`testthat`](https://testthat.r-lib.org/)
        package. If you are more\\nfamiliar with testing in other languages, this
        quote from the Overview\\nmight help:\\n\\n\\u003e testthat draws inspiration
        from the xUnit family of testing packages,\\n\\u003e as well as from many
        of the innovative ruby testing libraries, like\\n\\u003e rspec, testy, bacon
        and cucumber.\\n\\n### A note on `usethis`\\n\\nIn R we have a rich ecosystem
        of developer tools to help us make\\npackages. `testthat` is one. Another
        one is `usethis`. See what they did\\nthere? Anyway, for the purpose of this
        article, you just need to know\\nthat a package called `usethis` helps us
        set up things for us to make\\ndevelopment easier. In the future I might write
        something more about it\\n¯\\\\\\\\\\\\_(ツ)\\\\_/¯.\\n\\n## `testthat`\\n\\n###
        Setting up `testthat`\\n\\nAssuming that you have a well formatted R Package
        structure, you can\\neasily enable a testing framework and all the boiler
        plate you might\\nneed with one line:\\n\\n``` r\\nusethis::use_testthat()\\n```\\n\\nWhich
        will do a few things for you and tell you what it’s doing.\\n\\n``` sh\\n✔
        Setting active project to '/Users/davidparr/Documents/example.testthat'\\n✔
        Adding 'testthat' to Suggests field in DESCRIPTION\\n✔ Creating 'tests/testthat/'\\n✔
        Writing 'tests/testthat.R'\\n● Call `use_test()` to initialize a basic test
        file and open it for editing.\\n```\\n\\nFrom there, we can use `usethis::use_test()`.
        If you have a file open in\\nRStudio which is an `*.R` file containing function
        definitions it will\\nthen make a new test file for you:\\n\\n``` sh\\n✔ Increasing
        'testthat' version to '\\u003e= 2.1.0' in DESCRIPTION\\n✔ Writing 'tests/testthat/test-hello.R'\\n●
        Modify 'tests/testthat/test-hello.R'\\n```\\n\\nThe contents of that test
        file will be silly boilerplate, so now it’s\\ntime to do some real work.\\n\\n###
        Writing a `testthat` test\\n\\n``` r\\ntest_that(\\\"multiplication works\\\",
        {\\n  expect_equal(2 * 2, 4)\\n})\\n```\\n\\nThis is the boilerplate. If you
        run it, you might be surprised that\\nnothing happens\\\\! Well, actually
        a lot of stuff happens, but it doesn’t\\nreally tell you about it by design.
        If you make a test that isn’t going\\nto pass however…\\n\\n``` r\\ntest_that(\\\"maths
        works\\\", {\\n  expect_equal(2 * 2, 5)\\n})\\n```\\n\\n    ## Error: Test
        failed: 'maths works'\\n    ## * \\u003ctext\\u003e:2: 2 * 2 not equal to
        5.\\n    ## 1/1 mismatches\\n    ## [1] 4 - 5 == -1\\n\\nAn error\\\\! Just
        what we wanted\\\\! so this is the basis of testing with\\n`testthat`. Write
        a `test_that()` function, which has a name, and then a\\nblock of expectations
        to check against.\\n\\n## `webmockr`\\n\\nSo this works fine for traditional
        unit tests, where we can give\\ndiscrete calculations, or check that a given
        function gives a specific\\noutput end to end, where we control both the test,
        but also the function\\nas a whole. But what if we’re reliant on some ‘external’
        process that we\\nmight not control. The dev.to API for instance? I’m not
        employed by\\ndev.to (through I am [looking for a new\\nopportunity](https://dev.to/daveparr/i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5)),\\nso
        I don’t get to play around inside the API system, but I do need to\\nprove
        that any code I write will behave the way I want it to based on\\ntheir API
        requests and responses. A simple way to prove this is to\\n*mock* their service
        (i.e. impersonate it, not tell it it’s silly). This\\nis where [`webmockr`](https://docs.ropensci.org/webmockr/)
        comes in.\\n`webmockr` is an:\\n\\n\\u003e “R library for stubbing and setting
        expectations on HTTP requests”\\n\\nPerfect. Let’s write something using both
        `testthat` and `webmockr`.\\n\\n### Writing a `webmockr` test\\n\\nIn `webmockr`
        we make *stubs*. These are fake, minimal objects that are\\nsimilar to test
        fixtures. We know their properties, because we made\\nthem, and we want to
        make sure that any functions we write interact with\\nthese objects in a predictable
        way. Another way of looking at them is as\\na fake API. They look like an
        API, with responses and status codes, but\\nthey only exist in our test suite.
        This means I don’t need to bombard\\ndev.to with requests any more to make
        sure I haven’t broken anything.\\n\\n``` r\\nwebmockr::enable(adapter = \\\"httr\\\")\\n\\nwebmockr::stub_registry_clear()\\n\\nwebmockr::stub_request(\\\"get\\\",
        \\\"https://dev.to/api/users/me\\\") %\\u003e%\\n  webmockr::to_return(body
        = \\\"success!\\\", status = 200)\\n\\nmy_user \\u003c- dev.to.ol::get_my_user()\\n\\ntest_that(\\\"stubbed
        response is 200\\\", {\\n  expect_is(my_user, \\\"response\\\")\\n  expect_equal(my_user$status_code,
        200)\\n})\\n```\\n\\nThis code first of all sets up our test file to understand
        that requests\\nwill be sent as if from the `httr` package. It then clears
        the registry,\\njust to make sure nothing is left in a cache. It then populates
        the now\\nempty cache with a new stub. This stub will respond to a `GET` request\\nto
        the URL, and will return a simple text body, and a 200 status code.\\nThe
        function I want to test is then run, which in this environment hits\\nthe
        *stub*, not the real api. The object that is returned is then\\nchecked by
        `test_that` to make sure it is a `response` type object, and\\nthat is has
        a status code that has the value 200.\\n\\n### Good enough, but is it actually
        enough?\\n\\nThis proves a few, specific things. That the function returns
        a\\n`response` that has a 200 status code if it trys to `GET` from that\\nspecific
        URL. However, APIs actually return quite a lot of information\\nby default
        and maybe I care about more things than a 200 status code.\\nThey can also
        have quite complex structures, so using this method to\\nmake a fake response
        could get *very* awkward if I am trying to make a\\nrealistic response. Also,
        what if the structure of the api changes\\nunderneath us? It is in beta after
        all. A big change would mean all\\nthose carefully written pipes would have
        to be rewritten by me every\\ntime. Blergh. Luckily we have a solution for
        that too\\\\!\\n\\n## `vcr`\\n\\n[`vcr`](https://docs.ropensci.org/vcr/) does
        not stand for `Very Cool\\nResponses`, but I think it should. From it’s own
        description:\\n\\n\\u003e Record HTTP calls and replay them\\n\\nIt’s an R
        port of a ruby gem of the same name, this package allows you\\nto ‘record’
        the response of an API to a YAML file ‘cassette’. You can\\nthen ‘play’ the
        ‘cassette’ back during the test as if the API was being\\nactually called.
        If you’re still not sure where the name comes from,\\nthen you might be a
        little to young to [get the\\nreference](https://twitter.com/TheEllenShow/status/1116056186606850048).\\n\\n###
        Setting up `vcr`\\n\\n`vcr` has a few things it needs in a project to run,
        and though it\\ndoesn’t have its *own* entry in `usethis`, it does have it’s
        own\\nset-up function in a similar style:\\n\\n``` r\\nvcr::use_vcr()\\n```\\n\\n```
        sh\\n◉ Using package: vcr.example  \\n◉ assuming fixtures at: tests/fixtures
        \ \\n✓ Adding vcr to Suggests field in DESCRIPTION  \\n✓ Creating directory:
        ./tests/testthat  \\n◉ Looking for testthat.R file or similar  \\n✓ tests/testthat.R:
        added  \\n✓ Adding vcr config to tests/testthat/helper-vcr.example.R  \\n✓
        Adding example test file tests/testthat/test-vcr_example.R  \\n✓ .gitattributes:
        added  \\n◉ Learn more about `vcr`: https://books.ropensci.org/http-testing\\n```\\n\\nFrom
        there, we can use the normal `testthat` flow. Here’s an example\\nusing the
        `POST` to write a new article.\\n\\n``` r\\ntest_that(\\\"post new article\\\",
        {\\n  vcr::use_cassette(\\\"post_new_article\\\", {\\n    new_article \\u003c-
        dev.to.ol::post_new_article(file = \\\"./test.Rmd\\\")\\n  })\\n\\n  expect_is(new_article,
        \\\"response\\\")\\n  expect_equal(new_article$status_code, 201)\\n})\\n```\\n\\nWell,
        that’s an easy change\\\\! The only difference from the first test is\\nthat
        we have wrapped the function we are testing in a `use_cassette`\\nblock, inside
        the `test_that` block. Now, the first time this function\\nis run, you [get\\nthis](https://github.com/DaveParr/dev.to.ol/blob/master/tests/fixtures/post_new_article.yml).\\nA
        huge YAML file that describes the response of the actual API. Now,\\nevery
        time the test is run, that cassette will get loaded as the ‘mock’,\\nand it’s
        so much more developed than our stub\\\\! We can test against\\nanything we
        want in the response, and even better, the response is\\ntotally human readable.\\n\\nWhat
        about changes? What happens if you make a change to the data you\\nuse to
        test the function that invalidates the `cassette`? What if the\\ndev.to spec
        changes? Easy, all you do is delete the test and re-run. The\\nfunction will
        then go and get a new response, and populate the file\\nagain. Your tests
        then run against the new file. You can even commit\\nthese to version control.
        Then you can tell exactly when an API change\\noccurred, and what was different
        afterwards.\\n\\n## Thanks Scott\\n\\nBoth the `webmockr` and `vcr` packages
        are being maintained by @sckott,\\nwho is an active writer here on dev.to.
        and I think he’s really worth a\\nfollow. He also works on [ROpenSci](https://ropensci.org/),
        which I\\nthink is also a really cool project. If you are working with R on
        a\\nscientific/research project you should be extra interested.\\n\\n\\\\*
        Yes, I know that TDD exists. IMHO: No, I don’t think it’s a bad\\nthing, but
        also no, I don’t think it’s always something to use\\neverywhere all the time.\\n\",\"positive_reactions_count\":5,\"cover_image\":null,\"tag_list\":[\"Rstats\",\"projectbenatar\",\"showdev\",\"testing\"],\"canonical_url\":\"https://dev.to/daveparr/testing-my-dev-to-api-package-with-testthat-webmockr-and-vcr-2dgm\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"showdev\",\"bg_color_hex\":\"#091b47\",\"text_color_hex\":\"#b2ffe1\"}},{\"type_of\":\"article\",\"id\":347581,\"title\":\"Does
        anyone have any meetup alternatives?\",\"description\":\"I found this article
        on meetup alternatives interesting. I'm an organiser for Cardiff R Usergroup,
        an...\",\"published\":true,\"published_at\":\"2020-06-01T17:52:32.193Z\",\"slug\":\"does-anyone-have-any-meetup-alternatives-30j2\",\"path\":\"/daveparr/does-anyone-have-any-meetup-alternatives-30j2\",\"url\":\"https://dev.to/daveparr/does-anyone-have-any-meetup-alternatives-30j2\",\"comments_count\":3,\"public_reactions_count\":2,\"page_views_count\":36,\"published_timestamp\":\"2020-06-01T17:52:32Z\",\"body_markdown\":\"[I
        found this article on meetup alternatives interesting](https://marcusnoble.co.uk/2019-10-21-meetup-alternatives/).
        I'm an organiser for [Cardiff R Usergroup](https://www.meetup.com/Cardiff-R-User-Group/),
        and regularly attend quite a few other events in the city. \\n\\nIs meetup
        common for tech groups where you are? Do you or events you go to use anything
        different?\",\"positive_reactions_count\":2,\"cover_image\":null,\"tag_list\":[\"watercooler\",\"discuss\",\"eventsinyourcity\"],\"canonical_url\":\"https://dev.to/daveparr/does-anyone-have-any-meetup-alternatives-30j2\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"watercooler\",\"bg_color_hex\":\"#D0ECFF\",\"text_color_hex\":\"#130074\"}},{\"type_of\":\"article\",\"id\":345001,\"title\":\"Building
        my first Django project with a Database\",\"description\":\"I'm working through
        Django for Beginners by William S. Vincent. Chapter 4 starts using a database
        to...\",\"published\":true,\"published_at\":\"2020-06-01T15:14:30.186Z\",\"slug\":\"building-my-first-django-project-with-a-database-4j09\",\"path\":\"/daveparr/building-my-first-django-project-with-a-database-4j09\",\"url\":\"https://dev.to/daveparr/building-my-first-django-project-with-a-database-4j09\",\"comments_count\":0,\"public_reactions_count\":3,\"page_views_count\":8,\"published_timestamp\":\"2020-06-01T15:14:30Z\",\"body_markdown\":\"I'm
        working through [Django for Beginners by William S. Vincent](https://djangoforbeginners.com/).
        Chapter 4 starts using a database to act as a data store for a Message Board
        app.\\n\\nThis seemed very related to what my buddies do with Laravel, where
        migrations are run when the data Model in the backend needs to be changed.
        I was actually a little surprised that at no point did I need to write any
        SQL though. As someone who has spent their professional life asking databases
        for info, I was actually a tiny bit disappointed \U0001F61C. \\n\\nI'm starting
        to become curious about this `manage.py` file though. All I have in my workspace
        to represent it is:\\n\\n```py\\n#!/usr/bin/env python\\n\\\"\\\"\\\"Django's
        command-line utility for administrative tasks.\\\"\\\"\\\"\\nimport os\\nimport
        sys\\n\\n\\ndef main():\\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE',
        'blog_project.settings')\\n    try:\\n        from django.core.management
        import execute_from_command_line\\n    except ImportError as exc:\\n        raise
        ImportError(\\n            \\\"Couldn't import Django. Are you sure it's installed
        and \\\"\\n            \\\"available on your PYTHONPATH environment variable?
        Did you \\\"\\n            \\\"forget to activate a virtual environment?\\\"\\n
        \       ) from exc\\n    execute_from_command_line(sys.argv)\\n\\n\\nif __name__
        == '__main__':\\n    main()\\n```\\n\\nSo it's obviously getting some morecode
        under the hood, but I'm starting to think it has super powers. It starts projects
        and apps, it makes users, it runs migrations and tests as well as the local
        server. For something that hasn't even really been mentioned other than a
        line of text to type into the CLI my curiosity is definitely rising. Unfortunately
        `python manage.py makecoffee' is the only thing that hasn't worked so far.
        What are your favourite powers of `manage.py`?\",\"positive_reactions_count\":3,\"cover_image\":null,\"tag_list\":[\"python\",\"django\",\"sqlite\"],\"canonical_url\":\"https://dev.to/daveparr/building-my-first-django-project-with-a-database-4j09\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":344150,\"title\":\"Building
        my first Django project\",\"description\":\"I'm working through Django for
        Beginners by William S. Vincent. The second chapter gets us into devel...\",\"published\":true,\"published_at\":\"2020-06-01T12:00:26.409Z\",\"slug\":\"building-my-first-django-project-4fi3\",\"path\":\"/daveparr/building-my-first-django-project-4fi3\",\"url\":\"https://dev.to/daveparr/building-my-first-django-project-4fi3\",\"comments_count\":0,\"public_reactions_count\":2,\"page_views_count\":123,\"published_timestamp\":\"2020-06-01T12:00:26Z\",\"body_markdown\":\"I'm
        working through [Django for Beginners by William S. Vincent](https://djangoforbeginners.com/).
        The second chapter gets us into developing our first app. It simply displays
        a single page with an unformatted Hello World on it, but I really appreciated
        how the project is so fully fleshed out end to end. You start a project with
        a clean `pipenv`, and make the files and folders through the CLI. The django
        framework provides some really nice methods to 'boilerplate' the multiple
        files needed in each project, and having this introduced at the start and
        then fill in the details later when you are hands on is definitely the best
        way to go.\\n\\nIntroducing migrations and the url-view-model[-template] core
        concepts was pretty simple in practice, though a little confusing initially.
        \\\"I've just made a bunch of files with this single `startapp` command, what
        do they all do?\\\" was admittedly my first reaction. \\n\\nThe best part
        of the way this book is set up is the definition of done used in the core
        workflow. A project isn't done unless it has a commit history, is hosted on
        GitHub and deployed on Heroku. I'm really a fan of approaching deployment
        in Chapter 2, just like version control and dev environments in Chapter 1.
        These concepts are your friends, not your monsters :)\\n\\nIncidentally, having
        only been aware of Heroku in passing, I really like the PAAS set up. Very
        usable, the cli tools make the whole thing a doddle and the end satisfaction
        of being able to point at something that's actually on the web and say 'I
        did that!' is always a little more satisfying than 'It works on my machine?'.\",\"positive_reactions_count\":2,\"cover_image\":null,\"tag_list\":[\"python\",\"django\"],\"canonical_url\":\"https://dev.to/daveparr/building-my-first-django-project-4fi3\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":344145,\"title\":\"Setting
        up a Django dev environment\",\"description\":\"I'm working through Django
        for Beginners by William S. Vincent. The first part is about setting up yo...\",\"published\":true,\"published_at\":\"2020-05-27T18:33:40.372Z\",\"slug\":\"setting-up-a-django-dev-environment-17b7\",\"path\":\"/daveparr/setting-up-a-django-dev-environment-17b7\",\"url\":\"https://dev.to/daveparr/setting-up-a-django-dev-environment-17b7\",\"comments_count\":0,\"public_reactions_count\":5,\"page_views_count\":97,\"published_timestamp\":\"2020-05-27T18:33:40Z\",\"body_markdown\":\"I'm
        working through [Django for Beginners by William S. Vincent](https://djangoforbeginners.com/).
        The first part is about setting up your dev environment. The book is setup
        to start for a _complete_ beginner level, which is really nice. It starts
        from introducing the basics of the CLI for both Mac and Windows systems, and
        then some simple terminal commands with `cd`, `ls` etc.\\n\\nIt then goes
        on to help with installation of Python3, `git`, `pipenv` and `django`, all
        great stuff for getting started, plus it set's a great baseline for the rest
        of the book.\\n\\nFor anyone who has worked at all with terminals, version
        control, isolating environments and code editors, 90% of this will be already
        done on the machine, but I still think it's worth putting in. Having it laid
        out for you at the start of your programming experience that version control
        and the terminal are part of the process I think helps with the hump I've
        seen in more experienced beginners where `git` and `pipenv` are Yet Another
        Thing To Learn and so get pushed back in the learning pathway more out of
        fear than anything else.\\n\\nPersonally, I zipped through the setup in a
        few minutes. Hello World django app next!\\n\\nHas anyone else seen the 'git
        is yet another thing to learn' hump? Maybe even had it? How did you overcome
        it?\",\"positive_reactions_count\":5,\"cover_image\":null,\"tag_list\":[\"python\",\"django\",\"git\",\"pipenv\"],\"canonical_url\":\"https://dev.to/daveparr/setting-up-a-django-dev-environment-17b7\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":343573,\"title\":\"I
        made my dev.to content into a website to find a new job\",\"description\":\"After
        discovering this post and this post, I decided to use this tooling to get
        a very simple job don...\",\"published\":true,\"published_at\":\"2020-05-25T18:29:10.311Z\",\"slug\":\"i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5\",\"path\":\"/daveparr/i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5\",\"url\":\"https://dev.to/daveparr/i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5\",\"comments_count\":2,\"public_reactions_count\":25,\"page_views_count\":381,\"published_timestamp\":\"2020-05-25T18:29:10Z\",\"body_markdown\":\"After
        discovering [this post](https://dev.to/stackbit/project-benatar-publishing-dev-powered-websites-with-stackbit-lfo)
        and [this post](https://dev.to/devteam/you-can-now-generate-self-hostable-static-blogs-right-from-your-dev-content-via-stackbit-7a5),
        I decided to use this tooling to get a very simple job done to help me look
        for work.\\n\\n## Context\\n\\nI've been using dev.to a little over the last
        year, and a lot more over the last month. It makes sense for me to use this
        content in my job hunt. I also had a languishing personal page. Originally
        made as a little experiment with hugo, it hadn't seen love in a while, and
        due to some jankey usage of high quality photos performance wise it was pretty
        bad. I'd been meaning to overhaul it for a while, and when the dev.to x stackbit
        collab came to my attention, it was a perfect fit.\\n\\n## Goals\\n\\n1. Use
        the content I've written, and will be continuing to write, to prove I know
        at least a few things about programming.\\n1. Get that content wrapped up
        neatly with a contact page, a statement that I'm looking for work, and a brief
        about me\\n1. Use my daveparr.info domain\\n1. Make the website more performant
        than it's current iteration\\n1. Use a clean, simple, slightly professional
        theme\\n\\n## Method\\n\\n1. Read the instructions in @ben 's [post](https://dev.to/devteam/you-can-now-generate-self-hostable-static-blogs-right-from-your-dev-content-via-stackbit-7a5)\\n1.
        Go through the creation flow\\n1. Assign the domain in netlify (I had a netlify
        hosted JAMstack previously, and my domain was already loaded in there. YMMV)\\n1.
        Clone the project @stackbit created from GitHub, and follow the [readme](https://github.com/DaveParr/daveparrinfo/blob/master/README.md)
        they left there to help you authenticate correctly\\n1. Update the [boilerplate
        stuff](https://github.com/DaveParr/daveparrinfo/commit/d8836e723d49ccd13f5655e7f58346dfa4ade17f)\\n1.
        Push the changes back to GitHub\\n1. Profit\\n\\n## Hiccup\\n\\nI was a little
        surprised when my local copy suddenly got all my blog files [that I then just
        commited]\\n(https://github.com/DaveParr/daveparrinfo/commit/1987c701187b45a85d8b0448a8c577c47ab8b2ac),
        but that seemed to be ok. Pretty sure I've not broken anything :)\\n\\n##
        The End\\n\\nGoals achieved, faster website, with better styling, that will
        be kept more up to date.\\n\\n## P.S. \\n\\nIf you are reading this _on_ my
        [website](daveparr.info), this is all actually managed through a headless
        CMS called [dev.to](dev.to). You can use the link to my profile on the left
        of this article. If you are reading this on dev.to you can see my running
        website at [daveparr.info](daveparr.info).\",\"positive_reactions_count\":25,\"cover_image\":null,\"tag_list\":[\"projectbenatar\",\"showdev\",\"hugo\",\"stackbit\"],\"canonical_url\":\"https://dev.to/daveparr/i-made-my-dev-to-content-into-a-website-to-find-a-new-job-2kn5\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"showdev\",\"bg_color_hex\":\"#091b47\",\"text_color_hex\":\"#b2ffe1\"}},{\"type_of\":\"article\",\"id\":342971,\"title\":\"Posting
        straight from .Rmd to dev.to (for real this time)\",\"description\":\"I’ve
        spent a little time fleshing out my open source R package to post from .Rmd
        straight to dev.to....\",\"published\":true,\"published_at\":\"2020-05-24T17:08:05.561Z\",\"slug\":\"posting-straight-from-rmd-to-dev-to-1j4p\",\"path\":\"/daveparr/posting-straight-from-rmd-to-dev-to-1j4p\",\"url\":\"https://dev.to/daveparr/posting-straight-from-rmd-to-dev-to-1j4p\",\"comments_count\":0,\"public_reactions_count\":18,\"page_views_count\":173,\"published_timestamp\":\"2020-05-24T17:08:05Z\",\"body_markdown\":\"I’ve
        spent a little time fleshing out my [open source R\\npackage](https://github.com/DaveParr/dev.to.ol)
        to post from `.Rmd`\\nstraight to dev.to.\\n\\n## Update from V1\\n\\nThe
        biggest difference from the [first\\nversion](https://dev.to/daveparr/posting-from-rmd-to-dev-to-5gld)
        is\\nthat there is now a single function to move straight from an `.Rmd` on\\ndisk
        to a post on dev.to. In V1 the user still had to:\\n\\n1.  Write an `.Rmd`\\n2.
        \ `knit` to `github_document`\\n3.  `post_new_article` using my `dev.to.ol`
        package\\n4.  De-duplicate the title\\n5.  (Optionally) Add meta-data\\n\\nWith
        this new function the workflow is:\\n\\n1.  Write an `.Rmd`\\n2.  `post_new_article`
        using my `dev.to.ol` package\\n\\n:tada:\\n\\n``` r\\n#' @title Post a markdown
        file to dev.to\\n#' @description Create a new post from an .Rmd.\\n#' @param
        file The path to the file\\n#' @param key Your API key, Default: NA\\n#' @return
        The response\\n#' @details Will look for an api key in the `.REnviron` file.
        Seems to check if the body is identical to a previous article and error if
        so with `\\\"Body markdown has already been taken\\\"`.\\n#' The following
        YAML arguments are read from the file YAML frontmatter if present:\\n#' \\\\describe{\\n#'
        \  \\\\item{title}{A character string}\\n#'   \\\\item{series}{A character
        string}\\n#'   \\\\item{published}{A boolean}\\n#'   \\\\item{tags}{list of
        character strings: \\\\code{[\\\"tag1\\\", \\\"tag2\\\"]}}\\n#' }\\n#'\\n#'
        The default table output method renders a very large print code block.\\n#'
        The workaround is to use  \\\\code{\\\\link[knitr]{kable}}.\\n#'\\n#' @examples\\n#'
        \\\\dontrun{\\n#' if(interactive()){\\n#'  post_new_article(\\\"./articles/my_article.Rmd\\\")\\n#'
        \ }\\n#' }\\n#' @seealso\\n#'  \\\\code{\\\\link[rmarkdown]{yaml_front_matter}},\\\\code{\\\\link[rmarkdown]{render}}\\n#'
        \ \\\\code{\\\\link[readr]{read_file}}\\n#'  \\\\code{\\\\link[stringr]{str_remove}}\\n#'
        \ \\\\code{\\\\link[glue]{glue}}\\n#'  \\\\code{\\\\link[httr]{POST}},\\\\code{\\\\link[httr]{add_headers}},\\\\code{\\\\link[httr]{content}}\\n#'
        @rdname post_new_article\\n#' @export\\n#' @importFrom rmarkdown yaml_front_matter
        render\\n#' @importFrom readr read_file\\n#' @importFrom stringr str_remove\\n#'
        @importFrom glue glue\\n#' @importFrom httr POST add_headers content\\n\\npost_new_article
        \\u003c-\\n  function(file,\\n           key = NA) {\\n    check_file \\u003c-
        is_postable_Rmd(file)\\n\\n    if (check_file) {\\n      file_frontmatter
        \\u003c- rmarkdown::yaml_front_matter(file)\\n\\n      output_path \\u003c-
        rmarkdown::render('./data/test.Rmd',\\n                                       output_format
        = 'github_document',\\n                                       output_dir =
        getwd())\\n\\n      file_string \\u003c- readr::read_file(output_path) %\\u003e%\\n
        \       stringr::str_remove(glue::glue(\\\"{title}\\\\n================\\\\n\\\\n\\\\n\\\",\\n
        \                                      title = file_frontmatter$title))\\n\\n
        \     response \\u003c- httr::POST(\\n        url = \\\"https://dev.to/api/articles\\\",\\n
        \       httr::add_headers(\\\"api-key\\\" = api_key(key = key)),\\n        body
        = list(\\n          article = list(\\n            title = file_frontmatter$title,\\n
        \           series = file_frontmatter$series,\\n            published = file_frontmatter$published,\\n
        \           tags = file_frontmatter$tags,\\n            body_markdown = file_string\\n
        \         )\\n        ),\\n        encode = 'json'\\n      )\\n      httr::content(response)\\n
        \   } else {\\n      message(attr(check_file, \\\"msg\\\"))\\n    }\\n  }\\n```\\n\\n##
        Notable changes\\n\\n### Extract `YAML` frontmatter and render from `.Rmd`
        with [`rmarkdown`](https://rmarkdown.rstudio.com/)\\n\\nThe function will
        now accept an `.Rmd` file directly which it renders to\\nthe correct markdown
        output internally. This was the biggest part\\nmissing from V1, and was easy
        to do with `rmarkdown::render`. A great\\nside-effect is that I can also access
        the `YAML` frontmatter of the\\n`.Rmd`, which I can use to populate the meta-data
        such as the series the\\npost is in, the tags the post is relevant to, and
        the published status.\\n\\n### Check file is suitable with\\n[`assertthat`](https://github.com/hadley/assertthat)\\n\\nAnother
        benefit is that there is now a concrete object I can check for\\ncorrectness.
        I’ve adopted the `assertthat` package to help me, and most\\nof the work was
        [done in this\\ncommit](https://github.com/DaveParr/dev.to.ol/commit/ddccf8ce60adf2bc35ed61d0c0ae581a9189d32d).\\nThe
        workhorse function is\\n[`is_postable_Rmd`](https://github.com/DaveParr/dev.to.ol/blob/master/R/is_postable_Rmd.R):\\n\\n
        \   is_postable_Rmd \\u003c- function(file) {\\n      assertthat::see_if(\\n
        \       assertthat::is.readable(file),\\n        assertthat::has_extension(file,
        \\\"Rmd\\\")\\n      )\\n    }\\n\\nUsing `assertthat::see_if` was really
        useful. It allowed me to check for\\nmultiple conditions, and if they were
        both passed, it returns `TRUE`.\\nHowever, if they did not pass, it returns
        `FALSE` *as well as a message\\nattribute*. This meant that I could very trivially
        plumb that back into\\nthe main function for user feedback as to what is the
        problem with the\\nline `message(attr(check_file, \\\"msg\\\"))`. Additionally,
        as I add criteria\\nto the function I know they will all return human, well
        formatted error\\nmessages. Great work `assertthat`\\\\!\\n\\n### Deduplicate
        the title with [`glue`](https://glue.tidyverse.org/) and [`stringr`](https://stringr.tidyverse.org/)\\n\\nOne
        of the issues with the original approach was the call to render will\\ngenerate
        an `.md` with a title *in the file*, but the dev.to api wants\\nthe title
        *as a separate part of the call*. `stringr` and `glue` to the\\nrescue\\\\!
        Using `glue` is basically a super powered paste. It does nice\\nthings to
        insert named string variables into a templated string. I use\\nthis to make
        the string that is what I want to *remove* from the\\n`body_markdown` object,
        and then do the actual removal with\\n`str_remove`.\\n\\n## Next steps\\n\\nImages.
        The real power of Rmarkdown comes from turning code into\\nnotebooks populated
        with graphics representing your data science work. I\\nhave [not yet found
        an api endpoint for\\nimages](https://dev.to/daveparr/is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd).\\nThe
        POST looks like it will allow a cover image to be included, but on\\nthe face
        of it I don’t think it will allow images to be inserted at\\narbitrary points
        in the article text. Still, I’ll start there and see\\nwhere it goes\\\\!\\n\",\"positive_reactions_count\":18,\"cover_image\":null,\"tag_list\":[\"rstats\",\"projectbenatar\",\"showdev\",\"meta\"],\"canonical_url\":\"https://dev.to/daveparr/posting-straight-from-rmd-to-dev-to-1j4p\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"showdev\",\"bg_color_hex\":\"#091b47\",\"text_color_hex\":\"#b2ffe1\"}},{\"type_of\":\"article\",\"id\":342420,\"title\":\"Is
        there an API endpoint to upload images to DEV.TO?\",\"description\":\"I'm
        continuing to work on dev.to.ol. Some of the future work is sort of clear
        to me, but I'm still mi...\",\"published\":true,\"published_at\":\"2020-05-23T17:24:47.260Z\",\"slug\":\"is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd\",\"path\":\"/daveparr/is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd\",\"url\":\"https://dev.to/daveparr/is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd\",\"comments_count\":0,\"public_reactions_count\":2,\"page_views_count\":73,\"published_timestamp\":\"2020-05-23T17:24:47Z\",\"body_markdown\":\"
        I'm continuing to work on [`dev.to.ol`](https://github.com/DaveParr/dev.to.ol).
        Some of the [future work](https://github.com/DaveParr/dev.to.ol/projects)
        is sort of clear to me, but I'm still missing a big piece of the puzzle. \\n\\n\\u003e
        How can I take the charts (images) generated by the rendering of the .Rmd,
        and submit them to dev.to?\\n\\nI'm not spotting a `POST` or `PUT` method
        in the [api docs](https://docs.dev.to/api/). Have I overlooked something,
        or is it something that might be a future feature?\",\"positive_reactions_count\":2,\"cover_image\":null,\"tag_list\":[\"help\",\"meta\",\"projectbenatar\",\"Rstats\"],\"canonical_url\":\"https://dev.to/daveparr/is-there-an-api-endpoint-to-upload-images-to-dev-to-2acd\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"help\",\"bg_color_hex\":\"#ff3232\",\"text_color_hex\":\"#ffffff\"}},{\"type_of\":\"article\",\"id\":339873,\"title\":\"Posting
        from .Rmd to dev.to\",\"description\":\"I’ve started making an R package called
        dev.to.ol. Dev.to has an api which is in beta, which I’m usin...\",\"published\":true,\"published_at\":\"2020-05-20T11:37:27.120Z\",\"slug\":\"posting-from-rmd-to-dev-to-5gld\",\"path\":\"/daveparr/posting-from-rmd-to-dev-to-5gld\",\"url\":\"https://dev.to/daveparr/posting-from-rmd-to-dev-to-5gld\",\"comments_count\":2,\"public_reactions_count\":6,\"page_views_count\":150,\"published_timestamp\":\"2020-05-20T11:37:27Z\",\"body_markdown\":\"I’ve
        started making an R package called\\n[`dev.to.ol`](https://github.com/DaveParr/dev.to.ol).
        Dev.to has an [api\\nwhich is in beta](https://docs.dev.to/api/), which I’m
        using to power\\nthe package.\\n\\n## Prototype\\n\\nThe first function was
        really just to make sure I could use the api at\\nall. It gets all the articles
        for the authenticated user. What’s my most\\nrecent articles title?\\n\\n```
        r\\nlibrary(dev.to.ol)\\ndev.to.ol::get_users_articles()[[1]]$title\\n```\\n\\n
        \   ## Using DEVTO in .Reinviron\\n\\n    ## [1] \\\"Tidy Tuesday and space
        to learn\\\"\\n\\nSo how does this function work?\\n\\n``` r\\n#' @title get
        the authenticated users articles\\n#' @description Provides lots of info on
        your users articles\\n#' @param key the api you have set up on DEV.TO\\n#'
        @return article stuff\\n#' @details if no key is supplied, will check for
        key named DEVTO in `.Renviron`\\n#' @examples\\n#' \\\\dontrun{\\n#' if(interactive()){\\n#'
        \ get_users_articles(\\\"my_api_key\\\")\\n#'  }\\n#' }\\n#' @seealso\\n#'
        \ \\\\code{\\\\link[httr]{content}},\\\\code{\\\\link[httr]{GET}},\\\\code{\\\\link[httr]{add_headers}}\\n#'
        @rdname get_users_articles\\n#' @export\\n#' @importFrom httr content GET
        add_headers\\n\\nget_users_articles \\u003c- function(key = NA) {\\n  httr::content(httr::GET(url
        = \\\"https://dev.to/api/articles/me\\\",\\n                          httr::add_headers(\\\"api-key\\\"
        =\\n                                              if (!is.na(key)) {\\n                                                key\\n
        \                                             } else {\\n                                                message(\\\"Using
        DEVTO in .Renviron\\\")\\n                                                Sys.getenv(x
        = \\\"DEVTO\\\")\\n                                              })))\\n}\\n```\\n\\nVery
        simply\\\\!\\n\\n  - It uses `httr` to do most of the work through a `GET`
        request.\\n  - It allows a user to supply their own api key as an argument.\\n
        \ - If the user has left that argument as the default `NA`, it will use\\n
        \   the environmental variable named `DEVTO`. This can be set with an\\n    `.Renviron`
        file at the project or user level that looks like this:\\n\\n\\u003c!-- end
        list --\\u003e\\n\\n    DEVTO=\\\"obviouslynotmyrealkey\\\"\\n\\n## Motivation\\n\\nSo
        as R users, we have a great tool baked into our language: rmarkdown.\\nI use
        it for nearly everything. We also have some great tools to magnify\\nit’s
        power, such as R Notebooks, blogdown, package down and distill.\\nSome great
        R people are making the effort to put content here such as\\nJulia Silge (@juliasilge)
        and Colin Fay (@colinfay), though they are\\nalready well established bloggers,
        and are publishing from their main\\nwebsite through RSS. It’s a great solution
        for them but personally I was\\nlooking at dev.to as a great way to *not*
        have to have a whole website.\\nSo what do you do if you want to publish a
        blog, but don’t want to\\nactually maintain a full website? What if you also
        want to be able to be\\npart of the great dev.to community? What if you’re
        both of those things\\nand also find you have a large volume of time on your
        hands? You write a\\npackage to put `.Rmd`s onto dev.to as simply as possible.\\n\\n##
        Workflow\\n\\nMy current process is this:\\n\\n1.  Write an Rmarkdown\\n2.
        \ Render to `github_document` style markdown\\n3.  Open the markdown file
        I just made\\n4.  Copy and paste the output to the dev.to UI\\n5.  Fill in
        the meta-date\\n6.  Hit publish\\n\\nAn ideal process would be:\\n\\n1.  Write
        an Rmarkdown\\n2.  Hit publish\\n\\nLets see, that’s…\\n\\n``` r\\nremoved_work
        \\u003c- 4/6\\n\\nscales::label_percent()(removed_work)\\n```\\n\\n    ##
        [1] \\\"67%\\\"\\n\\nWow, gains\\\\!\\n\\n## Minimum Viable Function\\n\\nSo,
        the key piece of the package is to get a function that will jump my\\nmarkdown
        output from my computer onto dev.to. There are lots more bits\\nthat I should
        have, but that part is the most important.\\n\\n``` r\\n#' @title Post a markdown
        file to dev.to\\n#' @description Create a new post well rendered markdown
        file\\n#' @param key Your API key, Default: NA\\n#' @param file The path to
        the file, Default: file\\n#' @return The response\\n#' @details Will look
        for an api key in the `.REnviron` file. Seems to check if the body is identical
        to a previous article and error if so with `\\\"Body markdown has already
        been taken\\\"`.\\n#' @examples\\n#' \\\\dontrun{\\n#' if(interactive()){\\n#'
        \ post_new_article(\\\"./articles/my_article.md\\\")\\n#'  }\\n#' }\\n#' @seealso\\n#'
        \ \\\\code{\\\\link[httr]{POST}},\\\\code{\\\\link[httr]{add_headers}},\\\\code{\\\\link[httr]{verbose}},\\\\code{\\\\link[httr]{content}}\\n#'
        \ \\\\code{\\\\link[readr]{read_file}}\\n#' @rdname post_new_article\\n#'
        @export\\n#' @importFrom httr POST add_headers verbose content\\n#' @importFrom
        readr read_file\\n\\npost_new_article \\u003c- function(key = NA, file = file)
        {\\n\\n  response \\u003c- httr::POST(\\n    url = \\\"https://dev.to/api/articles\\\",\\n
        \   httr::add_headers(\\\"api-key\\\" =\\n                        if (!is.na(key))
        {\\n                          key\\n                        } else {\\n                          message(\\\"Using
        DEVTO in .Renviron\\\")\\n                          Sys.getenv(x = \\\"DEVTO\\\")\\n
        \                       }),\\n    body = list(article = list(\\n      title
        = 'title',\\n      body_markdown = readr::read_file(file = file)\\n    )),\\n
        \   encode = 'json',\\n    httr::verbose()\\n  )\\n  httr::content(response)\\n}\\n```\\n\\nLots
        of similar things as the earlier function. Api key is all the same\\ncode
        (don’t worry, when I have to write it a third time, I’ll abstract\\nit ;P).
        There are three key changes.\\n\\n1.  use `httr::POST` instead of `httr::GET`
        because here I’m giving the\\n    api info, not requesting it.\\n2.  use the
        `body` argument to enclose the info I am sending the api,\\n    with a list
        of 1 item `article` which itself is a list of 2 items\\n    `title` and `body_markdown`\\n3.
        \ use `readr::read_file` to read the markdown file I want to post into\\n
        \   memory so it can be sent to the api\\n\\n## So does it work?\\n\\nIf you
        can read this, yes :mechanical\\\\_arm:\\n\",\"positive_reactions_count\":6,\"cover_image\":null,\"tag_list\":[\"Rstats\",\"projectbenatar\",\"showdev\",\"markdown\"],\"canonical_url\":\"https://dev.to/daveparr/posting-from-rmd-to-dev-to-5gld\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"},\"flare_tag\":{\"name\":\"showdev\",\"bg_color_hex\":\"#091b47\",\"text_color_hex\":\"#b2ffe1\"}},{\"type_of\":\"article\",\"id\":338914,\"title\":\"Tidy
        Tuesday and space to learn\",\"description\":\"TidyTusdays are a weekly R
        Community event where people learn about RStats by practising with a diffe...\",\"published\":true,\"published_at\":\"2020-05-19T11:55:13.566Z\",\"slug\":\"tidy-tuesday-and-space-to-learn-162o\",\"path\":\"/daveparr/tidy-tuesday-and-space-to-learn-162o\",\"url\":\"https://dev.to/daveparr/tidy-tuesday-and-space-to-learn-162o\",\"comments_count\":0,\"public_reactions_count\":5,\"page_views_count\":87,\"published_timestamp\":\"2020-05-19T11:55:13Z\",\"body_markdown\":\"[TidyTusdays](https://github.com/rfordatascience/tidytuesday)
        are a\\nweekly R Community event where people learn about RStats by practising\\nwith
        a different data set each week. Last week the [Cardiff R User\\ngroup](https://www.meetup.com/Cardiff-R-User-Group/)
        worked on the\\nvolcanoes data-set :volcano:, and something in it really tripped
        me up.\\nWe’ve done this a few times now, and are building up our work in
        [this\\nGitHub repo](https://github.com/CaRdiffR/tidy_thursdays).\\n\\n```
        r\\nlibrary(tidyverse)\\nvolcano \\u003c- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-12/volcano.csv')\\n```\\n\\n##
        Data structure\\n\\nLet’s have a look at what the data is\\n\\n``` r\\nvolcano
        %\\u003e% \\n  str()\\n```\\n\\n    ## tibble [958 × 26] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\\n
        \   ##  $ volcano_number          : num [1:958] 283001 355096 342080 213004
        321040 ...\\n    ##  $ volcano_name            : chr [1:958] \\\"Abu\\\" \\\"Acamarachi\\\"
        \\\"Acatenango\\\" \\\"Acigol-Nevsehir\\\" ...\\n    ##  $ primary_volcano_type
        \   : chr [1:958] \\\"Shield(s)\\\" \\\"Stratovolcano\\\" \\\"Stratovolcano(es)\\\"
        \\\"Caldera\\\" ...\\n    ##  $ last_eruption_year      : chr [1:958] \\\"-6850\\\"
        \\\"Unknown\\\" \\\"1972\\\" \\\"-2080\\\" ...\\n    ##  $ country                 :
        chr [1:958] \\\"Japan\\\" \\\"Chile\\\" \\\"Guatemala\\\" \\\"Turkey\\\" ...\\n
        \   ##  $ region                  : chr [1:958] \\\"Japan, Taiwan, Marianas\\\"
        \\\"South America\\\" \\\"México and Central America\\\" \\\"Mediterranean
        and Western Asia\\\" ...\\n    ##  $ subregion               : chr [1:958]
        \\\"Honshu\\\" \\\"Northern Chile, Bolivia and Argentina\\\" \\\"Guatemala\\\"
        \\\"Turkey\\\" ...\\n    ##  $ latitude                : num [1:958] 34.5
        -23.3 14.5 38.5 46.2 ...\\n    ##  $ longitude               : num [1:958]
        131.6 -67.6 -90.9 34.6 -121.5 ...\\n    ##  $ elevation               : num
        [1:958] 641 6023 3976 1683 3742 ...\\n    ##  $ tectonic_settings       :
        chr [1:958] \\\"Subduction zone / Continental crust (\\u003e25 km)\\\" \\\"Subduction
        zone / Continental crust (\\u003e25 km)\\\" \\\"Subduction zone / Continental
        crust (\\u003e25 km)\\\" \\\"Intraplate / Continental crust (\\u003e25 km)\\\"
        ...\\n    ##  $ evidence_category       : chr [1:958] \\\"Eruption Dated\\\"
        \\\"Evidence Credible\\\" \\\"Eruption Observed\\\" \\\"Eruption Dated\\\"
        ...\\n    ##  $ major_rock_1            : chr [1:958] \\\"Andesite / Basaltic
        Andesite\\\" \\\"Dacite\\\" \\\"Andesite / Basaltic Andesite\\\" \\\"Rhyolite\\\"
        ...\\n    ##  $ major_rock_2            : chr [1:958] \\\"Basalt / Picro-Basalt\\\"
        \\\"Andesite / Basaltic Andesite\\\" \\\"Dacite\\\" \\\"Dacite\\\" ...\\n
        \   ##  $ major_rock_3            : chr [1:958] \\\"Dacite\\\" \\\" \\\" \\\" \\\"
        \\\"Basalt / Picro-Basalt\\\" ...\\n    ##  $ major_rock_4            : chr
        [1:958] \\\" \\\" \\\" \\\" \\\" \\\" \\\"Andesite / Basaltic Andesite\\\"
        ...\\n    ##  $ major_rock_5            : chr [1:958] \\\" \\\" \\\" \\\"
        \\\" \\\" \\\" \\\" ...\\n    ##  $ minor_rock_1            : chr [1:958]
        \\\" \\\" \\\" \\\" \\\"Basalt / Picro-Basalt\\\" \\\" \\\" ...\\n    ##  $
        minor_rock_2            : chr [1:958] \\\" \\\" \\\" \\\" \\\" \\\" \\\" \\\"
        ...\\n    ##  $ minor_rock_3            : chr [1:958] \\\" \\\" \\\" \\\"
        \\\" \\\" \\\" \\\" ...\\n    ##  $ minor_rock_4            : chr [1:958]
        \\\" \\\" \\\" \\\" \\\" \\\" \\\" \\\" ...\\n    ##  $ minor_rock_5            :
        chr [1:958] \\\" \\\" \\\" \\\" \\\" \\\" \\\" \\\" ...\\n    ##  $ population_within_5_km
        \ : num [1:958] 3597 0 4329 127863 0 ...\\n    ##  $ population_within_10_km
        : num [1:958] 9594 7 60730 127863 70 ...\\n    ##  $ population_within_30_km
        : num [1:958] 117805 294 1042836 218469 4019 ...\\n    ##  $ population_within_100_km:
        num [1:958] 4071152 9092 7634778 2253483 393303 ...\\n    ##  - attr(*, \\\"spec\\\")=\\n
        \   ##   .. cols(\\n    ##   ..   volcano_number = col_double(),\\n    ##
        \  ..   volcano_name = col_character(),\\n    ##   ..   primary_volcano_type
        = col_character(),\\n    ##   ..   last_eruption_year = col_character(),\\n
        \   ##   ..   country = col_character(),\\n    ##   ..   region = col_character(),\\n
        \   ##   ..   subregion = col_character(),\\n    ##   ..   latitude = col_double(),\\n
        \   ##   ..   longitude = col_double(),\\n    ##   ..   elevation = col_double(),\\n
        \   ##   ..   tectonic_settings = col_character(),\\n    ##   ..   evidence_category
        = col_character(),\\n    ##   ..   major_rock_1 = col_character(),\\n    ##
        \  ..   major_rock_2 = col_character(),\\n    ##   ..   major_rock_3 = col_character(),\\n
        \   ##   ..   major_rock_4 = col_character(),\\n    ##   ..   major_rock_5
        = col_character(),\\n    ##   ..   minor_rock_1 = col_character(),\\n    ##
        \  ..   minor_rock_2 = col_character(),\\n    ##   ..   minor_rock_3 = col_character(),\\n
        \   ##   ..   minor_rock_4 = col_character(),\\n    ##   ..   minor_rock_5
        = col_character(),\\n    ##   ..   population_within_5_km = col_double(),\\n
        \   ##   ..   population_within_10_km = col_double(),\\n    ##   ..   population_within_30_km
        = col_double(),\\n    ##   ..   population_within_100_km = col_double()\\n
        \   ##   .. )\\n\\n## Objective\\n\\nLots of character columns, and some with
        some slightly funky formatting,\\nsuch as `/` and variations on a theme with
        `(s)` and `(es)`. We’ve also\\ngot a bunch of ‘sparse’ data in the columns
        that start with `major_rock`\\nor `minor_rock` that look like spaces. R has
        a rich set of tools for\\ndealing with missing data a little more effectively,
        so lets\\nclean this up by setting the missing data to be explicit `NA`. In
        this\\ncase, as the column is a character type, we need to `NA_character`
        to\\nfill it up.\\n\\n## Failing solution\\n\\n``` r\\nvolcano %\\u003e%\\n
        \   mutate_at(\\n    .vars = vars(starts_with(c(\\\"major_rock\\\", \\\"minor_rock\\\"))),\\n
        \   .funs = ~ case_when(\\n      . == \\\" \\\" ~ NA_character_,\\n      TRUE
        ~ .\\n    )\\n  ) %\\u003e% \\n  select(starts_with(c(\\\"major_rock\\\",
        \\\"minor_rock\\\"))) %\\u003e% \\n  head() %\\u003e% \\n  knitr::kable()\\n```\\n\\n|
        major\\\\_rock\\\\_1               | major\\\\_rock\\\\_2               |
        major\\\\_rock\\\\_3        | major\\\\_rock\\\\_4               | major\\\\_rock\\\\_5
        | minor\\\\_rock\\\\_1        | minor\\\\_rock\\\\_2        | minor\\\\_rock\\\\_3
        | minor\\\\_rock\\\\_4 | minor\\\\_rock\\\\_5 |\\n| :---------------------------
        | :--------------------------- | :-------------------- | :---------------------------
        | :------------- | :-------------------- | :-------------------- | :-------------
        | :------------- | :------------- |\\n| Andesite / Basaltic Andesite | Basalt
        / Picro-Basalt        | Dacite                |                              |
        \               |                       |                       |                |
        \               |                |\\n| Dacite                       | Andesite
        / Basaltic Andesite |                       |                              |
        \               |                       |                       |                |
        \               |                |\\n| Andesite / Basaltic Andesite | Dacite
        \                      |                       |                              |
        \               | Basalt / Picro-Basalt |                       |                |
        \               |                |\\n| Rhyolite                     | Dacite
        \                      | Basalt / Picro-Basalt | Andesite / Basaltic Andesite
        |                |                       |                       |                |
        \               |                |\\n| Andesite / Basaltic Andesite | Basalt
        / Picro-Basalt        |                       |                              |
        \               | Dacite                |                       |                |
        \               |                |\\n| Andesite / Basaltic Andesite |                              |
        \                      |                              |                | Dacite
        \               | Basalt / Picro-Basalt |                |                |
        \               |\\n\\nWell, that doesn’t quite work. What I want is to have
        the blank spots\\nfilled up with `NA`. Is it my code? It’s not the most basic
        solution,\\nusing some of the tidyeval concepts such as `vars` and `funs`.
        Lets make\\nit as simple as possible.\\n\\n``` r\\nvolcano %\\u003e% \\n  filter(major_rock_5
        == \\\" \\\") %\\u003e% \\n  knitr::kable()\\n```\\n\\n| volcano\\\\_number
        | volcano\\\\_name | primary\\\\_volcano\\\\_type | last\\\\_eruption\\\\_year
        | country | region | subregion | latitude | longitude | elevation | tectonic\\\\_settings
        | evidence\\\\_category | major\\\\_rock\\\\_1 | major\\\\_rock\\\\_2 | major\\\\_rock\\\\_3
        | major\\\\_rock\\\\_4 | major\\\\_rock\\\\_5 | minor\\\\_rock\\\\_1 | minor\\\\_rock\\\\_2
        | minor\\\\_rock\\\\_3 | minor\\\\_rock\\\\_4 | minor\\\\_rock\\\\_5 | population\\\\_within\\\\_5\\\\_km
        | population\\\\_within\\\\_10\\\\_km | population\\\\_within\\\\_30\\\\_km
        | population\\\\_within\\\\_100\\\\_km |\\n| --------------: | :------------
        | :--------------------- | :------------------- | :------ | :----- | :--------
        | -------: | --------: | --------: | :----------------- | :-----------------
        | :------------- | :------------- | :------------- | :------------- | :-------------
        | :------------- | :------------- | :------------- | :------------- | :-------------
        | ------------------------: | -------------------------: | -------------------------:
        | --------------------------: |\\n\\nOdd. I can’t find any values that are
        just spaces, even though they are\\nprinted out that way\\\\! I know they
        are there, I can see them\\\\! Luckily,\\nthe point of these projects is to
        learn, and to learn from each other in\\nthe group :school:.\\n\\n## Problem\\n\\nMy
        buddy [Heather](https://twitter.com/HeathrTurnr) was I think a little\\nsurprised
        when I demonstrated this, but within a few minutes she’d\\nworked it out.
        It’s encoded as a *non\\\\_breaking space*. She linked this\\nblog in our
        chat about [non-braking\\nspaces](https://blog.tonytsai.name/blog/2017-12-04-detecting-non-breaking-space-in-r/)\\nand
        offered us the cryptic solution:\\n\\n    \\\"\\\\u00A0\\\"\\n\\nThe blog
        goes into detail about what this is but the tl;dr is: “It looks\\nlike a space
        but it’s not and it’s [designed that\\nway](https://en.wikipedia.org/wiki/Non-breaking_space)”.\\n\\nSo
        a quick tweak to the code and…\\n\\n## Functional solution\\n\\n``` r\\nvolcano
        %\\u003e%\\n    mutate_at(\\n    .vars = vars(starts_with(c(\\\"major_rock\\\",
        \\\"minor_rock\\\"))),\\n    .funs = ~ case_when(\\n      . == \\\"\\\\u00A0\\\"
        ~ NA_character_,\\n      TRUE ~ .\\n    )\\n  ) %\\u003e% \\n  select(starts_with(c(\\\"major_rock\\\",
        \\\"minor_rock\\\"))) %\\u003e% \\n  head() %\\u003e% \\n  knitr::kable()\\n```\\n\\n|
        major\\\\_rock\\\\_1               | major\\\\_rock\\\\_2               |
        major\\\\_rock\\\\_3        | major\\\\_rock\\\\_4               | major\\\\_rock\\\\_5
        | minor\\\\_rock\\\\_1        | minor\\\\_rock\\\\_2        | minor\\\\_rock\\\\_3
        | minor\\\\_rock\\\\_4 | minor\\\\_rock\\\\_5 |\\n| :---------------------------
        | :--------------------------- | :-------------------- | :---------------------------
        | :------------- | :-------------------- | :-------------------- | :-------------
        | :------------- | :------------- |\\n| Andesite / Basaltic Andesite | Basalt
        / Picro-Basalt        | Dacite                | NA                           |
        NA             | NA                    | NA                    | NA             |
        NA             | NA             |\\n| Dacite                       | Andesite
        / Basaltic Andesite | NA                    | NA                           |
        NA             | NA                    | NA                    | NA             |
        NA             | NA             |\\n| Andesite / Basaltic Andesite | Dacite
        \                      | NA                    | NA                           |
        NA             | Basalt / Picro-Basalt | NA                    | NA             |
        NA             | NA             |\\n| Rhyolite                     | Dacite
        \                      | Basalt / Picro-Basalt | Andesite / Basaltic Andesite
        | NA             | NA                    | NA                    | NA             |
        NA             | NA             |\\n| Andesite / Basaltic Andesite | Basalt
        / Picro-Basalt        | NA                    | NA                           |
        NA             | Dacite                | NA                    | NA             |
        NA             | NA             |\\n| Andesite / Basaltic Andesite | NA                           |
        NA                    | NA                           | NA             | Dacite
        \               | Basalt / Picro-Basalt | NA             | NA             |
        NA             |\\n\\n## Full solution\\n\\nSuccess\\\\! After digging around
        a little, I discovered `str_trim` and\\n`str_squish` can be used for this
        as well to make a perfectly tidy\\nsolution\\\\!\\n\\n``` r\\nvolcano %\\u003e%\\n
        \   mutate_at(\\n    .vars = vars(starts_with(c(\\\"major_rock\\\", \\\"minor_rock\\\"))),\\n
        \   .funs = ~ case_when(\\n      str_trim(.) == \\\"\\\" ~ NA_character_,\\n
        \     TRUE ~ .\\n    )\\n  ) %\\u003e% \\n  select(starts_with(c(\\\"major_rock\\\",
        \\\"minor_rock\\\"))) %\\u003e% \\n  head() %\\u003e% \\n  knitr::kable()\\n```\\n\\n|
        major\\\\_rock\\\\_1               | major\\\\_rock\\\\_2               |
        major\\\\_rock\\\\_3        | major\\\\_rock\\\\_4               | major\\\\_rock\\\\_5
        | minor\\\\_rock\\\\_1        | minor\\\\_rock\\\\_2        | minor\\\\_rock\\\\_3
        | minor\\\\_rock\\\\_4 | minor\\\\_rock\\\\_5 |\\n| :---------------------------
        | :--------------------------- | :-------------------- | :---------------------------
        | :------------- | :-------------------- | :-------------------- | :-------------
        | :------------- | :------------- |\\n| Andesite / Basaltic Andesite | Basalt
        / Picro-Basalt        | Dacite                | NA                           |
        NA             | NA                    | NA                    | NA             |
        NA             | NA             |\\n| Dacite                       | Andesite
        / Basaltic Andesite | NA                    | NA                           |
        NA             | NA                    | NA                    | NA             |
        NA             | NA             |\\n| Andesite / Basaltic Andesite | Dacite
        \                      | NA                    | NA                           |
        NA             | Basalt / Picro-Basalt | NA                    | NA             |
        NA             | NA             |\\n| Rhyolite                     | Dacite
        \                      | Basalt / Picro-Basalt | Andesite / Basaltic Andesite
        | NA             | NA                    | NA                    | NA             |
        NA             | NA             |\\n| Andesite / Basaltic Andesite | Basalt
        / Picro-Basalt        | NA                    | NA                           |
        NA             | Dacite                | NA                    | NA             |
        NA             | NA             |\\n| Andesite / Basaltic Andesite | NA                           |
        NA                    | NA                           | NA             | Dacite
        \               | Basalt / Picro-Basalt | NA             | NA             |
        NA             |\\n\\nLet’s try and breakdown what is happening in this solution
        by concept,\\nand then outline the routine in human language to finish.\\n\\n##
        Concepts\\n\\n### Non-breaking spaces\\n\\n  - the ‘missing’ values are not
        real spaces, they are *non-breaking\\n    spaces*.\\n  - [`stringr::str_trim`](https://stringr.tidyverse.org/reference/str_trim.html)\\n
        \   and `stringr::str_squish` removes space from either the ends or all\\n
        \   the way through a character string depending on what else is\\n    happening
        in the string and what you need from the solution.\\n  - [`mutate_at`](https://dplyr.tidyverse.org/reference/mutate_all.html)\\n
        \   is a buddy of `mutate`, where you use *functional programming* style\\n
        \   to apply a function over a collection of columns.\\n  - this means that
        for the context of evaluation, we will be getting\\n    `\\\"\\\"`, where
        as previously we were seeing `\\\" \\\"` which was actually\\n    encoded
        as `\\\"\\\\u00A0\\\"`\\n\\n### Variable selection\\n\\n  - [`starts_with`](https://dplyr.tidyverse.org/reference/select.html#useful-functions)\\n
        \   is a select helper that is designed for cases when a related value\\n
        \   is stretch wide across multiple columns with similar names, and\\n    returns
        a vector of column names filtered to your criteria.\\n  - [`vars`](https://dplyr.tidyverse.org/reference/vars.html)\\n
        \   automatically *quotes* the names of the columns to *evaluate* later\\n
        \   in context and is almost always used as a wrapper to the `.var =`\\n    argument
        when it’s supported by a function.\\n  - this means that we will be doing
        on operation on each of the columns\\n    selected.\\n\\n### Formula function\\n\\n
        \ - `.funs =` argument, like `.var =`, has a counterpart\\n    [`funs()`](https://dplyr.tidyverse.org/reference/funs.html),
        but\\n    this is being deprecated in favour of the *expression notation*.\\n
        \ - [`case_when`](https://dplyr.tidyverse.org/reference/case_when.html)\\n
        \   is an alternative version of the more common `if else` operation.\\n  -
        `~` is a special operator that is key to the expression notation. It\\n    effectively
        separates the Left Hand Side (LHS) of an expression from\\n    the Right Hand
        Side (RHS). It’s used in two ways in this code.\\n    `case_when` uses full
        expressions to represent what should happen on\\n    the RHS when the criteria
        of the LHS is met. `.funs =` uses it to\\n    make a lambda style formula.
        This is sometimes referred to as a\\n    [*quosure*](https://dplyr.tidyverse.org/articles/programming.html#quoting).\\n
        \ - `.` is also a special operator, and I recommend reading the\\n    [documentation
        of\\n    pipe](https://magrittr.tidyverse.org/reference/pipe.html) `%\\u003e%`.
        The\\n    idea of it here is to reference the data being operated on itself.\\n
        \   In this specific case, it’s each value from each of the selected\\n    columns
        for equivalence to an empty space.\\n\\n## Step-by-step\\n\\nDid you follow
        all that? It’s a minefield I know, but it allows us to do\\nsomething very
        powerful in only a few lines. As an alternative way of\\nunderstanding what
        this does, here’s the step by step:\\n\\n1)  Get all the columns that start
        with either `\\\"major_rock'` or\\n    `\\\"minor_rock\\\"`\\n2)  For each
        of the those columns trim any value at the start or end\\n    that is whitespace,
        including non-breaking white space temporarily,\\n    without modifying the
        underlying data\\n3)  If the value after that is an empty string, replace
        it in the same\\n    column with the `NA` value for characters\\n4)  If the
        value after does not pass that test, use the original value\\n\\nSo do you
        *have to* program this way? No, not really. You could manually\\ncreate the
        list of columns you want to modify, but that would be prone\\nto human error
        and what if you end up with `\\\"minor_rock_6\\\"` or\\n`\\\"major_rock_100\\\"`?
        You could always make a traditional `if else`\\nstructure, but that can get
        long fast if there are multiple conditions\\nto check for. How about using
        the character string `\\\"\\\\u00A0\\\"` to test\\nfor equivalence? Well,
        that would work now, but how do you pick up if\\nthey change suddenly to actual
        spaces? Or another whitespace encoding?\\nProgramming like this keeps code
        readable, maintainable, and robust.\\n\\nIs this overkill for tidy Tuesdays?
        Yes, absolutely. Are the problems\\nthat you solve with this approach purely
        academic? No, not at all. Plus,\\ndoing all that work in 129 characters is
        pretty neat. Excluding spaces.\",\"positive_reactions_count\":5,\"cover_image\":null,\"tag_list\":[\"RStats\",\"tidyverse\",\"tidytuesday\"],\"canonical_url\":\"https://dev.to/daveparr/tidy-tuesday-and-space-to-learn-162o\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":334065,\"title\":\"Is
        there a good way to post from .Rmd to dev.to yet?\",\"description\":\"I know
        we have blogdown and distill, which are great for hosting whole sites. We
        also have the github...\",\"published\":true,\"published_at\":\"2020-05-13T12:05:26.081Z\",\"slug\":\"is-there-a-good-way-to-post-from-rmd-to-dev-to-yet-4c9\",\"path\":\"/daveparr/is-there-a-good-way-to-post-from-rmd-to-dev-to-yet-4c9\",\"url\":\"https://dev.to/daveparr/is-there-a-good-way-to-post-from-rmd-to-dev-to-yet-4c9\",\"comments_count\":1,\"public_reactions_count\":1,\"page_views_count\":41,\"published_timestamp\":\"2020-05-13T12:05:26Z\",\"body_markdown\":\"I
        know we have `blogdown` and `distill`, which are great for hosting whole sites.
        We also have the `github_document` output from `knitr`, which is ok, but a
        little manual to get something up on the site.\\n\\nDoes anyone know if there
        is any work being done to publish more effectively to dev.to, or something
        that I might have missed that is well known?\",\"positive_reactions_count\":1,\"cover_image\":null,\"tag_list\":[\"Rstats\",\"question\",\"devto\",\"blogging\"],\"canonical_url\":\"https://dev.to/daveparr/is-there-a-good-way-to-post-from-rmd-to-dev-to-yet-4c9\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":334055,\"title\":\"Pocket
        Monster BMI\",\"description\":\"library(pokedex) library(tidyverse) library(knitr)
        \             How big is a Pocket Monster?   Pokemo...\",\"published\":true,\"published_at\":\"2020-05-13T11:55:29.276Z\",\"slug\":\"pocket-monster-bmi-1ao0\",\"path\":\"/daveparr/pocket-monster-bmi-1ao0\",\"url\":\"https://dev.to/daveparr/pocket-monster-bmi-1ao0\",\"comments_count\":0,\"public_reactions_count\":4,\"page_views_count\":87,\"published_timestamp\":\"2020-05-13T11:55:29Z\",\"body_markdown\":\"```
        r\\nlibrary(pokedex)\\nlibrary(tidyverse)\\nlibrary(knitr)\\n```\\n\\n# How
        big is a Pocket Monster?\\n\\nPokemon is a combination of ‘Pocket’ and ‘Monster’.
        So they’re all\\npretty small right? Not quite.\\n\\n``` r\\nscale_format
        \\u003c- scales::number_format(accuracy = 1, big.mark = \\\",\\\")\\n\\npokemon
        %\\u003e%\\n  ggplot(aes(x = height, y = weight)) +\\n  geom_point() +\\n
        \ scale_y_continuous(labels = scale_format) + \\n  labs(title = \\\"Height
        and Weight of Pocket Monsters\\\",\\n       x = \\\"Height (m)\\\",\\n       y
        = \\\"Weight (kg)\\\")\\n```\\n\\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/ma2yfumh5qno7716asn6.png)\\n\\nMaybe
        we need to work on this graph a little. Let's make it log scaled on\\nboth
        axis. I’ll put myself in for reference too.\\n\\n``` r\\npokemon %\\u003e%\\n
        \ ggplot(aes(x = height, y = weight)) +\\n  geom_point() +\\n  geom_vline(xintercept
        = 1.7) +\\n  geom_hline(yintercept = 72) +\\n  labs(title = \\\"Height and
        Weight of Pocket Monsters\\\",\\n       subtitle = \\\"Trainer Daves's height
        and weight for reference\\\",\\n       x = \\\"Height (m)\\\",\\n       y
        = \\\"Weight (kg)\\\",\\n       caption = \\\"Log X and Y Scale\\\") +\\n
        \ scale_x_log10() +\\n  scale_y_log10(labels = scale_format)\\n```\\n\\n![Alt
        Text](https://dev-to-uploads.s3.amazonaws.com/i/0rvxuys3lh1jwiggs95v.png)\\n\\nSo
        after a log transform of the scales we have a (roughly) linear\\nrelationship.
        This is what we would expect in real world data. Nothing\\nwith a physical
        existence can have a 0 or negative measure for these\\nfeatures. Therefore,
        thinking of this in terms of average can be\\nmisleading. It will always be
        ‘long tailed’. It might be a stretch to\\nrefer to them all as Pocket Monsters
        though.\\n\\nThere’s also clearly a relationship between both height and weight.\\nLet’s
        try and capture this in a single feature.\\n\\n# BMI\\n\\nThe body mass index
        is a simple metric to link height and weight. Let’s\\ncreate it for our Pokemon.\\n\\n```
        r\\nBMI \\u003c- function(weight, height) {\\n  weight/(height^2)\\n}\\n\\npokemon
        %\\u003e% \\n  mutate(BMI = BMI(weight = weight, height = height)) -\\u003e
        pokemon\\n\\npokemon %\\u003e% \\n  ggplot(aes(x = BMI)) +\\n  geom_histogram()
        +\\n  labs(title = \\\"BMI of Pocket Monsters\\\")\\n```\\n\\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/wc0wmg7bis190lc4gqcy.png)\\n\\nWell,
        that’s something of a surprise. Looking at the scatter plots from\\nearlier,
        there is something in the data set that is very small, but also\\n*extremely*
        heavy. Let’s try and work out what that is.\\n\\n``` r\\npokemon %\\u003e%
        \\n  arrange(desc(BMI)) %\\u003e% \\n  select(name, height, weight, BMI, genus)
        %\\u003e% \\n  top_n(10, BMI) %\\u003e% \\n  kable()\\n```\\n\\n| name      |
        height | weight |        BMI | genus              |\\n| :-------- | -----:
        | -----: | ---------: | :----------------- |\\n| Cosmoem   |    0.1 |  999.9
        | 99990.0000 | Protostar Pokémon  |\\n| Minior    |    0.3 |   40.0 |   444.4444
        | Meteor Pokémon     |\\n| Aron      |    0.4 |   60.0 |   375.0000 | Iron
        Armor Pokémon |\\n| Durant    |    0.3 |   33.0 |   366.6667 | Iron Ant Pokémon
        \  |\\n| Clamperl  |    0.4 |   52.5 |   328.1250 | Bivalve Pokémon    |\\n|
        Torkoal   |    0.5 |   80.4 |   321.6000 | Coal Pokémon       |\\n| Cacnea
        \   |    0.4 |   51.3 |   320.6250 | Cactus Pokémon     |\\n| Munchlax  |
        \   0.6 |  105.0 |   291.6667 | Big Eater Pokémon  |\\n| Sandygast |    0.5
        |   70.0 |   280.0000 | Sand Heap Pokémon  |\\n| Beldum    |    0.6 |   95.2
        |   264.4444 | Iron Ball Pokémon  |\\n\\nThere’s no accounting for cosmological
        battle entities. I’m going to\\nclaim that the Protostar Pokemon is a little
        out of scope for this and\\nfilter it out. Let’s have a look at what we’re
        left with.\\n\\n``` r\\nDave_BMI \\u003c- BMI(weight = 72,  height = 1.70)\\n\\npokemon
        %\\u003e% \\n  filter(name != \\\"Cosmoem\\\")%\\u003e% \\n  ggplot(aes(x
        = BMI)) +\\n  geom_histogram() +\\n  geom_vline(xintercept = Dave_BMI) + \\n
        \ labs(title = \\\"BMI of Pocket Monsters\\\",\\n       subtitle = \\\"Trainer
        Dave's BMI for reference\\\",\\n       caption = \\\"Cosmoem removed\\\")\\n```\\n\\n![Alt
        Text](https://dev-to-uploads.s3.amazonaws.com/i/kj2y0tn7o91vny08qggf.png)\\n\\nSo
        most Pokemon are actually a little bigger than me, and a few of them\\nare
        a lot bigger\\\\!\\nWe’ve also realised that some of them might just be very
        different to\\nme, like stars, made entirely of metal or rock, or maybe even
        giant\\ndragons? Just like in the earlier article, I’m going to pivot the
        data\\nso we get a comparison for dual type Pokemon on both their types.\\n\\n```
        r\\npokemon %\\u003e%\\n  filter(name != \\\"Cosmoem\\\") %\\u003e% \\n  select(name,
        type_1, type_2, BMI, height, weight) %\\u003e%\\n  pivot_longer(\\n    cols
        = starts_with(\\\"type\\\"),\\n    names_to = \\\"slot\\\",\\n    values_to
        = \\\"type\\\",\\n    values_drop_na = TRUE\\n  ) %\\u003e% \\n  ggplot(aes(x
        = BMI)) +\\n  geom_density() + \\n  geom_vline(xintercept = Dave_BMI) + \\n
        \ facet_wrap(. ~ type, scales = \\\"free\\\") +\\n  labs(title = \\\"Pocket
        Monster BMI by type\\\",\\n       subtitle = \\\"Trainer Dave's BMI for reference\\\",\\n
        \      caption = \\\"Cosmoem removed\\\")\\n```\\n\\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/yus2sxt4ss54olz64zii.png)\\n\\nSo
        it looks like I’m not quite as hefty as Pokemon that are rock, steel,\\nice,
        ground, fighting, dark or dragon. That makes sense. I’m also a bit\\nmore
        corporeal than fairy or ghost type. Pokemon has some really big\\nbugs though\\\\!\\n\\n#
        Game Over\\n\\nWe’ve learned quite a few R programming things today. The most
        obvious\\nwere some `ggplot` chart tools:\\n\\n  - `geom_vline()` and `geom_hline()`
        make 1 dimensional lines at\\n    specific points\\n  - `geom_histogram()`
        and `geom_density()` show the distribution of a\\n    single value across
        mutiple observations\\n  - `facet_wrap()` can make grouped charts, which are
        often known as\\n    *small multiples*\\n  - `scale_x_log10()` and `scale_y_log10`
        is an easy way to plot a log\\n    axis\\n  - the `scales` package is also
        useful for formatting the axis labels\\n\\nDid you also notice the first thing
        we did with the `scales` package? In\\nR you can assign a *function* to a
        reference. This means that we don’t\\nneed to repeat ourselves if we want
        to set it up with the same arguments\\nmultiple times, like with formatting
        axis with large numbers.\\n\\nIn the `tidyverse` world we also used the optional
        arguments in\\n`pivot_longer()` to select 2 columns to pivot on, and to drop
        rows we\\ncreate that have `NA` when the Pokemon only has 1 type.\\n\\nMost
        importantly though, we created our own function, and it was easy\\\\!\\nThe
        `BMI` function we created we used to make a single value,\\n`Dave_BMI`, but
        also to make the whole `BMI` column for each Pokemon in\\nthe data set\\\\!
        That’s pretty cool.\\n\\nFrom 2 known features, `weight` and `height` we made
        one single new\\nmeasurement `BMI`. This an example of something that will
        come up more\\nin later posts about machine learning which is called ‘feature\\nengineering’.\\n\\nThe
        next article will be going into how the Pokedex package is actually\\nmade,
        both in trying to design a ‘tidy’ data set, but also how to make a\\npackage
        in R\\\\!\\n\\nP.S. I know that `Pocket Monster` is related to the pokeballs
        they fit in, but that's a less fun title.\",\"positive_reactions_count\":4,\"cover_image\":null,\"tag_list\":[\"Rstats\",\"tidyverse\",\"pokemon\",\"functional\"],\"canonical_url\":\"https://dev.to/daveparr/pocket-monster-bmi-1ao0\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":331136,\"title\":\"Introducing
        the Pokedex package!\",\"description\":\"I made an R data package to make
        Pokemon data more usable in R!   library(pokedex) library(tidyverse)...\",\"published\":true,\"published_at\":\"2020-05-09T17:03:18.022Z\",\"slug\":\"introducing-the-pokedex-package-5416\",\"path\":\"/daveparr/introducing-the-pokedex-package-5416\",\"url\":\"https://dev.to/daveparr/introducing-the-pokedex-package-5416\",\"comments_count\":0,\"public_reactions_count\":6,\"page_views_count\":139,\"published_timestamp\":\"2020-05-09T17:03:18Z\",\"body_markdown\":\"I
        made an R data package to make Pokemon data more usable in R\\\\!\\n\\n```
        r\\nlibrary(pokedex)\\nlibrary(tidyverse)\\nlibrary(knitr)\\n```\\n\\n# How
        many Pokemon in the package?\\n\\nI’ve tried to make the data set ‘tidy’ from
        the start, so we can use\\n`summarise` to count them, and `kable` to make
        some dev.to friendly\\nmarkdown tables.\\n\\n``` r\\npokemon %\\u003e% \\n
        \ summarise(count = n()) %\\u003e% \\n  kable()\\n```\\n\\n| count |\\n| ----:
        |\\n|   807 |\\n\\n# Types\\n\\nTypes are pretty key to Pokemon. Lets have
        a quick look at the Kanto\\nstarters and types.\\n\\n``` r\\npokemon %\\u003e%
        \\n  top_n(n = -9, wt = species_id) %\\u003e% \\n  select(identifier, type_1,
        type_2) %\\u003e%\\n  kable()\\n```\\n\\n| identifier | type\\\\_1 | type\\\\_2
        |\\n| :--------- | :------ | :------ |\\n| bulbasaur  | grass   | poison  |\\n|
        ivysaur    | grass   | poison  |\\n| venusaur   | grass   | poison  |\\n|
        charmander | fire    | NA      |\\n| charmeleon | fire    | NA      |\\n|
        charizard  | fire    | flying  |\\n| squirtle   | water   | NA      |\\n|
        wartortle  | water   | NA      |\\n| blastoise  | water   | NA      |\\n\\n#
        Single and dual types\\n\\nSo Pokemon can have either 1 or 2 types. What’s
        the split between single\\ntype and dual type Pokemon?\\n\\n``` r\\npokemon
        %\\u003e%\\n  mutate(dual_type = case_when(is.na(type_2) ~ TRUE,\\n                               TRUE
        ~ FALSE)) %\\u003e%\\n  group_by(dual_type) %\\u003e%\\n  summarise(count
        = n()) %\\u003e% \\n  kable()\\n```\\n\\n| dual\\\\_type | count |\\n| :---------
        | ----: |\\n| FALSE      |   405 |\\n| TRUE       |   402 |\\n\\nSo, it’s
        nearly a 50:50 split of Pokemon that are single type to Pokemon\\nthat have
        2 types.\\n\\n# How many by type?\\n\\nBut there are also quite a few types
        of Pokemon. Starting with the\\nprimary type, lets make a quick chart to understand
        the distribution of\\nprimary types. Using `group_by` will mean the `summarise`
        gets\\ncalculated *per group*. We can then pipe directly into `ggplot` for
        a\\ncol chart with `geom_col`.\\n\\n``` r\\npokemon %\\u003e%\\n  group_by(type_1)
        %\\u003e%\\n  summarise(count = n()) %\\u003e%\\n  ggplot(aes(x = type_1,
        y = count)) +\\n  geom_col() +\\n  labs(title = \\\"Pokemon by primary type\\\")\\n```\\n\\n![Pokemon
        by primary type](https://dev-to-uploads.s3.amazonaws.com/i/v9nfgl5rwqt0zp18i44s.png)\\n\\nLots
        of water type Pokemon, and lots of normal type Pokemon, but very\\nfew flying
        types. Interesting. How about the secondary types?\\n\\n``` r\\npokemon %\\u003e%
        \\n  filter(!is.na(type_2)) %\\u003e% \\n  group_by(type_2) %\\u003e% \\n
        \ summarise(count = n()) %\\u003e% \\n  ggplot(aes(x = type_2, y = count))
        +\\n  geom_col() +\\n  labs(title = \\\"Pokemon by secondary type\\\",\\n
        \      caption = \\\"For Pokemon with dual type\\\")\\n```\\n\\n![Pokemon
        by secondary type](https://dev-to-uploads.s3.amazonaws.com/i/7r4iuz9whihop7b5cjrh.png)\\n\\nLook
        at all those ’mons with flying as a secondary type\\\\! The thing is\\nthat,
        game-wise, the *order* of the typing doesn’t matter. We can easily\\ncount
        the occurrence of a specific type in either primary or secondary\\nposition
        with `pivot_longer`.\\n\\n`pivot_longer` is actually a newer tidyverse function.
        It is\\ncomplemented with `pivot_wider` and this pair are intended to eventually\\nreplace
        `spread` and `gather`. By filtering out the `NA` I remove any\\nobservations
        of secondary types for Pokemon that don’t actually have\\nthem.\\n\\n``` r\\npokemon
        %\\u003e% \\n  select(identifier, type_1, type_2) %\\u003e% \\n  pivot_longer(-identifier,
        names_to = \\\"slot\\\", values_to = \\\"type\\\") %\\u003e% \\n  group_by(type)
        %\\u003e% \\n  summarise(count = n()) %\\u003e% \\n  filter(!is.na(type))
        %\\u003e% \\n  ggplot(aes(x = type, y = count)) +\\n  geom_col() +\\n  labs(title
        = \\\"Pokemon by either type\\\",\\n       caption = \\\"This will count a
        dual type Pokemon twice,\\\\nonce for each type\\\")\\n```\\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/v5uh6xygkrq7rjikajce.png)\\n\\nSo
        is there any consistency in order at all?\\n\\n``` r\\npokemon %\\u003e%\\n
        \ filter((type_1 == \\\"ghost\\\" \\u0026 type_2 == \\\"fire\\\") |\\n           (type_1
        == \\\"fire\\\" \\u0026 type_2 == \\\"ghost\\\")) %\\u003e% \\n  select(identifier,
        type_1, type_2)\\n```\\n\\n    ## # A tibble: 4 x 3\\n    ##   identifier
        \ type_1 type_2\\n    ##   \\u003cchr\\u003e       \\u003cchr\\u003e  \\u003cchr\\u003e
        \\n    ## 1 litwick     ghost  fire  \\n    ## 2 lampent     ghost  fire  \\n
        \   ## 3 chandelure  ghost  fire  \\n    ## 4 blacephalon fire   ghost\\n\\nIt
        doesn’t look like it. a `ghost fire` Pokemon and a `fire ghost`\\nPokemon
        both turn up. I’d like to see what the coincidence rate is of\\neach type
        in dual type Pokemon, so I need to get some ordering in. I can\\nuse `case_when`
        in `mutate` to create a two new columns in the data. I\\ncan make 2 in one
        call because `mutate` supports multiple *expressions*,\\neach of which names
        a column, and then operates conditionally on the\\nother 2 type columns. These
        new columns will:\\n\\n  - always have a value in the column `type_1_ordered`\\n
        \ - if the Pokemon is dual type, have a value in `type_2_ordered`\\n  - always
        have the types alphabetically ordered between the two\\n    columns. i.e. it
        will always be `fire, ghost`, never `ghost, fire`.\\n\\n\\u003c!-- end list
        --\\u003e\\n\\n``` r\\npokemon %\\u003e%\\n  mutate(\\n    type_1_ordered
        = case_when(is.na(type_2) ~ type_1,\\n                               type_1
        \\u003c type_2 ~ type_1,\\n                               TRUE ~ type_2),\\n
        \   type_2_ordered = case_when(type_1 \\u003e type_2 ~ type_1,\\n                               TRUE
        ~ type_2)\\n  ) -\\u003e pokemon\\n```\\n\\nWhat might the distribution be
        of the flying secondary type, per primary\\ntype?\\n\\n``` r\\npokemon %\\u003e%\\n
        \ mutate(type_combined = case_when(\\n    !is.na(type_2_ordered) ~ paste(type_1_ordered,
        type_2_ordered),\\n    is.na(type_2_ordered) ~ type_1_ordered\\n  )) %\\u003e%\\n
        \ group_by(type_combined) %\\u003e%\\n  summarise(count = n()) %\\u003e%\\n
        \ arrange(desc(count)) %\\u003e%\\n  mutate(type_combined = as_factor(type_combined))
        %\\u003e%\\n  ggplot(aes(x = type_combined, y = count)) +\\n  geom_col() +\\n
        \ labs(title = \\\"Count of Pokemon by dual type\\\",\\n       caption = \\\"Ordered
        by count\\\") + \\n  theme(axis.text.x = element_text(angle = 90))\\n```\\n\\n![Alt
        Text](https://dev-to-uploads.s3.amazonaws.com/i/fz5flcvh8dbtfh3zvh9s.png)\\n\\nSo
        the most often occurring dual type is flying normal. That explains\\nthe first
        2 charts. It’s a bit tricky to see the rest though. Lets make\\na more useful
        plot.\\n\\n``` r\\npokemon %\\u003e% \\n  group_by(type_1_ordered, type_2_ordered)
        %\\u003e% \\n  filter(!is.na(type_2_ordered)) %\\u003e% \\n  summarise(count
        = n()) %\\u003e% \\n  ggplot(aes(x = type_1_ordered, y = type_2_ordered, size
        = count)) +\\n  geom_point() +\\n  labs(title = \\\"Coincidence of a particular
        dual type\\\")\\n```\\n\\n![Alt Text](https://dev-to-uploads.s3.amazonaws.com/i/v6qbe0h2nh6n4vz4bnmz.png)\\n\\nSo
        `flying normal` has the biggest count, with there being quite a few\\n`bug
        flying`. That makes sense, as so many bug Pokemon have wings\\\\!\\nThere
        are also lot’s of `bug poison` and `grass poison`. That makes\\nsense too,
        as so many bugs and plants are poisonous\\\\! How many Pokemon\\nhave unique
        types though?\\n\\n``` r\\npokemon %\\u003e% \\n  group_by(type_1_ordered,
        type_2_ordered) %\\u003e% \\n  filter(!is.na(type_2_ordered)) %\\u003e% \\n
        \ summarise(count = n()) %\\u003e% \\n  filter(count == 1) %\\u003e% \\n  ungroup()
        %\\u003e% \\n  summarise(count = n()) %\\u003e% \\n  kable()\\n```\\n\\n|
        count |\\n| ----: |\\n|    24 |\\n\\n24 Pokemon have unique dual types. Out
        of 807 that isn’t very many\\\\!\\nMaybe these Pokemon might be particularly
        useful? I’ll try and work it\\nout…\\n\\n# Game Over\\n\\nThis post has been
        a simple example of both the data in the package, but\\nalso the `tidyverse`
        methods of doing Exploratory Data Analysis. You can\\nfind out more about
        tidyverse [here](https://www.tidyverse.org/)\\n\\nI got the raw data from
        [this repo by\\nveekun](https://github.com/veekun/pokedex). My package is
        available\\n[here](https://github.com/DaveParr/pokedex), and the particular
        version\\nI used for this post is\\n[here](https://github.com/DaveParr/pokedex/commit/67638e8bc52d58bb0c38534b7c2acc9a78b42053).\\nThough
        it’s in a pretty raw state, I hope to improve over time.\\n\\nI made this
        package to have a bigish, diverse set of data to play with,\\nthat lots of
        people recognise, and that has some inherent real world\\napplication. Pokemon
        is a huge franchise with multiple instalments. Lots\\nof people have played
        it, and even if you haven’t you probably have an\\nintuition about what a
        Pokemon is, and what data about a Pokemon might\\nmake sense, and mean in
        context with other Pokemon. Feel free to fork\\nand mess around with as you
        like. I hope its fun, and maybe even\\nuseful\\\\!\\n\",\"positive_reactions_count\":6,\"cover_image\":null,\"tag_list\":[\"R\",\"Pokemon\",\"tidyverse\",\"RStats\"],\"canonical_url\":\"https://dev.to/daveparr/introducing-the-pokedex-package-5416\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":235676,\"title\":\"Local
        gitlab runners, 'no such image', docker and disk space\",\"description\":\"Davids-MacBook-Pro:data-science
        davidparr$ gitlab-runner exec docker 'anomaly detection' Runtime plat...\",\"published\":true,\"published_at\":\"2020-01-10T13:08:31.863Z\",\"slug\":\"gotcha-local-gitlab-runners-no-such-image-docker-and-disk-space-7ei\",\"path\":\"/daveparr/gotcha-local-gitlab-runners-no-such-image-docker-and-disk-space-7ei\",\"url\":\"https://dev.to/daveparr/gotcha-local-gitlab-runners-no-such-image-docker-and-disk-space-7ei\",\"comments_count\":0,\"public_reactions_count\":9,\"page_views_count\":376,\"published_timestamp\":\"2020-01-10T13:08:31Z\",\"body_markdown\":\"```\\nDavids-MacBook-Pro:data-science
        davidparr$ gitlab-runner exec docker 'anomaly detection'\\nRuntime platform
        \                                   arch=amd64 os=darwin pid=72331 revision=a8a019e0
        version=12.3.0\\nWARNING: You most probably have uncommitted changes. \\nWARNING:
        These changes will not be tested.         \\nRunning with gitlab-runner 12.3.0
        (a8a019e0)\\nUsing Docker executor with image rocker/tidyverse:latest ...\\nAuthenticating
        with credentials from /Users/davidparr/.docker/config.json\\nPulling docker
        image rocker/tidyverse:latest ...\\nERROR: Preparation failed: Error: No such
        image: rocker/tidyverse:latest (executor_docker.go:195:0s)\\nWill be retried
        in 3s ...\\nUsing Docker executor with image rocker/tidyverse:latest ...\\nAuthenticating
        with credentials from /Users/davidparr/.docker/config.json\\nPulling docker
        image rocker/tidyverse:latest ...\\nERROR: Preparation failed: Error: No such
        image: rocker/tidyverse:latest (executor_docker.go:195:0s)\\nWill be retried
        in 3s ...\\nUsing Docker executor with image rocker/tidyverse:latest ...\\nAuthenticating
        with credentials from /Users/davidparr/.docker/config.json\\nPulling docker
        image rocker/tidyverse:latest ...\\nERROR: Preparation failed: Error: No such
        image: rocker/tidyverse:latest (executor_docker.go:195:0s)\\nWill be retried
        in 3s ...\\nERROR: Job failed (system failure): Error: No such image: rocker/tidyverse:latest
        (executor_docker.go:195:0s)\\n```\\n\\nBut you _know_ the image exists. It's
        _definately_ a thing. Look, [it's right here](https://hub.docker.com/r/rocker/tidyverse/).
        I can even __RUN IT IN PRODUCTION__ so why is it not running on my machine?\\n\\n![Alt
        Text](https://thepracticaldev.s3.amazonaws.com/i/4t9ogf06iqphsaewwxvt.jpg)\\n\\nTurns
        out gitlab, as brilliant as I'm normally finding their CICD solution, is lying
        to you. The image _does_ exist, you _aren't_ mad, just not seeing the whole
        picture. \\n\\n```\\nDavids-MacBook-Pro:data-science davidparr$ docker pull
        rocker/tidyverse\\nUsing default tag: latest\\nlatest: Pulling from rocker/tidyverse\\n16ea0e8c8879:
        Pull complete \\n7ce39da2c1e2: Extracting [==================================================\\u003e]
        \ 222.8MB/222.8MB\\nff1bceed0bef: Download complete \\ne36d273bec5a: Download
        complete \\nd3acc34c6c77: Download complete \\n14d07989ce8b: Download complete
        \\n73b6bcbfcb26: Download complete \\n70b803ec0e47: Download complete \\nfailed
        to register layer: Error processing tar file(exit status 1): write /usr/lib/gcc/x86_64-linux-gnu/8/libsupc++.a:
        no space left on device\\nDavids-MacBook-Pro:data-science davidparr$ docker
        pull rocker/tidyverse\\nUsing default tag: latest\\nlatest: Pulling from rocker/tidyverse\\n16ea0e8c8879:
        Pull complete \\n7ce39da2c1e2: Extracting [===================\\u003e                               ]
        \ 85.23MB/222.8MB\\nff1bceed0bef: Download complete \\ne36d273bec5a: Download
        complete \\nd3acc34c6c77: Download complete \\n14d07989ce8b: Download complete
        \\n73b6bcbfcb26: Download complete \\n70b803ec0e47: Downloading [==================================================\\u003e]
        \ 324.8MB/324.8MB\\nwrite /var/lib/docker/tmp/GetImageBlob686008714: no space
        left on device\\n```\\n\\n_That's_ the error message we needed. It turns out
        that after a while, your local machines 'Sparse Image', that has all your
        docker images, containers, networks and registries, and also resizes it's
        on disk footprint as you use docker, will get filled up with old images, containers
        and other cruft. \\n\\nThere is a bit more info [in this thread](https://forums.docker.com/t/no-space-left-on-device-error/10894)
        but the short version is that you probably just want to run `docker system
        prune -a`.\\n\\nThis command is documented to \\\"Remove unused data\\\",
        and when run will tell you all about what it's going to do:\\n\\n```\\nWARNING!
        This will remove:\\n  - all stopped containers\\n  - all networks not used
        by at least one container\\n  - all images without at least one container
        associated to them\\n  - all build cache\\n```\\n\\nFor my use cases this
        is perfect. All the images I need in practice are backed up on the cloud and
        can be rebuilt from code when needed (as they should be), leaving my disk
        memory to be able to be treated a little more like active memory, hot swapping
        in and out containers as needed, keeping the disk space tidy and minimal.
        \\n\\nIn the end I received this lovely message:\\n```\\nTotal reclaimed space:
        10.24GB\\n```\\n\\nAnd we're back to happy local emulation of my CI/CD pipeline.
        Now if only I could optimise my R testing image...\\n\",\"positive_reactions_count\":9,\"cover_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--iaizgnXx--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://thepracticaldev.s3.amazonaws.com/i/wgy943gt1fv7y9sn39aa.jpg\",\"tag_list\":[\"cicd\",\"docker\",\"gitlab\"],\"canonical_url\":\"https://dev.to/daveparr/gotcha-local-gitlab-runners-no-such-image-docker-and-disk-space-7ei\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}},{\"type_of\":\"article\",\"id\":139436,\"title\":\"The
        Real Difference (TM) between Python and R for Data Science\",\"description\":\"smarter
        than your average comparison\",\"published\":true,\"published_at\":\"2019-08-27T13:42:58.731Z\",\"slug\":\"the-real-difference-tm-between-python-and-r-for-data-science-280i\",\"path\":\"/daveparr/the-real-difference-tm-between-python-and-r-for-data-science-280i\",\"url\":\"https://dev.to/daveparr/the-real-difference-tm-between-python-and-r-for-data-science-280i\",\"comments_count\":0,\"public_reactions_count\":7,\"page_views_count\":342,\"published_timestamp\":\"2019-08-27T13:42:58Z\",\"body_markdown\":\"---\\ntitle:
        The Real Difference (TM) between Python and R for Data Science\\npublished:
        true\\ndescription: smarter than your average comparison\\ntags: data science,
        rstats, python, comparison\\n---\\n\\n## Batman vs Superman\\n\\nData science
        has a two language problem. R and python are **both** _the_ language for data
        science. This has lead to some pretty abstract, generic and sometimes absurd
        definitions between the two languages. The worst is probably this image:\\n\\n![RBat
        vs pyman](https://pbs.twimg.com/media/Ce8VP0FWIAI0ad2?format=jpg\\u0026name=small)\\n\\nData
        science is such a wide term, with sometimes a very diverse or even poor understanding
        in business, that clickbaity titles giving superficial answers abound. I've
        tracked down the [source of this image](http://ucanalytics.com/blogs/r-vs-python-comparison-and-awsome-books-free-pdfs-to-learn-them/),
        which has also floated around on twitter [once (2016)](https://twitter.com/lisachwinter/status/715814232676298753)
        or [twice (2018)](https://twitter.com/cmastication/status/1037486624500854784).
        To give the author of the post his dues, the article it's derived from is
        interesting, and I hope the SEO bonus from publishing as the film hype cycle
        grew got him some extra book sales (the books he links to are actually _really_
        worth reading).\\n\\nI first came across it on (a now removed) instagram post
        where it was literally captioned \\\"How to pass any data-science interview\\\"
        on an account specifically advertising it's data science recruitment services.
        I'm not against pop-culture/programming bleed over in any form (I've done
        enough Pokemon programming talks that any horse I get on has to be less Rapidash
        and more Ponyta), but at the point that people who are trying to break into
        the industry are being told this is _valuable information to tell an interviewer_,
        then there is evidently a gap between needs and knowledge.\\n\\nThe difference,
        and decision for the 'right' tool for the job is actually defined by a mixture
        of internal and external factors. Both languages, in themselves, do the job
        of data ingest, processing, analysis, modelling and prediction equally well.
        Both can be deployed on-premises or on the cloud. Both  Minor differences
        in syntax, and major differences in deployment tooling become the defining
        factors.\\n\\n## INTERNALS: Syntax and ecosystem\\n\\nAny programming language
        is little more than syntax. Functional, Object-oriented, Imperative and more,
        in various combinations, with specific conventions and patterns. Curiously
        both [R](https://en.wikipedia.org/wiki/R_(programming_language)) and [Python](https://en.wikipedia.org/wiki/Python_(programming_language))
        are 'Multi-paradigm' according to Wikipedia. This means that multiple, different
        styles can be used depending on the problem at hand. You can write python
        in an OO way, or a functional way. R is often thought of as functional, though
        it allows the construction of classes, and objects with methods, and side-effects,
        so it's not a 'pure functional' language.\\n\\n### However, how do _people_
        actually write code for data science? \\n\\nIn R, data science is a _first
        class application_ (and maybe even _sole aplication_?). [Tidyverse](https://www.tidyverse.org/)
        is arguably the de facto way to write most R projects now. With RStudio giving
        it full corporate support and funding an eco-system of tooling, most R I write,
        have seen others write, and I've taught people to write is in this style.
        Pipes `%\\u003e%` chain function calls with non-standard evaluation of arguments,
        Rmarkdown documents, ggplot visualisation and shiny apps are an R data scientists
        solution of choice. Tidyverse is itself _functionally inspired_, [purrr explicitly
        states this](https://purrr.tidyverse.org/articles/other-langs.html) and [Hadley
        Wickham directly argues that \\\"R, at its heart, is a functional programming
        (FP) language.\\\"](http://adv-r.had.co.nz/Functional-programming.html)\\n\\n\\nPython
        is _everywhere_. Data science in Python isn't pythons only reason for existence.
        [scipy](https://www.scipy.org/) is the python tool chain for data science.
        numpy and pandas are best of buddies, and matplotlib is a front runner for
        graphics. This collection of tools is far less cohesive though, with scikit
        learn, seaborn and jupyter notebooks also being hugely popular, but totally
        removed from the scipy ecosystem. These tools therefore need a bit more work
        to mould into a full product. Object Oriented programming is also more popular,
        [even for](https://towardsdatascience.com/a-data-scientist-should-know-at-least-this-much-python-oop-d63f37eaac4d)
        [data science](https://towardsdatascience.com/object-oriented-programming-for-data-scientists-build-your-ml-estimator-7da416751f64).
        This means you'll be calling objects more directly, and explicitly pulling
        out methods on objects with `myObject.method` more often.\\n\\n\\n### What
        does that mean for me?\\n\\nDo you understand functional programming or object
        oriented programming already, or is one immediately making sense over the
        other? Great, use that one. \\nDo you already have an ecosystem of certain
        tools? Great, use whatever you already have.\\nDo you already have colleagues
        that you need to work with? Great, use whatever they are.\\nDo you already
        have a support network around you for one language but not the other? Great,
        don't make life harder than it needs to be.\\n\\n## EXTERNALS: Application
        and deployment\\n\\nWhat if you don't have an easy answer though? You're starting
        a new project, or you are the only programmer in the business? Then the choice
        becomes harder to get right, but more clear the more experience you have.
        When you know both tools _can achieve_ the same job, you have to choose which
        one does it _more easily_. I've found that I will reach for python and R equally
        now I've been working professionally in both for a while, however, _which_
        I use is defined pretty clearly.\\n\\n### When to use R\\n\\nR encapsulates
        statistic and mathematical ideas clearly and robustly. Depending on where
        you get your dependencies from you can have a very clear idea of the likely
        'correctness' of the library. Roughly [ROpenSci](https://ropensci.org/) is
        more rigorous and stable than [CRAN](https://cran.r-project.org/) which is
        better than github. Tidyverse pipes, NSE, purrr give a tightly coupled working
        environment where syntax is consistent, terse, and trivially refactored. ggplot
        and RMarkdown give business consumable outputs from the start, where code
        can be kept tightly coupled to narrative and reporting, but also infinitely
        customisable to produce something that would get past marketing without a
        glance. Many academic publications rely on R and RMarkdown for both research
        and publication. If you need to make interactive output, shiny is a straightforward
        application framework, with a tight to everything else in this ecosystem.\\n\\nR
        is for **analysts** who need to be _certain_ of the underlying data processing
        _immediately_, produce and iterate on _reporting_ outputs _as fast as possible_
        and write the _least code_ for the most return. [Hadley effectively said as
        much last week](https://qz.com/1661487/hadley-wickham-on-the-future-of-r-python-and-the-tidyverse/).\\n\\n\\u003e
        I think R Markdown is an amazing contribution to R. ... When you are doing
        data analysis typing speed is actually a bottleneck.\\n\\n### When to use
        Python\\n\\nPython is [already used tonnes more than R](https://insights.stackoverflow.com/survey/2019#technology-_-programming-scripting-and-markup-languages)
        because data science isn't it's _only_ job. Data engineers use it very heavily,
        back-end and even front-end developers use it for all kinds of projects, wether
        it is data intensive or not. In many linux distributions (including Mac) it's
        actually installed as part of your machine when you put the operating system
        on. It's also arguably a _cloud native_ language. AWS lambda functions [support
        it out of the box](https://aws.amazon.com/lambda/features/), and Microsoft
        [recently copied them](https://www.theregister.co.uk/2019/08/20/microsoft_azure_functions/).
        This is doubly interesting as Microsoft bought one of the [biggest R consultancies
        in 2015](https://blogs.technet.microsoft.com/machinelearning/2015/04/06/microsoft-closes-acquisition-of-revolution-analytics/),
        but as of yet R is not a natively supported language in much of Microsofts
        ecosystem. It's definitely got more baked in R support than AWS ([PowerBI](https://docs.microsoft.com/en-us/power-bi/desktop-r-visuals)
        and [many others](https://techcommunity.microsoft.com/t5/AI-Customer-Engineering-Team/Understanding-your-R-strategy-options-on-the-Azure-AI-Platform/ba-p/735626?WT.mc_id=Revolutions-blog-davidsmi\\u0026WT.mc_id=Revolutions-blog-davidsmi)),
        but has made moves to [potentially trim back MRAN](https://blog.revolutionanalytics.com/2019/05/cran-snapshots-and-you.html).
        All this means that Python is spoken by most developers, that python is supported
        by most big cloud providers, and that python is probably already built into
        whatever you are working on.\\n\\nPython is for **developers** who need to
        _deploy software_ within a _traditional software environment_ in a _more traditional
        development_ workflow, where _first-class cloud support_ matters, and integration
        with _existing code_ is of top priority.\\n\\n## Conclusion\\n\\nR doesn't
        [necessarily deploy easily into software development](https://resources.rstudio.com/rstudio-conf-2019/it-depends-a-dialog-about-dependencies)
        (\\u003c- not strictly related, but great talk that's relevant to the problem),
        though it is definitely possible (I've done it), you have to put in more work
        to get a roughly similar result. In many situations, that trade off might
        not be worth it.\\n\\nPython doesn't necessarily fit into BI and academic
        workflows, thought it's definitely possible (I've also done it), you have
        to put in more work to get a roughly similar result. In many situations, that
        trade off might not be worth it.\\n\\nSuperman, Batman, Detective Work, Intelligence,
        Cunning, Usage of Tools, More Brain than Muscles, Muscle Power, Super Strength,
        Elegance, Wide Range, More Muscles than Brain are not meaningful differentiators.\",\"positive_reactions_count\":7,\"cover_image\":null,\"tag_list\":[\"datascience\",\"rstats\",\"python\",\"comparison\"],\"canonical_url\":\"https://dev.to/daveparr/the-real-difference-tm-between-python-and-r-for-data-science-280i\",\"user\":{\"name\":\"Dave
        Parr\",\"username\":\"daveparr\",\"twitter_username\":\"DaveParr\",\"github_username\":\"DaveParr\",\"website_url\":\"https://www.daveparr.info\",\"profile_image\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--v1yPvsiE--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\",\"profile_image_90\":\"https://res.cloudinary.com/practicaldev/image/fetch/s--J8DJ9NrN--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/150692/22b3fd57-c859-4087-897b-f63d034fa359.jpeg\"}}]"
  recorded_at: 2020-06-29 13:55:30 GMT
  recorded_with: vcr/0.5.4, webmockr/0.6.2
